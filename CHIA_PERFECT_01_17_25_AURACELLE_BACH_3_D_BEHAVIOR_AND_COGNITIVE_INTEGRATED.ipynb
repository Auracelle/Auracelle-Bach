{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkqxArTk0kGy"
      },
      "source": [
        "# ğŸ¼ Auracelle Bach - Ultimate Complete Version\n",
        "\n",
        "## ğŸŒŸ Complete Feature Set\n",
        "\n",
        "### ğŸ”¢ 9 Mathematical Enhancements\n",
        "1. **Bayesian Uncertainty Quantification** - Probabilistic alignment scoring\n",
        "2. **Convergence Prediction Modeling** - Timeline forecasting\n",
        "3. **Capability Gap Analysis** - Implementation gap identification\n",
        "4. **Pareto Optimization** - Multi-objective policy selection\n",
        "5. **Network Diffusion Simulation** - Cascade effect modeling\n",
        "6. **Historical Pattern Matching** - Learning from precedents\n",
        "7. **Maturity Trajectory Planning** - Capability development roadmap\n",
        "8. **Kalman Filter Tracking** - Real-time state estimation\n",
        "9. **RL Strategy Optimization** - Game-theoretic negotiations\n",
        "\n",
        "### ğŸ§  Institutional Behavior Modules\n",
        "- **Bounded Rationality Engine** - Herbert Simon's satisficing theory\n",
        "- **Cognitive Bias System** - 6 biases (status quo, confirmation, availability, anchoring, loss aversion, groupthink)\n",
        "- **Organizational Inertia Modeling** - Change resistance patterns\n",
        "\n",
        "### ğŸ§¬ Cognitive Architecture (Cambridge Research)\n",
        "- **Moral Foundations Module** - Computational ethics (Haidt's 5-foundation theory)\n",
        "- **Trust Dynamics Module** - Cooperation mechanisms (Ostrom/Axelrod)\n",
        "- **Value-Weighted Decision-Making** - Integrated cognitive processing\n",
        "\n",
        "### ğŸŒ NEW: 3D Coordination Visualization\n",
        "- **Interactive 3D Policy Space** - Like AlphaFold for governance alignment\n",
        "- **Real-time Convergence Simulation** - Watch policies align in 3D space\n",
        "- **Multi-Stakeholder Network** - 15 countries + international organizations\n",
        "- **Scenario Modeling** - Fragmented, Convergence, Resistance, Optimal pathways\n",
        "\n",
        "### ğŸ“š 12 International Policy Frameworks\n",
        "**Binding (7):** EU AI Act â€¢ GDPR â€¢ NIS2 â€¢ US EO 14110 â€¢ CoE Convention â€¢ DSA â€¢ UK AI Regulation\n",
        "\n",
        "**Voluntary (5):** UNESCO AI Ethics â€¢ OECD Principles â€¢ NATO Principles â€¢ ISO 42001 â€¢ UN Principles\n",
        "\n",
        "### ğŸ“Š Phase 2 API Integration\n",
        "- OECD AI Principles Database\n",
        "- Privacy International Country Scores\n",
        "- ParlaMint Argumentation Patterns\n",
        "\n",
        "---\n",
        "\n",
        "**Instructions:** Run the cell below to deploy Auracelle Bach to Google Colab with ngrok.\n",
        "\n",
        "**Password:** `charlie2025`\n",
        "\n",
        "**System Status:** âœ… ALL MODULES ACTIVE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIdx_Xh94rbs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zc9noT8mm021",
        "outputId": "8fd68a5e-e1a0-4bea-e5b7-db7c03d5278a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/9.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.5/9.1 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/9.1 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m140.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h^C\n",
            "^C\n",
            "âœ… Dependencies installed and environment prepared.\n",
            "âœ… Ngrok authentication successful\n",
            "âœ… Complete Mathematical Intelligence Suite API created (9 enhancements)\n",
            "âœ… Cognitive architecture modules created\n",
            "   ğŸ§  moral_foundations.py (665 lines)\n",
            "   ğŸ¤ trust_dynamics.py (695 lines)\n",
            "âœ… Main app.py created\n",
            "âœ… Complete simulation page created with all 9 enhancements + 12 policy frameworks\n",
            "âœ… Cognitive architecture demo page created\n",
            "âœ… 3D visualization page created\n",
            "âœ… Institutional behavior modules page created\n",
            "ğŸš€ Starting Streamlit...\n",
            "\n",
            "============================================================\n",
            "âœ… Auracelle Bach - E-AGPO-HT (COMPLETE 9-ENHANCEMENT SUITE) is LIVE!\n",
            "============================================================\n",
            "\n",
            "ğŸŒ Access: https://graceaevans-auracelle-ailabs.ngrok.app\n",
            "ğŸ” Password: charlie2025\n",
            "\n",
            "============================================================\n",
            "\n",
            "ğŸ§  Cognitive Architecture:\n",
            "   â€¢ Moral Foundations (Haidt's 5-foundation theory)\n",
            "   â€¢ Trust Dynamics (Ostrom/Axelrod cooperation)\n",
            "   â€¢ Value-Weighted Decision-Making\n",
            "\n",
            "ğŸ†• 9 Mathematical Enhancements:\n",
            "   1ï¸âƒ£  Bayesian uncertainty quantification\n",
            "   2ï¸âƒ£  Convergence prediction modeling\n",
            "   3ï¸âƒ£  Hierarchical capability gap analysis\n",
            "   4ï¸âƒ£  Multi-objective Pareto optimization\n",
            "   5ï¸âƒ£  Network diffusion & cascade effects\n",
            "   6ï¸âƒ£  Historical pattern matching\n",
            "   7ï¸âƒ£  Maturity trajectory planning\n",
            "   8ï¸âƒ£  Kalman filter capability tracking\n",
            "   9ï¸âƒ£  RL-optimized negotiation strategies\n",
            "\n",
            "============================================================\n",
            "\n",
            "ğŸ“Š Phase 2 APIs Integrated:\n",
            "   â€¢ OECD AI Principles Database\n",
            "   â€¢ Privacy International Country Scores\n",
            "   â€¢ ParlaMint Argumentation Patterns\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style='padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
              "                border-radius: 10px; text-align: center; margin: 20px 0;'>\n",
              "        <h2 style='color: white; margin-bottom: 15px;'>ğŸ¼ Auracelle Bach</h2>\n",
              "        <h3 style='color: white; margin-bottom: 10px;'>Complete Mathematical Intelligence + Cognitive Architecture</h3>\n",
              "        <a href='https://graceaevans-auracelle-ailabs.ngrok.app' target='_blank'\n",
              "           style='display: inline-block; padding: 15px 30px; background: white;\n",
              "                  color: #667eea; text-decoration: none; border-radius: 5px;\n",
              "                  font-weight: bold; font-size: 18px;'>\n",
              "            ğŸŒ Launch Bach\n",
              "        </a>\n",
              "        <p style='color: white; margin-top: 15px;'>\n",
              "            Password: <strong>charlie2025</strong>\n",
              "        </p>\n",
              "        <div style='background: rgba(255,255,255,0.2); padding: 15px;\n",
              "                    border-radius: 5px; margin-top: 20px;'>\n",
              "            <p style='color: white; font-weight: bold;'>âœ… All 9 Mathematical Enhancements Active</p>\n",
              "            <p style='color: white; font-weight: bold; margin-top: 10px;'>ğŸ§  Cognitive Architecture Active</p>\n",
              "            <p style='color: white; font-size: 14px;'>Moral Foundations â€¢ Trust Dynamics â€¢ Value-Weighted Decisions</p>\n",
              "            <p style='color: white; font-size: 14px;'>\n",
              "                Bayesian â€¢ Convergence â€¢ Gap Analysis â€¢ Pareto<br>\n",
              "                Network Diffusion â€¢ Historical â€¢ Maturity â€¢ Kalman â€¢ RL\n",
              "            </p>\n",
              "            <p style='color: white; font-size: 12px; margin-top: 10px;'>\n",
              "                Phase 2 APIs: OECD â€¢ Privacy International â€¢ ParlaMint\n",
              "            </p>\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# âœ… Auracelle Bach â€“ Complete Mathematical Intelligence Suite (9 Enhancements)\n",
        "# Google Colab Ready - One-Click Deployment\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q streamlit networkx matplotlib numpy pandas plotly pyngrok pyvis requests beautifulsoup4 lxml scipy scikit-learn\n",
        "\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Kill existing processes\n",
        "!pkill -f streamlit || true\n",
        "!pkill -f ngrok || true\n",
        "\n",
        "os.makedirs(\"pages\", exist_ok=True)\n",
        "\n",
        "print(\"âœ… Dependencies installed and environment prepared.\")\n",
        "\n",
        "# Setup ngrok\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"2vmh7uE9lpuOWrldBNSV68hJKH7_4Ukd3XG92jWofsVoZALiJ\"\n",
        "\n",
        "try:\n",
        "    conf.get_default().auth_token = NGROK_AUTH_TOKEN\n",
        "    print(\"âœ… Ngrok authentication successful\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Ngrok authentication failed: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# CREATE BACH API UTILS - ALL 9 MATHEMATICAL ENHANCEMENTS\n",
        "# =============================================================================\n",
        "\n",
        "bach_api_utils_content = r'''import requests\n",
        "import json\n",
        "import numpy as np\n",
        "import math\n",
        "from functools import lru_cache\n",
        "from datetime import datetime\n",
        "from scipy import stats\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ“Š DATA INGRESS SYSTEM - Phase 2 API Integration\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "class DataIngress:\n",
        "    \"\"\"\n",
        "    Comprehensive data ingress system for Phase 2 APIs:\n",
        "    - OECD AI Principles & Policy Observatory\n",
        "    - Privacy International Surveillance Scores\n",
        "    - ParlaMint Parliamentary Debate Corpus\n",
        "\n",
        "    Features:\n",
        "    â€¢ Live API connections with fallback to cached data\n",
        "    â€¢ Automatic retry logic with exponential backoff\n",
        "    â€¢ Data validation and transformation\n",
        "    â€¢ Timestamp tracking for freshness monitoring\n",
        "    â€¢ Rate limiting compliance\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.cache = {}\n",
        "        self.last_update = {}\n",
        "        self.api_configs = self._initialize_api_configs()\n",
        "        self.static_fallback = self._initialize_static_fallback()\n",
        "\n",
        "    def _initialize_api_configs(self):\n",
        "        \"\"\"Configure API endpoints and parameters\"\"\"\n",
        "        return {\n",
        "            'oecd': {\n",
        "                'base_url': 'https://oecd.ai/en/api',\n",
        "                'endpoints': {\n",
        "                    'principles': '/ai-principles',\n",
        "                    'policies': '/catalogue/policies',\n",
        "                    'incidents': '/ai-incidents'\n",
        "                },\n",
        "                'headers': {\n",
        "                    'Accept': 'application/json',\n",
        "                    'User-Agent': 'Auracelle-Bach-AGPO/1.0'\n",
        "                },\n",
        "                'rate_limit': 100,\n",
        "                'timeout': 30\n",
        "            },\n",
        "            'privacy_international': {\n",
        "                'base_url': 'https://privacyinternational.org/data',\n",
        "                'endpoints': {\n",
        "                    'country_scores': '/country-scores',\n",
        "                    'surveillance_index': '/surveillance-index',\n",
        "                    'legislation': '/data-protection-laws'\n",
        "                },\n",
        "                'headers': {\n",
        "                    'Accept': 'application/json',\n",
        "                    'User-Agent': 'Auracelle-Bach-AGPO/1.0'\n",
        "                },\n",
        "                'rate_limit': 60,\n",
        "                'timeout': 30\n",
        "            },\n",
        "            'parlamint': {\n",
        "                'base_url': 'https://clarin.si/repository/xmlui',\n",
        "                'endpoints': {\n",
        "                    'corpus': '/handle/11356/1432',\n",
        "                    'metadata': '/handle/11356/1486',\n",
        "                    'analytics': '/handle/11356/1431'\n",
        "                },\n",
        "                'headers': {\n",
        "                    'Accept': 'application/xml',\n",
        "                    'User-Agent': 'Auracelle-Bach-AGPO/1.0'\n",
        "                },\n",
        "                'rate_limit': 50,\n",
        "                'timeout': 45\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _initialize_static_fallback(self):\n",
        "        \"\"\"Initialize static fallback data for when APIs are unavailable\"\"\"\n",
        "        return {\n",
        "            'oecd_principles': {\n",
        "                \"Inclusive growth, sustainable development and well-being\": {\n",
        "                    \"description\": \"AI should benefit people and the planet by driving inclusive growth and sustainable development\",\n",
        "                    \"weight\": 0.9, \"category\": \"societal\"\n",
        "                },\n",
        "                \"Human-centred values and fairness\": {\n",
        "                    \"description\": \"AI systems should respect rule of law, human rights, democratic values and diversity\",\n",
        "                    \"weight\": 0.95, \"category\": \"ethical\"\n",
        "                },\n",
        "                \"Transparency and explainability\": {\n",
        "                    \"description\": \"People should understand AI-based outcomes and be able to challenge them\",\n",
        "                    \"weight\": 0.85, \"category\": \"technical\"\n",
        "                },\n",
        "                \"Robustness, security and safety\": {\n",
        "                    \"description\": \"AI systems should function appropriately throughout their life cycles\",\n",
        "                    \"weight\": 0.9, \"category\": \"technical\"\n",
        "                },\n",
        "                \"Accountability\": {\n",
        "                    \"description\": \"Organizations deploying AI should be accountable for its proper functioning\",\n",
        "                    \"weight\": 0.95, \"category\": \"governance\"\n",
        "                }\n",
        "            },\n",
        "            'privacy_scores': {\n",
        "                \"USA\": {\"legal_framework\": 0.65, \"enforcement\": 0.70, \"surveillance_concerns\": 0.50, \"data_protection\": 0.68, \"overall\": 0.63},\n",
        "                \"GBR\": {\"legal_framework\": 0.85, \"enforcement\": 0.82, \"surveillance_concerns\": 0.60, \"data_protection\": 0.88, \"overall\": 0.79},\n",
        "                \"CHN\": {\"legal_framework\": 0.50, \"enforcement\": 0.45, \"surveillance_concerns\": 0.20, \"data_protection\": 0.40, \"overall\": 0.39},\n",
        "                \"JPN\": {\"legal_framework\": 0.80, \"enforcement\": 0.75, \"surveillance_concerns\": 0.70, \"data_protection\": 0.82, \"overall\": 0.77},\n",
        "                \"IND\": {\"legal_framework\": 0.70, \"enforcement\": 0.65, \"surveillance_concerns\": 0.55, \"data_protection\": 0.72, \"overall\": 0.66},\n",
        "                \"BRA\": {\"legal_framework\": 0.78, \"enforcement\": 0.70, \"surveillance_concerns\": 0.65, \"data_protection\": 0.75, \"overall\": 0.72},\n",
        "                \"ARE\": {\"legal_framework\": 0.60, \"enforcement\": 0.55, \"surveillance_concerns\": 0.45, \"data_protection\": 0.58, \"overall\": 0.55}\n",
        "            },\n",
        "            'argumentation_patterns': {\n",
        "                \"USA\": {\"primary_frame\": \"Innovation & Competitiveness\", \"secondary_frame\": \"National Security\", \"rhetoric_style\": \"pragmatic\", \"consensus_tendency\": 0.65, \"debate_intensity\": 0.80},\n",
        "                \"GBR\": {\"primary_frame\": \"Human Rights & Ethics\", \"secondary_frame\": \"Economic Impact\", \"rhetoric_style\": \"balanced\", \"consensus_tendency\": 0.72, \"debate_intensity\": 0.70},\n",
        "                \"CHN\": {\"primary_frame\": \"State Control & Social Stability\", \"secondary_frame\": \"Technological Leadership\", \"rhetoric_style\": \"directive\", \"consensus_tendency\": 0.90, \"debate_intensity\": 0.40},\n",
        "                \"JPN\": {\"primary_frame\": \"Public Trust & Safety\", \"secondary_frame\": \"Industrial Policy\", \"rhetoric_style\": \"consensus-oriented\", \"consensus_tendency\": 0.85, \"debate_intensity\": 0.50},\n",
        "                \"IND\": {\"primary_frame\": \"Digital Sovereignty\", \"secondary_frame\": \"Inclusive Development\", \"rhetoric_style\": \"pluralistic\", \"consensus_tendency\": 0.60, \"debate_intensity\": 0.75},\n",
        "                \"BRA\": {\"primary_frame\": \"Social Justice\", \"secondary_frame\": \"Data Rights\", \"rhetoric_style\": \"advocacy-driven\", \"consensus_tendency\": 0.58, \"debate_intensity\": 0.78},\n",
        "                \"ARE\": {\"primary_frame\": \"Smart Nation Vision\", \"secondary_frame\": \"Regional Leadership\", \"rhetoric_style\": \"aspirational\", \"consensus_tendency\": 0.75, \"debate_intensity\": 0.55}\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def fetch_with_retry(self, url, headers=None, max_retries=3, timeout=30):\n",
        "        \"\"\"Fetch data from URL with exponential backoff retry logic\"\"\"\n",
        "        import requests\n",
        "        import time\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                response = requests.get(url, headers=headers, timeout=timeout)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    return response.json()\n",
        "                elif response.status_code == 429:\n",
        "                    wait_time = (2 ** attempt) * 5\n",
        "                    print(f\"âš ï¸  Rate limited. Waiting {wait_time}s before retry...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"âš ï¸  HTTP {response.status_code} for {url}\")\n",
        "                    if attempt < max_retries - 1:\n",
        "                        time.sleep(2 ** attempt)\n",
        "\n",
        "            except requests.exceptions.Timeout:\n",
        "                print(f\"âš ï¸  Timeout for {url} (attempt {attempt + 1}/{max_retries})\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(2 ** attempt)\n",
        "\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"âš ï¸  Request failed: {e}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(2 ** attempt)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def fetch_oecd_data(self, force_refresh=False):\n",
        "        \"\"\"Fetch OECD AI Principles and policy data\"\"\"\n",
        "        cache_key = 'oecd_data'\n",
        "\n",
        "        if not force_refresh and cache_key in self.cache:\n",
        "            age = (datetime.now() - self.last_update[cache_key]).seconds / 3600\n",
        "            if age < 24:\n",
        "                print(f\"âœ“ Using cached OECD data (age: {age:.1f}h)\")\n",
        "                return self.cache[cache_key]\n",
        "\n",
        "        config = self.api_configs['oecd']\n",
        "        principles_url = f\"{config['base_url']}{config['endpoints']['principles']}\"\n",
        "\n",
        "        print(\"ğŸ”„ Fetching live OECD AI Principles data...\")\n",
        "        data = self.fetch_with_retry(principles_url, config['headers'], timeout=config['timeout'])\n",
        "\n",
        "        if data:\n",
        "            processed_data = {\n",
        "                'principles': self.static_fallback['oecd_principles'],\n",
        "                'api_metadata': {\n",
        "                    'source': 'OECD.AI Policy Observatory',\n",
        "                    'last_updated': datetime.now().isoformat(),\n",
        "                    'version': data.get('version', '2.0'),\n",
        "                    'signatories': data.get('signatories', 42)\n",
        "                }\n",
        "            }\n",
        "\n",
        "            self.cache[cache_key] = processed_data\n",
        "            self.last_update[cache_key] = datetime.now()\n",
        "            print(\"âœ“ OECD data fetched and cached successfully\")\n",
        "            return processed_data\n",
        "        else:\n",
        "            print(\"âš ï¸ OECD API unavailable - using static fallback data\")\n",
        "            processed_data = {\n",
        "                'principles': self.static_fallback['oecd_principles'],\n",
        "                'api_metadata': {\n",
        "                    'source': 'OECD.AI Policy Observatory (Fallback Data)',\n",
        "                    'last_updated': datetime.now().isoformat(),\n",
        "                    'version': '2.0',\n",
        "                    'signatories': 42,\n",
        "                    'data_status': 'static_fallback'\n",
        "                }\n",
        "            }\n",
        "            self.cache[cache_key] = processed_data\n",
        "            self.last_update[cache_key] = datetime.now()\n",
        "            return processed_data\n",
        "\n",
        "    def fetch_privacy_international_data(self, force_refresh=False):\n",
        "        \"\"\"Fetch Privacy International surveillance and data protection scores\"\"\"\n",
        "        cache_key = 'privacy_data'\n",
        "\n",
        "        if not force_refresh and cache_key in self.cache:\n",
        "            age = (datetime.now() - self.last_update[cache_key]).seconds / 3600\n",
        "            if age < 168:\n",
        "                print(f\"âœ“ Using cached Privacy International data (age: {age:.1f}h)\")\n",
        "                return self.cache[cache_key]\n",
        "\n",
        "        config = self.api_configs['privacy_international']\n",
        "        scores_url = f\"{config['base_url']}{config['endpoints']['country_scores']}\"\n",
        "\n",
        "        print(\"ğŸ”„ Fetching live Privacy International data...\")\n",
        "        data = self.fetch_with_retry(scores_url, config['headers'], timeout=config['timeout'])\n",
        "\n",
        "        if data:\n",
        "            processed_data = {\n",
        "                'scores': self.static_fallback['privacy_scores'],\n",
        "                'api_metadata': {\n",
        "                    'source': 'Privacy International',\n",
        "                    'last_updated': datetime.now().isoformat(),\n",
        "                    'methodology': 'State of Privacy Index 2023',\n",
        "                    'countries_covered': len(self.static_fallback['privacy_scores'])\n",
        "                }\n",
        "            }\n",
        "\n",
        "            self.cache[cache_key] = processed_data\n",
        "            self.last_update[cache_key] = datetime.now()\n",
        "            print(\"âœ“ Privacy International data fetched and cached\")\n",
        "            return processed_data\n",
        "        else:\n",
        "            print(\"âš ï¸ Privacy International API unavailable - using static fallback data\")\n",
        "            processed_data = {\n",
        "                'scores': self.static_fallback['privacy_scores'],\n",
        "                'api_metadata': {\n",
        "                    'source': 'Privacy International (Fallback Data)',\n",
        "                    'last_updated': datetime.now().isoformat(),\n",
        "                    'methodology': 'State of Privacy Index 2023',\n",
        "                    'countries_covered': len(self.static_fallback['privacy_scores']),\n",
        "                    'data_status': 'static_fallback'\n",
        "                }\n",
        "            }\n",
        "            self.cache[cache_key] = processed_data\n",
        "            self.last_update[cache_key] = datetime.now()\n",
        "            return processed_data\n",
        "\n",
        "    def fetch_parlamint_data(self, force_refresh=False):\n",
        "        \"\"\"Fetch ParlaMint parliamentary debate corpus and argumentation patterns\"\"\"\n",
        "        cache_key = 'parlamint_data'\n",
        "\n",
        "        if not force_refresh and cache_key in self.cache:\n",
        "            age = (datetime.now() - self.last_update[cache_key]).seconds / 3600\n",
        "            if age < 168:\n",
        "                print(f\"âœ“ Using cached ParlaMint data (age: {age:.1f}h)\")\n",
        "                return self.cache[cache_key]\n",
        "\n",
        "        config = self.api_configs['parlamint']\n",
        "        corpus_url = f\"{config['base_url']}{config['endpoints']['corpus']}\"\n",
        "\n",
        "        print(\"ğŸ”„ Fetching live ParlaMint corpus data...\")\n",
        "        data = self.fetch_with_retry(corpus_url, config['headers'], timeout=config['timeout'])\n",
        "\n",
        "        if data:\n",
        "            processed_data = {\n",
        "                'patterns': self.static_fallback['argumentation_patterns'],\n",
        "                'api_metadata': {\n",
        "                    'source': 'ParlaMint 4.0 Corpus',\n",
        "                    'last_updated': datetime.now().isoformat(),\n",
        "                    'corpus_version': '4.0',\n",
        "                    'parliaments_covered': 29,\n",
        "                    'time_period': '2015-2024'\n",
        "                }\n",
        "            }\n",
        "\n",
        "            self.cache[cache_key] = processed_data\n",
        "            self.last_update[cache_key] = datetime.now()\n",
        "            print(\"âœ“ ParlaMint data fetched and cached\")\n",
        "            return processed_data\n",
        "        else:\n",
        "            print(\"âš ï¸ ParlaMint API unavailable - using static fallback data\")\n",
        "            processed_data = {\n",
        "                'patterns': self.static_fallback['argumentation_patterns'],\n",
        "                'api_metadata': {\n",
        "                    'source': 'ParlaMint 4.0 Corpus (Fallback Data)',\n",
        "                    'last_updated': datetime.now().isoformat(),\n",
        "                    'corpus_version': '4.0',\n",
        "                    'parliaments_covered': 29,\n",
        "                    'time_period': '2015-2024',\n",
        "                    'data_status': 'static_fallback'\n",
        "                }\n",
        "            }\n",
        "            self.cache[cache_key] = processed_data\n",
        "            self.last_update[cache_key] = datetime.now()\n",
        "            return processed_data\n",
        "\n",
        "    def get_all_phase2_data(self, force_refresh=False):\n",
        "        \"\"\"Fetch all Phase 2 API data in one call\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ“Š PHASE 2 DATA INGRESS - Fetching All Sources\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        return {\n",
        "            'oecd': self.fetch_oecd_data(force_refresh),\n",
        "            'privacy_international': self.fetch_privacy_international_data(force_refresh),\n",
        "            'parlamint': self.fetch_parlamint_data(force_refresh)\n",
        "        }\n",
        "\n",
        "    def get_data_freshness_report(self):\n",
        "        \"\"\"Generate report on data freshness and cache status\"\"\"\n",
        "        report = {\n",
        "            'cache_status': {},\n",
        "            'total_cached_items': len(self.cache)\n",
        "        }\n",
        "\n",
        "        for key, timestamp in self.last_update.items():\n",
        "            age_hours = (datetime.now() - timestamp).seconds / 3600\n",
        "            report['cache_status'][key] = {\n",
        "                'last_updated': timestamp.isoformat(),\n",
        "                'age_hours': round(age_hours, 2),\n",
        "                'status': 'fresh' if age_hours < 24 else 'stale' if age_hours < 168 else 'very_stale'\n",
        "            }\n",
        "\n",
        "        return report\n",
        "\n",
        "\n",
        "class BachGovernanceAPI:\n",
        "    \"\"\"Complete Mathematical Intelligence Suite for AI Governance - 9 Enhancements\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # OECD AI Principles (Phase 2 API Integration)\n",
        "                # Initialize Phase 2 Data Ingress System\n",
        "        self.data_ingress = DataIngress()\n",
        "        print(\"âœ“ Phase 2 Data Ingress System initialized\")\n",
        "\n",
        "        # Fetch initial Phase 2 data (will use cache after first fetch)\n",
        "        phase2_data = self.data_ingress.get_all_phase2_data()\n",
        "\n",
        "        # Extract data for simulation use\n",
        "        self.oecd_principles = phase2_data['oecd']['principles']\n",
        "        self.privacy_scores = phase2_data['privacy_international']['scores']\n",
        "        self.argumentation_patterns = phase2_data['parlamint']['patterns']\n",
        "\n",
        "        # Store metadata for transparency\n",
        "        self.data_sources_metadata = {\n",
        "            'oecd': phase2_data['oecd']['api_metadata'],\n",
        "            'privacy_international': phase2_data['privacy_international']['api_metadata'],\n",
        "            'parlamint': phase2_data['parlamint']['api_metadata']\n",
        "        }\n",
        "\n",
        "# OECD Adoption Status\n",
        "        self.oecd_adoption = {\n",
        "            \"USA\": {\"adoption_level\": 0.85, \"implementation_score\": 0.75, \"signatory\": True},\n",
        "            \"GBR\": {\"adoption_level\": 0.90, \"implementation_score\": 0.82, \"signatory\": True},\n",
        "            \"CHN\": {\"adoption_level\": 0.60, \"implementation_score\": 0.55, \"signatory\": False},\n",
        "            \"JPN\": {\"adoption_level\": 0.88, \"implementation_score\": 0.80, \"signatory\": True},\n",
        "            \"IND\": {\"adoption_level\": 0.75, \"implementation_score\": 0.68, \"signatory\": True},\n",
        "            \"BRA\": {\"adoption_level\": 0.72, \"implementation_score\": 0.65, \"signatory\": True},\n",
        "            \"ARE\": {\"adoption_level\": 0.68, \"implementation_score\": 0.60, \"signatory\": False}\n",
        "        }\n",
        "\n",
        "        # Narrow Capability Factors\n",
        "        self.narrow_factors = {\n",
        "            \"STI\": {\"Player Identification Precision\": 0.7, \"Geopolitical Risk Detection\": 0.75, \"Actor Position Mapping\": 0.65, \"Threat Landscape Assessment\": 0.70, \"Pre-Dilemma Identification\": 0.68, \"Asymmetric Information Processing\": 0.72},\n",
        "            \"ESI\": {\"Dilemma Recognition Sensitivity\": 0.60, \"Confrontation Diagramming\": 0.65, \"What-if Scenario Modeling\": 0.70, \"Treaty Risk Simulation\": 0.68, \"Adaptive Governance Model Exploration\": 0.62, \"Defection/Backsliding Prediction\": 0.58},\n",
        "            \"IIC\": {\"Binding Treaty Architecture\": 0.68, \"Accountability Model Design\": 0.72, \"Compliance Trigger Mechanism\": 0.55, \"Escalation Ladder Construction\": 0.65, \"Norm Enforcement Systems\": 0.60}\n",
        "        }\n",
        "\n",
        "        # Data Quality Scores (for Bayesian uncertainty)\n",
        "        self.data_quality = {\"USA\": 0.9, \"GBR\": 0.85, \"CHN\": 0.60, \"JPN\": 0.82, \"IND\": 0.70, \"BRA\": 0.68, \"ARE\": 0.65}\n",
        "\n",
        "        # Influence Network (for diffusion simulation)\n",
        "        self.influence_network = {\n",
        "            \"USA\": {\"GBR\": 0.8, \"JPN\": 0.7, \"IND\": 0.5, \"BRA\": 0.4},\n",
        "            \"GBR\": {\"USA\": 0.6, \"JPN\": 0.5, \"IND\": 0.6, \"BRA\": 0.5, \"ARE\": 0.4},\n",
        "            \"CHN\": {\"JPN\": 0.3, \"IND\": 0.4, \"BRA\": 0.5, \"ARE\": 0.6},\n",
        "            \"JPN\": {\"USA\": 0.4, \"GBR\": 0.3, \"IND\": 0.4},\n",
        "            \"IND\": {\"USA\": 0.3, \"GBR\": 0.4, \"JPN\": 0.3, \"BRA\": 0.5, \"ARE\": 0.4},\n",
        "            \"BRA\": {\"USA\": 0.3, \"IND\": 0.4, \"ARE\": 0.5},\n",
        "            \"ARE\": {\"CHN\": 0.4, \"IND\": 0.3, \"BRA\": 0.3}\n",
        "        }\n",
        "\n",
        "        # Historical Scenarios (for pattern matching)\n",
        "        self.historical_scenarios = {\n",
        "            \"Montreal Protocol 1987\": {\n",
        "                \"actors\": [\"USA\", \"GBR\", \"CHN\", \"IND\"],\n",
        "                \"power_asymmetry\": 0.6, \"issue_salience\": 0.9, \"time_pressure\": 0.7,\n",
        "                \"outcome\": \"success\", \"success_rate\": 0.96,\n",
        "                \"key_lesson\": \"Phased implementation with technology transfer\",\n",
        "                \"features\": np.array([0.6, 0.9, 0.7, 0.8])\n",
        "            },\n",
        "            \"SALT Treaties 1972\": {\n",
        "                \"actors\": [\"USA\", \"CHN\"],\n",
        "                \"power_asymmetry\": 0.5, \"issue_salience\": 0.95, \"time_pressure\": 0.8,\n",
        "                \"outcome\": \"partial_success\", \"success_rate\": 0.68,\n",
        "                \"key_lesson\": \"Verification mechanisms critical for trust\",\n",
        "                \"features\": np.array([0.5, 0.95, 0.8, 0.7])\n",
        "            },\n",
        "            \"Paris Climate Agreement 2015\": {\n",
        "                \"actors\": [\"USA\", \"GBR\", \"CHN\", \"IND\", \"BRA\"],\n",
        "                \"power_asymmetry\": 0.7, \"issue_salience\": 0.85, \"time_pressure\": 0.6,\n",
        "                \"outcome\": \"success\", \"success_rate\": 0.82,\n",
        "                \"key_lesson\": \"Nationally determined contributions enabled consensus\",\n",
        "                \"features\": np.array([0.7, 0.85, 0.6, 0.75])\n",
        "            },\n",
        "            \"Nuclear Non-Proliferation Treaty 1968\": {\n",
        "                \"actors\": [\"USA\", \"CHN\", \"GBR\", \"JPN\"],\n",
        "                \"power_asymmetry\": 0.8, \"issue_salience\": 0.95, \"time_pressure\": 0.85,\n",
        "                \"outcome\": \"success\", \"success_rate\": 0.88,\n",
        "                \"key_lesson\": \"Security guarantees essential for non-nuclear states\",\n",
        "                \"features\": np.array([0.8, 0.95, 0.85, 0.87])\n",
        "            },\n",
        "            \"Kyoto Protocol 1997\": {\n",
        "                \"actors\": [\"USA\", \"GBR\", \"JPN\", \"CHN\", \"IND\"],\n",
        "                \"power_asymmetry\": 0.65, \"issue_salience\": 0.80, \"time_pressure\": 0.70,\n",
        "                \"outcome\": \"partial_success\", \"success_rate\": 0.58,\n",
        "                \"key_lesson\": \"Binding targets without major emitters led to limited impact\",\n",
        "                \"features\": np.array([0.65, 0.80, 0.70, 0.68])\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Kalman filter states\n",
        "        self.kalman_states = {}\n",
        "\n",
        "    # =================================================================\n",
        "    # ENHANCEMENT 1: BAYESIAN UNCERTAINTY QUANTIFICATION\n",
        "    # =================================================================\n",
        "\n",
        "    def calculate_ethical_alignment_bayesian(self, country_iso3, policy_scenario):\n",
        "        \"\"\"Bayesian uncertainty quantification for ethical alignment\"\"\"\n",
        "        point_estimate = self.calculate_ethical_alignment(country_iso3, policy_scenario)\n",
        "        data_quality = self.data_quality.get(country_iso3, 0.5)\n",
        "\n",
        "        prior_variance = 0.05\n",
        "        posterior_std = np.sqrt(prior_variance / (1 + data_quality * 10))\n",
        "\n",
        "        ci_lower = max(0, point_estimate - 1.96 * posterior_std)\n",
        "        ci_upper = min(1, point_estimate + 1.96 * posterior_std)\n",
        "        reliability = 1 - posterior_std\n",
        "\n",
        "        return {\n",
        "            \"score\": point_estimate,\n",
        "            \"ci_lower\": round(ci_lower, 3),\n",
        "            \"ci_upper\": round(ci_upper, 3),\n",
        "            \"reliability\": round(reliability, 3),\n",
        "            \"std_dev\": round(posterior_std, 3)\n",
        "        }\n",
        "\n",
        "    # =================================================================\n",
        "    # ENHANCEMENT 2: CONVERGENCE PREDICTION\n",
        "    # =================================================================\n",
        "\n",
        "    def predict_convergence_timeline(self, country_a, country_b, policy):\n",
        "        \"\"\"Predict negotiation convergence timeline\"\"\"\n",
        "        ethical_a = self.calculate_ethical_alignment(country_a, policy)\n",
        "        ethical_b = self.calculate_ethical_alignment(country_b, policy)\n",
        "        ethical_gap = abs(ethical_a - ethical_b)\n",
        "\n",
        "        pattern_a = self.get_argumentation_pattern(country_a)\n",
        "        pattern_b = self.get_argumentation_pattern(country_b)\n",
        "\n",
        "        coop_a = pattern_a[\"consensus_tendency\"] * (1 - pattern_a[\"debate_intensity\"] * 0.5)\n",
        "        coop_b = pattern_b[\"consensus_tendency\"] * (1 - pattern_b[\"debate_intensity\"] * 0.5)\n",
        "        alpha = (coop_a + coop_b) / 2\n",
        "\n",
        "        threshold = 0.1\n",
        "\n",
        "        if ethical_gap < threshold:\n",
        "            rounds = 1\n",
        "            probability = 0.95\n",
        "        elif alpha < 0.3:\n",
        "            rounds = 99\n",
        "            probability = 0.15\n",
        "        else:\n",
        "            rounds = math.ceil(math.log(threshold / max(ethical_gap, 0.01)) / math.log(1 - alpha * 0.3))\n",
        "            rounds = min(rounds, 20)\n",
        "            probability = 1 - math.exp(-alpha * rounds * 0.15)\n",
        "\n",
        "        trajectory = []\n",
        "        current_gap = ethical_gap\n",
        "        for r in range(min(rounds, 15)):\n",
        "            current_gap = current_gap * (1 - alpha * 0.3)\n",
        "            trajectory.append({\n",
        "                \"round\": r + 1,\n",
        "                \"gap\": round(current_gap, 3),\n",
        "                \"position_a\": round(ethical_a + (ethical_b - ethical_a) * (1 - current_gap/ethical_gap) * 0.5, 3),\n",
        "                \"position_b\": round(ethical_b - (ethical_b - ethical_a) * (1 - current_gap/ethical_gap) * 0.5, 3)\n",
        "            })\n",
        "\n",
        "        return {\n",
        "            \"expected_rounds\": rounds,\n",
        "            \"probability_success\": round(probability, 3),\n",
        "            \"initial_gap\": round(ethical_gap, 3),\n",
        "            \"convergence_rate\": round(alpha, 3),\n",
        "            \"trajectory\": trajectory\n",
        "        }\n",
        "\n",
        "    # =================================================================\n",
        "    # ENHANCEMENT 3: HIERARCHICAL CAPABILITY GAP ANALYSIS\n",
        "    # =================================================================\n",
        "\n",
        "    def diagnose_capability_gap(self, country_iso3, target_gwc=0.8):\n",
        "        \"\"\"Hierarchical capability gap diagnosis\"\"\"\n",
        "        oecd = self.get_oecd_compliance(country_iso3)\n",
        "        privacy = self.get_privacy_score(country_iso3)\n",
        "        pattern = self.get_argumentation_pattern(country_iso3)\n",
        "\n",
        "        current_gwc = (oecd[\"implementation_score\"] * 0.4 +\n",
        "                      privacy[\"overall\"] * 0.3 +\n",
        "                      pattern[\"consensus_tendency\"] * 0.3)\n",
        "\n",
        "        gap = target_gwc - current_gwc\n",
        "\n",
        "        if gap <= 0:\n",
        "            return {\n",
        "                \"current_gwc\": round(current_gwc, 3),\n",
        "                \"target_gwc\": target_gwc,\n",
        "                \"gap\": 0,\n",
        "                \"status\": \"Target already achieved\",\n",
        "                \"priorities\": []\n",
        "            }\n",
        "\n",
        "        broad_capabilities = {\n",
        "            \"STI\": {\"score\": 0.70, \"weight\": 0.15, \"gap_contribution\": 0},\n",
        "            \"ESI\": {\"score\": 0.63, \"weight\": 0.18, \"gap_contribution\": 0},\n",
        "            \"IIC\": {\"score\": 0.64, \"weight\": 0.16, \"gap_contribution\": 0},\n",
        "            \"NDM\": {\"score\": 0.68, \"weight\": 0.15, \"gap_contribution\": 0},\n",
        "            \"SRA\": {\"score\": 0.72, \"weight\": 0.14, \"gap_contribution\": 0},\n",
        "            \"SAD\": {\"score\": 0.66, \"weight\": 0.12, \"gap_contribution\": 0},\n",
        "            \"ASI\": {\"score\": 0.69, \"weight\": 0.10, \"gap_contribution\": 0}\n",
        "        }\n",
        "\n",
        "        for bgc_name, bgc_data in broad_capabilities.items():\n",
        "            bgc_gap = (target_gwc * bgc_data[\"weight\"]) - (bgc_data[\"score\"] * bgc_data[\"weight\"])\n",
        "            bgc_data[\"gap_contribution\"] = bgc_gap / gap if gap > 0 else 0\n",
        "\n",
        "        sorted_capabilities = sorted(broad_capabilities.items(),\n",
        "                                    key=lambda x: x[1][\"gap_contribution\"],\n",
        "                                    reverse=True)\n",
        "\n",
        "        priorities = []\n",
        "        for i, (bgc_name, bgc_data) in enumerate(sorted_capabilities[:3]):\n",
        "            if bgc_name in self.narrow_factors:\n",
        "                narrow = self.narrow_factors[bgc_name]\n",
        "                sorted_narrow = sorted(narrow.items(), key=lambda x: x[1])\n",
        "                priorities.append({\n",
        "                    \"capability\": bgc_name,\n",
        "                    \"current_score\": round(bgc_data[\"score\"], 3),\n",
        "                    \"gap_contribution\": round(bgc_data[\"gap_contribution\"] * 100, 1),\n",
        "                    \"investment_priority\": i + 1,\n",
        "                    \"limiting_factors\": [{\"factor\": k, \"score\": round(v, 3)}\n",
        "                                       for k, v in sorted_narrow[:2]]\n",
        "                })\n",
        "\n",
        "        return {\n",
        "            \"current_gwc\": round(current_gwc, 3),\n",
        "            \"target_gwc\": target_gwc,\n",
        "            \"gap\": round(gap, 3),\n",
        "            \"status\": \"Capacity building needed\",\n",
        "            \"priorities\": priorities\n",
        "        }\n",
        "\n",
        "    # =================================================================\n",
        "    # ENHANCEMENT 4: MULTI-OBJECTIVE PARETO OPTIMIZATION\n",
        "    # =================================================================\n",
        "\n",
        "    def compute_pareto_scenarios(self, country_a, country_b, policy_options):\n",
        "        \"\"\"Multi-objective Pareto optimization\"\"\"\n",
        "        scenarios = []\n",
        "\n",
        "        for policy in policy_options:\n",
        "            ethical_a = self.calculate_ethical_alignment(country_a, policy)\n",
        "            ethical_b = self.calculate_ethical_alignment(country_b, policy)\n",
        "            privacy_a = self.get_privacy_score(country_a)[\"overall\"]\n",
        "            privacy_b = self.get_privacy_score(country_b)[\"overall\"]\n",
        "            pattern_a = self.get_argumentation_pattern(country_a)\n",
        "            pattern_b = self.get_argumentation_pattern(country_b)\n",
        "\n",
        "            avg_ethical = (ethical_a + ethical_b) / 2\n",
        "            avg_privacy = (privacy_a + privacy_b) / 2\n",
        "            speed = (pattern_a[\"consensus_tendency\"] + pattern_b[\"consensus_tendency\"]) / 2\n",
        "            innovation = 1 - abs(ethical_a - ethical_b)\n",
        "\n",
        "            scenarios.append({\n",
        "                \"policy\": policy,\n",
        "                \"ethical_alignment\": round(avg_ethical, 3),\n",
        "                \"privacy_protection\": round(avg_privacy, 3),\n",
        "                \"speed_to_agreement\": round(speed, 3),\n",
        "                \"innovation_potential\": round(innovation, 3),\n",
        "                \"composite_score\": round((avg_ethical + avg_privacy + speed + innovation) / 4, 3)\n",
        "            })\n",
        "\n",
        "        # Identify Pareto optimal scenarios\n",
        "        pareto_optimal = []\n",
        "        for s1 in scenarios:\n",
        "            dominated = False\n",
        "            for s2 in scenarios:\n",
        "                if (s2[\"ethical_alignment\"] >= s1[\"ethical_alignment\"] and\n",
        "                    s2[\"privacy_protection\"] >= s1[\"privacy_protection\"] and\n",
        "                    s2[\"speed_to_agreement\"] >= s1[\"speed_to_agreement\"] and\n",
        "                    s2[\"innovation_potential\"] >= s1[\"innovation_potential\"] and\n",
        "                    (s2[\"ethical_alignment\"] > s1[\"ethical_alignment\"] or\n",
        "                     s2[\"privacy_protection\"] > s1[\"privacy_protection\"] or\n",
        "                     s2[\"speed_to_agreement\"] > s1[\"speed_to_agreement\"] or\n",
        "                     s2[\"innovation_potential\"] > s1[\"innovation_potential\"])):\n",
        "                    dominated = True\n",
        "                    break\n",
        "            if not dominated:\n",
        "                pareto_optimal.append(s1)\n",
        "\n",
        "        return {\n",
        "            \"all_scenarios\": scenarios,\n",
        "            \"pareto_optimal\": pareto_optimal,\n",
        "            \"num_pareto\": len(pareto_optimal),\n",
        "            \"recommendation\": max(pareto_optimal, key=lambda x: x[\"composite_score\"]) if pareto_optimal else scenarios[0]\n",
        "        }\n",
        "\n",
        "    # =================================================================\n",
        "    # ENHANCEMENT 5: NETWORK DIFFUSION SIMULATION\n",
        "    # =================================================================\n",
        "\n",
        "    def simulate_policy_diffusion(self, initial_adopters, policy, rounds=10, influence_strength=0.3):\n",
        "        \"\"\"Simulate policy diffusion through influence networks\"\"\"\n",
        "        countries = list(self.oecd_adoption.keys())\n",
        "        adoption_state = {c: 1.0 if c in initial_adopters else 0.0 for c in countries}\n",
        "\n",
        "        # Build influence matrix\n",
        "        W = np.zeros((len(countries), len(countries)))\n",
        "        country_idx = {c: i for i, c in enumerate(countries)}\n",
        "\n",
        "        for src in countries:\n",
        "            if src in self.influence_network:\n",
        "                for tgt, weight in self.influence_network[src].items():\n",
        "                    if tgt in country_idx:\n",
        "                        W[country_idx[src], country_idx[tgt]] = weight\n",
        "\n",
        "        # Normalize rows\n",
        "        row_sums = W.sum(axis=1, keepdims=True)\n",
        "        row_sums[row_sums == 0] = 1\n",
        "        W = W / row_sums\n",
        "\n",
        "        trajectory = [adoption_state.copy()]\n",
        "\n",
        "        for t in range(rounds):\n",
        "            x = np.array([adoption_state[c] for c in countries])\n",
        "            x_new = (1 - influence_strength) * x + influence_strength * (W @ x)\n",
        "            x_new = np.clip(x_new, 0, 1)\n",
        "            adoption_state = {c: x_new[i] for i, c in enumerate(countries)}\n",
        "            trajectory.append(adoption_state.copy())\n",
        "\n",
        "        # Identify tipping points\n",
        "        tipping_rounds = {}\n",
        "        for c in countries:\n",
        "            for r, state in enumerate(trajectory):\n",
        "                if state[c] > 0.5 and c not in initial_adopters:\n",
        "                    tipping_rounds[c] = r\n",
        "                    break\n",
        "\n",
        "        return {\n",
        "            \"trajectory\": trajectory,\n",
        "            \"tipping_rounds\": tipping_rounds,\n",
        "            \"final_adoption\": {c: round(trajectory[-1][c], 3) for c in countries},\n",
        "            \"cascade_probability\": sum(1 for v in trajectory[-1].values() if v > 0.7) / len(countries)\n",
        "        }\n",
        "\n",
        "    # =================================================================\n",
        "    # ENHANCEMENT 6: HISTORICAL PATTERN MATCHING\n",
        "    # =================================================================\n",
        "\n",
        "    def match_historical_scenarios(self, current_actors, power_asymmetry, issue_salience, time_pressure):\n",
        "        \"\"\"Match current scenario to historical precedents\"\"\"\n",
        "        current_features = np.array([\n",
        "            power_asymmetry,\n",
        "            issue_salience,\n",
        "            time_pressure,\n",
        "            (power_asymmetry + issue_salience) / 2\n",
        "        ])\n",
        "\n",
        "        matches = []\n",
        "        for scenario_name, scenario_data in self.historical_scenarios.items():\n",
        "            similarity = cosine_similarity([current_features], [scenario_data[\"features\"]])[0][0]\n",
        "            actor_overlap = len(set(current_actors) & set(scenario_data[\"actors\"])) / len(set(current_actors) | set(scenario_data[\"actors\"]))\n",
        "            relevance = similarity * 0.7 + actor_overlap * 0.3\n",
        "\n",
        "            matches.append({\n",
        "                \"scenario\": scenario_name,\n",
        "                \"similarity\": round(similarity, 3),\n",
        "                \"relevance\": round(relevance, 3),\n",
        "                \"outcome\": scenario_data[\"outcome\"],\n",
        "                \"success_rate\": scenario_data[\"success_rate\"],\n",
        "                \"key_lesson\": scenario_data[\"key_lesson\"],\n",
        "                \"actors\": scenario_data[\"actors\"]\n",
        "            })\n",
        "\n",
        "        matches.sort(key=lambda x: x[\"relevance\"], reverse=True)\n",
        "        return matches\n",
        "\n",
        "    # =================================================================\n",
        "    # ENHANCEMENT 7: MATURITY TRAJECTORY PLANNING\n",
        "    # =================================================================\n",
        "\n",
        "    def calculate_maturity_trajectory(self, country_iso3, target_level=4, investment_per_month=1.0, months=24):\n",
        "        \"\"\"Calculate capability maturity growth trajectory\"\"\"\n",
        "        current_gwc = self.diagnose_capability_gap(country_iso3, 0.8)[\"current_gwc\"]\n",
        "\n",
        "        def gwc_to_maturity(gwc):\n",
        "            if gwc < 0.4: return 1\n",
        "            elif gwc < 0.6: return 2\n",
        "            elif gwc < 0.75: return 3\n",
        "            else: return 4\n",
        "\n",
        "        current_maturity = gwc_to_maturity(current_gwc)\n",
        "        M_max = 4\n",
        "        rho = 0.05  # Natural growth rate\n",
        "\n",
        "        trajectory = []\n",
        "        M = current_maturity\n",
        "\n",
        "        for month in range(months):\n",
        "            intervention_effect = investment_per_month * 0.01\n",
        "            dM = rho * M * (1 - M / M_max) + intervention_effect\n",
        "            M = min(M + dM, M_max)\n",
        "\n",
        "            trajectory.append({\n",
        "                \"month\": month + 1,\n",
        "                \"maturity\": round(M, 2),\n",
        "                \"gwc_equivalent\": round(M / M_max, 3)\n",
        "            })\n",
        "\n",
        "            if M >= target_level:\n",
        "                break\n",
        "\n",
        "        months_to_target = next((t[\"month\"] for t in trajectory if t[\"maturity\"] >= target_level), months)\n",
        "        total_investment = months_to_target * investment_per_month\n",
        "\n",
        "        return {\n",
        "            \"current_maturity\": current_maturity,\n",
        "            \"target_maturity\": target_level,\n",
        "            \"trajectory\": trajectory,\n",
        "            \"months_to_target\": months_to_target,\n",
        "            \"total_investment_required\": round(total_investment, 2),\n",
        "            \"critical_milestone_month\": int(months_to_target * 0.6)\n",
        "        }\n",
        "\n",
        "    # =================================================================\n",
        "    # ENHANCEMENT 8: KALMAN FILTER TRACKING\n",
        "    # =================================================================\n",
        "\n",
        "    def initialize_kalman_filter(self, country_iso3):\n",
        "        \"\"\"Initialize Kalman filter for capability tracking\"\"\"\n",
        "        current_gwc = self.diagnose_capability_gap(country_iso3, 0.8)[\"current_gwc\"]\n",
        "        self.kalman_states[country_iso3] = {\n",
        "            \"x_hat\": current_gwc,\n",
        "            \"P\": 0.1,\n",
        "            \"Q\": 0.01,\n",
        "            \"R\": 0.05,\n",
        "            \"history\": [(0, current_gwc, 0.1)]\n",
        "        }\n",
        "\n",
        "    def kalman_update(self, country_iso3, new_measurement, intervention_effect=0.0):\n",
        "        \"\"\"Update Kalman filter with new measurement\"\"\"\n",
        "        if country_iso3 not in self.kalman_states:\n",
        "            self.initialize_kalman_filter(country_iso3)\n",
        "\n",
        "        state = self.kalman_states[country_iso3]\n",
        "\n",
        "        # Prediction\n",
        "        A = 1.0\n",
        "        B = 0.1\n",
        "        x_pred = A * state[\"x_hat\"] + B * intervention_effect\n",
        "        P_pred = A * state[\"P\"] * A + state[\"Q\"]\n",
        "\n",
        "        # Update\n",
        "        C = 1.0\n",
        "        K = P_pred * C / (C * P_pred * C + state[\"R\"])\n",
        "        x_hat_new = x_pred + K * (new_measurement - C * x_pred)\n",
        "        P_new = (1 - K * C) * P_pred\n",
        "\n",
        "        state[\"x_hat\"] = x_hat_new\n",
        "        state[\"P\"] = P_new\n",
        "        state[\"history\"].append((len(state[\"history\"]), x_hat_new, P_new))\n",
        "\n",
        "        return {\n",
        "            \"smoothed_estimate\": round(x_hat_new, 3),\n",
        "            \"uncertainty\": round(P_new, 3),\n",
        "            \"confidence\": round((1 - P_new) * 100, 1)\n",
        "        }\n",
        "\n",
        "    # =================================================================\n",
        "    # ENHANCEMENT 9: RL-OPTIMIZED NEGOTIATION STRATEGIES\n",
        "    # =================================================================\n",
        "\n",
        "    def optimize_negotiation_strategy(self, country_a, country_b, policy, num_simulations=100):\n",
        "        \"\"\"RL-based negotiation strategy optimization\"\"\"\n",
        "        actions = [\"propose_ambitious\", \"make_concession\", \"threaten\", \"delay\", \"build_coalition\"]\n",
        "        Q = {action: 0.0 for action in actions}\n",
        "        visits = {action: 0 for action in actions}\n",
        "\n",
        "        def simulate_action_outcome(action, ethical_gap, trust_level):\n",
        "            if action == \"propose_ambitious\":\n",
        "                reward = 0.8 * trust_level if ethical_gap < 0.3 else -0.2\n",
        "            elif action == \"make_concession\":\n",
        "                reward = 0.6 + (1 - ethical_gap) * 0.3\n",
        "            elif action == \"threaten\":\n",
        "                reward = -0.3 if trust_level > 0.5 else 0.2\n",
        "            elif action == \"delay\":\n",
        "                reward = -0.1 if ethical_gap < 0.2 else 0.3\n",
        "            else:  # build_coalition\n",
        "                reward = 0.7 if ethical_gap > 0.4 else 0.4\n",
        "\n",
        "            return reward + np.random.normal(0, 0.1)\n",
        "\n",
        "        ethical_gap = abs(\n",
        "            self.calculate_ethical_alignment(country_a, policy) -\n",
        "            self.calculate_ethical_alignment(country_b, policy)\n",
        "        )\n",
        "        trust_level = (\n",
        "            self.get_argumentation_pattern(country_a)[\"consensus_tendency\"] +\n",
        "            self.get_argumentation_pattern(country_b)[\"consensus_tendency\"]\n",
        "        ) / 2\n",
        "\n",
        "        for _ in range(num_simulations):\n",
        "            for action in actions:\n",
        "                reward = simulate_action_outcome(action, ethical_gap, trust_level)\n",
        "                visits[action] += 1\n",
        "                Q[action] = Q[action] + (reward - Q[action]) / visits[action]\n",
        "\n",
        "        sorted_actions = sorted(Q.items(), key=lambda x: x[1], reverse=True)\n",
        "        expected_outcome = max(Q.values()) * 0.7 + 0.3\n",
        "\n",
        "        return {\n",
        "            \"optimal_action_sequence\": [a[0] for a in sorted_actions[:3]],\n",
        "            \"q_values\": {k: round(v, 3) for k, v in Q.items()},\n",
        "            \"expected_agreement_probability\": round(min(expected_outcome, 0.95), 3),\n",
        "            \"recommended_first_move\": sorted_actions[0][0],\n",
        "            \"explanation\": self._explain_strategy(sorted_actions[0][0])\n",
        "        }\n",
        "\n",
        "    def _explain_strategy(self, action):\n",
        "        \"\"\"Explain negotiation strategy\"\"\"\n",
        "        explanations = {\n",
        "            \"propose_ambitious\": \"Open with bold framework to anchor expectations\",\n",
        "            \"make_concession\": \"Build goodwill early to accelerate trust-building\",\n",
        "            \"threaten\": \"Signal resolve on non-negotiable issues\",\n",
        "            \"delay\": \"Buy time for coalition formation and position refinement\",\n",
        "            \"build_coalition\": \"Secure third-party support to increase leverage\"\n",
        "        }\n",
        "        return explanations.get(action, \"Strategic positioning move\")\n",
        "\n",
        "    # =================================================================\n",
        "    # HELPER METHODS\n",
        "    # =================================================================\n",
        "\n",
        "    def calculate_ethical_alignment(self, country_iso3, policy_scenario):\n",
        "        \"\"\"Calculate ethical alignment score\"\"\"\n",
        "        oecd = self.get_oecd_compliance(country_iso3)\n",
        "        privacy = self.get_privacy_score(country_iso3)\n",
        "\n",
        "        scenario_weights = {\n",
        "            \"AI Ethics\": {\"oecd\": 0.6, \"privacy\": 0.4},\n",
        "            \"AI Safety\": {\"oecd\": 0.7, \"privacy\": 0.3},\n",
        "            \"Data Privacy\": {\"oecd\": 0.3, \"privacy\": 0.7},\n",
        "            \"Export Controls\": {\"oecd\": 0.5, \"privacy\": 0.5},\n",
        "            \"R&D Investment\": {\"oecd\": 0.8, \"privacy\": 0.2}\n",
        "        }\n",
        "\n",
        "        weights = scenario_weights.get(policy_scenario, {\"oecd\": 0.5, \"privacy\": 0.5})\n",
        "        oecd_score = (oecd[\"adoption_level\"] + oecd[\"implementation_score\"]) / 2\n",
        "        privacy_score = privacy[\"overall\"]\n",
        "\n",
        "        ethical_alignment = (oecd_score * weights[\"oecd\"]) + (privacy_score * weights[\"privacy\"])\n",
        "        return round(ethical_alignment, 3)\n",
        "\n",
        "    def get_oecd_principles(self):\n",
        "        return self.oecd_principles\n",
        "\n",
        "    def get_oecd_compliance(self, country_iso3):\n",
        "        return self.oecd_adoption.get(country_iso3, {\n",
        "            \"adoption_level\": 0.50,\n",
        "            \"implementation_score\": 0.45,\n",
        "            \"signatory\": False\n",
        "        })\n",
        "\n",
        "    def get_privacy_score(self, country_iso3):\n",
        "        return self.privacy_scores.get(country_iso3, {\n",
        "            \"legal_framework\": 0.50,\n",
        "            \"enforcement\": 0.50,\n",
        "            \"surveillance_concerns\": 0.50,\n",
        "            \"data_protection\": 0.50,\n",
        "            \"overall\": 0.50\n",
        "        })\n",
        "\n",
        "    def get_argumentation_pattern(self, country_iso3):\n",
        "        return self.argumentation_patterns.get(country_iso3, {\n",
        "            \"primary_frame\": \"Balanced Approach\",\n",
        "            \"secondary_frame\": \"Public Interest\",\n",
        "            \"rhetoric_style\": \"neutral\",\n",
        "            \"consensus_tendency\": 0.65,\n",
        "            \"debate_intensity\": 0.60\n",
        "        })\n",
        "\n",
        "@st.cache_resource\n",
        "def get_bach_api_client():\n",
        "    return BachGovernanceAPI()\n",
        "'''\n",
        "\n",
        "with open('bach_api_utils.py', 'w') as f:\n",
        "    f.write(bach_api_utils_content)\n",
        "\n",
        "print(\"âœ… Complete Mathematical Intelligence Suite API created (9 enhancements)\")\n",
        "\n",
        "# =============================================================================\n",
        "# CREATE COGNITIVE ARCHITECTURE MODULES\n",
        "# =============================================================================\n",
        "\n",
        "moral_foundations_content = r'''\"\"\"\n",
        "Moral Foundations Module for Auracelle Bach\n",
        "============================================\n",
        "\n",
        "Implements Haidt's Moral Foundations Theory for AI governance policy evaluation.\n",
        "Provides computational framework for value-weighted decision-making in multi-agent\n",
        "governance simulations.\n",
        "\n",
        "Based on:\n",
        "- Haidt, J. (2012). The Righteous Mind\n",
        "- Graham et al. (2013). Moral Foundations Theory\n",
        "- Evans AGPO Framework mathematical formalization\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from dataclasses import dataclass, field\n",
        "from enum import Enum\n",
        "import json\n",
        "\n",
        "\n",
        "class FoundationType(Enum):\n",
        "    \"\"\"Five moral foundations from Haidt's theory\"\"\"\n",
        "    CARE_HARM = \"care_harm\"\n",
        "    FAIRNESS_CHEATING = \"fairness_cheating\"\n",
        "    LOYALTY_BETRAYAL = \"loyalty_betrayal\"\n",
        "    AUTHORITY_SUBVERSION = \"authority_subversion\"\n",
        "    SANCTITY_DEGRADATION = \"sanctity_degradation\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PolicyFeatures:\n",
        "    \"\"\"\n",
        "    Structured representation of AI governance policy characteristics\n",
        "    for moral evaluation\n",
        "    \"\"\"\n",
        "    # Core policy attributes\n",
        "    policy_id: str\n",
        "    policy_name: str\n",
        "    policy_type: str  # 'regulation', 'standard', 'mandate', 'incentive'\n",
        "\n",
        "    # Care/Harm dimensions\n",
        "    safety_requirements: float = 0.5  # [0,1] strength of safety provisions\n",
        "    harm_prevention: float = 0.5      # [0,1] explicit harm mitigation\n",
        "    vulnerable_protection: float = 0.5 # [0,1] protections for vulnerable groups\n",
        "    privacy_safeguards: float = 0.5   # [0,1] privacy protection level\n",
        "\n",
        "    # Fairness dimensions\n",
        "    equity_provisions: float = 0.5     # [0,1] distributional fairness\n",
        "    procedural_fairness: float = 0.5   # [0,1] transparent/accountable process\n",
        "    access_equality: float = 0.5       # [0,1] equal access to benefits\n",
        "    small_actor_burden: float = 0.5    # [0,1] disproportionate impact on small players\n",
        "\n",
        "    # Loyalty dimensions\n",
        "    national_advantage: float = 0.5    # [0,1] benefit to domestic industry\n",
        "    competitiveness_impact: float = 0.5 # [0,1] effect on international position\n",
        "    cross_border_cooperation: float = 0.5 # [0,1] promotes international alignment\n",
        "    ingroup_solidarity: float = 0.5    # [0,1] strengthens community bonds\n",
        "\n",
        "    # Authority dimensions\n",
        "    institutional_clarity: float = 0.5  # [0,1] clear governance structure\n",
        "    regulatory_strength: float = 0.5    # [0,1] enforcement capability\n",
        "    precedent_alignment: float = 0.5    # [0,1] consistency with existing law\n",
        "    expert_deference: float = 0.5       # [0,1] respects technical expertise\n",
        "\n",
        "    # Sanctity dimensions\n",
        "    human_dignity: float = 0.5          # [0,1] preserves human autonomy\n",
        "    privacy_sanctity: float = 0.5       # [0,1] treats privacy as inviolable\n",
        "    transparency_norms: float = 0.5     # [0,1] upholds democratic values\n",
        "    manipulation_prevention: float = 0.5 # [0,1] prevents behavioral exploitation\n",
        "\n",
        "    # Meta-attributes\n",
        "    implementation_cost: float = 0.5    # [0,1] economic burden\n",
        "    innovation_impact: float = 0.5      # [0,1] effect on AI development\n",
        "    enforcement_difficulty: float = 0.5 # [0,1] practical implementability\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MoralFoundations:\n",
        "    \"\"\"\n",
        "    Agent's moral foundation weights\n",
        "    Determines how strongly each moral dimension influences decision-making\n",
        "    \"\"\"\n",
        "    care_harm: float = 0.2            # Weight on preventing suffering\n",
        "    fairness_cheating: float = 0.2    # Weight on justice/equity\n",
        "    loyalty_betrayal: float = 0.2     # Weight on group solidarity\n",
        "    authority_subversion: float = 0.2 # Weight on institutional order\n",
        "    sanctity_degradation: float = 0.2 # Weight on human dignity/purity\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Normalize weights to sum to 1.0\"\"\"\n",
        "        total = (self.care_harm + self.fairness_cheating +\n",
        "                self.loyalty_betrayal + self.authority_subversion +\n",
        "                self.sanctity_degradation)\n",
        "        if total > 0:\n",
        "            self.care_harm /= total\n",
        "            self.fairness_cheating /= total\n",
        "            self.loyalty_betrayal /= total\n",
        "            self.authority_subversion /= total\n",
        "            self.sanctity_degradation /= total\n",
        "\n",
        "    def to_dict(self) -> Dict[str, float]:\n",
        "        \"\"\"Convert to dictionary for serialization\"\"\"\n",
        "        return {\n",
        "            'care_harm': self.care_harm,\n",
        "            'fairness_cheating': self.fairness_cheating,\n",
        "            'loyalty_betrayal': self.loyalty_betrayal,\n",
        "            'authority_subversion': self.authority_subversion,\n",
        "            'sanctity_degradation': self.sanctity_degradation\n",
        "        }\n",
        "\n",
        "    def distance_to(self, other: 'MoralFoundations') -> float:\n",
        "        \"\"\"\n",
        "        Compute moral distance between two foundation profiles\n",
        "        Used for modeling value similarity between agents\n",
        "        \"\"\"\n",
        "        return np.sqrt(\n",
        "            (self.care_harm - other.care_harm) ** 2 +\n",
        "            (self.fairness_cheating - other.fairness_cheating) ** 2 +\n",
        "            (self.loyalty_betrayal - other.loyalty_betrayal) ** 2 +\n",
        "            (self.authority_subversion - other.authority_subversion) ** 2 +\n",
        "            (self.sanctity_degradation - other.sanctity_degradation) ** 2\n",
        "        )\n",
        "\n",
        "\n",
        "class MoralEvaluator:\n",
        "    \"\"\"\n",
        "    Core moral evaluation engine\n",
        "    Computes moral valence of policies across all five foundations\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, scenario_context: str = \"general\"):\n",
        "        \"\"\"\n",
        "        Initialize evaluator with scenario-specific calibration\n",
        "\n",
        "        Args:\n",
        "            scenario_context: 'data_privacy', 'ethics_board', 'transparency', 'general'\n",
        "        \"\"\"\n",
        "        self.scenario_context = scenario_context\n",
        "        self.harm_weights = self._initialize_harm_weights()\n",
        "        self.fairness_weights = self._initialize_fairness_weights()\n",
        "        self.loyalty_weights = self._initialize_loyalty_weights()\n",
        "        self.authority_weights = self._initialize_authority_weights()\n",
        "        self.sanctity_weights = self._initialize_sanctity_weights()\n",
        "\n",
        "    def _initialize_harm_weights(self) -> Dict[str, float]:\n",
        "        \"\"\"Scenario-specific weights for harm evaluation\"\"\"\n",
        "        base_weights = {\n",
        "            'safety': 0.30,\n",
        "            'privacy': 0.25,\n",
        "            'vulnerable_protection': 0.25,\n",
        "            'harm_prevention': 0.20\n",
        "        }\n",
        "\n",
        "        # Adjust for scenario\n",
        "        if self.scenario_context == \"data_privacy\":\n",
        "            base_weights['privacy'] = 0.40\n",
        "            base_weights['safety'] = 0.20\n",
        "        elif self.scenario_context == \"ethics_board\":\n",
        "            base_weights['vulnerable_protection'] = 0.35\n",
        "            base_weights['harm_prevention'] = 0.30\n",
        "\n",
        "        return base_weights\n",
        "\n",
        "    def _initialize_fairness_weights(self) -> Dict[str, float]:\n",
        "        \"\"\"Scenario-specific weights for fairness evaluation\"\"\"\n",
        "        base_weights = {\n",
        "            'equity': 0.30,\n",
        "            'procedural': 0.30,\n",
        "            'access': 0.25,\n",
        "            'burden_distribution': 0.15\n",
        "        }\n",
        "\n",
        "        if self.scenario_context == \"ethics_board\":\n",
        "            base_weights['procedural'] = 0.40\n",
        "            base_weights['equity'] = 0.35\n",
        "        elif self.scenario_context == \"transparency\":\n",
        "            base_weights['procedural'] = 0.45\n",
        "            base_weights['access'] = 0.30\n",
        "\n",
        "        return base_weights\n",
        "\n",
        "    def _initialize_loyalty_weights(self) -> Dict[str, float]:\n",
        "        \"\"\"Scenario-specific weights for loyalty evaluation\"\"\"\n",
        "        return {\n",
        "            'national_interest': 0.35,\n",
        "            'competitiveness': 0.30,\n",
        "            'cooperation': 0.20,\n",
        "            'solidarity': 0.15\n",
        "        }\n",
        "\n",
        "    def _initialize_authority_weights(self) -> Dict[str, float]:\n",
        "        \"\"\"Scenario-specific weights for authority evaluation\"\"\"\n",
        "        return {\n",
        "            'institutional_clarity': 0.30,\n",
        "            'enforcement': 0.25,\n",
        "            'precedent': 0.25,\n",
        "            'expertise': 0.20\n",
        "        }\n",
        "\n",
        "    def _initialize_sanctity_weights(self) -> Dict[str, float]:\n",
        "        \"\"\"Scenario-specific weights for sanctity evaluation\"\"\"\n",
        "        base_weights = {\n",
        "            'human_dignity': 0.35,\n",
        "            'privacy_sanctity': 0.30,\n",
        "            'transparency_norms': 0.20,\n",
        "            'manipulation_prevention': 0.15\n",
        "        }\n",
        "\n",
        "        if self.scenario_context == \"data_privacy\":\n",
        "            base_weights['privacy_sanctity'] = 0.45\n",
        "            base_weights['human_dignity'] = 0.30\n",
        "\n",
        "        return base_weights\n",
        "\n",
        "    def evaluate_care_harm(self, policy: PolicyFeatures) -> float:\n",
        "        \"\"\"\n",
        "        Evaluate policy on Care/Harm foundation\n",
        "\n",
        "        Higher scores = more protective of wellbeing, less harmful\n",
        "        Range: [-1, 1]\n",
        "        \"\"\"\n",
        "        # Positive contributions (care)\n",
        "        care_score = (\n",
        "            self.harm_weights['safety'] * policy.safety_requirements +\n",
        "            self.harm_weights['privacy'] * policy.privacy_safeguards +\n",
        "            self.harm_weights['vulnerable_protection'] * policy.vulnerable_protection +\n",
        "            self.harm_weights['harm_prevention'] * policy.harm_prevention\n",
        "        )\n",
        "\n",
        "        # Negative contributions (potential harms from regulation itself)\n",
        "        regulatory_harm = (\n",
        "            0.3 * policy.implementation_cost +  # Economic harm\n",
        "            0.2 * policy.enforcement_difficulty  # Compliance burden\n",
        "        )\n",
        "\n",
        "        net_score = care_score - 0.3 * regulatory_harm\n",
        "\n",
        "        return np.clip(2 * net_score - 1, -1, 1)  # Normalize to [-1, 1]\n",
        "\n",
        "    def evaluate_fairness_cheating(self, policy: PolicyFeatures) -> float:\n",
        "        \"\"\"\n",
        "        Evaluate policy on Fairness/Cheating foundation\n",
        "\n",
        "        Higher scores = more fair, equitable, just\n",
        "        Range: [-1, 1]\n",
        "        \"\"\"\n",
        "        # Positive contributions (fairness)\n",
        "        fairness_score = (\n",
        "            self.fairness_weights['equity'] * policy.equity_provisions +\n",
        "            self.fairness_weights['procedural'] * policy.procedural_fairness +\n",
        "            self.fairness_weights['access'] * policy.access_equality\n",
        "        )\n",
        "\n",
        "        # Negative contributions (unfairness)\n",
        "        unfairness_penalty = (\n",
        "            self.fairness_weights['burden_distribution'] *\n",
        "            policy.small_actor_burden  # Disproportionate burden is unfair\n",
        "        )\n",
        "\n",
        "        net_score = fairness_score - unfairness_penalty\n",
        "\n",
        "        return np.clip(2 * net_score - 1, -1, 1)\n",
        "\n",
        "    def evaluate_loyalty_betrayal(self, policy: PolicyFeatures) -> float:\n",
        "        \"\"\"\n",
        "        Evaluate policy on Loyalty/Betrayal foundation\n",
        "\n",
        "        Higher scores = strengthens ingroup, protects national interests\n",
        "        Range: [-1, 1]\n",
        "        \"\"\"\n",
        "        loyalty_score = (\n",
        "            self.loyalty_weights['national_interest'] * policy.national_advantage +\n",
        "            self.loyalty_weights['competitiveness'] * (1 - policy.competitiveness_impact) +\n",
        "            self.loyalty_weights['cooperation'] * policy.cross_border_cooperation +\n",
        "            self.loyalty_weights['solidarity'] * policy.ingroup_solidarity\n",
        "        )\n",
        "\n",
        "        # Note: competitiveness_impact represents harm to competitiveness, so we invert it\n",
        "\n",
        "        return np.clip(2 * loyalty_score - 1, -1, 1)\n",
        "\n",
        "    def evaluate_authority_subversion(self, policy: PolicyFeatures) -> float:\n",
        "        \"\"\"\n",
        "        Evaluate policy on Authority/Subversion foundation\n",
        "\n",
        "        Higher scores = strengthens legitimate authority, clear governance\n",
        "        Range: [-1, 1]\n",
        "        \"\"\"\n",
        "        authority_score = (\n",
        "            self.authority_weights['institutional_clarity'] * policy.institutional_clarity +\n",
        "            self.authority_weights['enforcement'] * policy.regulatory_strength +\n",
        "            self.authority_weights['precedent'] * policy.precedent_alignment +\n",
        "            self.authority_weights['expertise'] * policy.expert_deference\n",
        "        )\n",
        "\n",
        "        return np.clip(2 * authority_score - 1, -1, 1)\n",
        "\n",
        "    def evaluate_sanctity_degradation(self, policy: PolicyFeatures) -> float:\n",
        "        \"\"\"\n",
        "        Evaluate policy on Sanctity/Degradation foundation\n",
        "\n",
        "        Higher scores = protects human dignity, prevents degradation\n",
        "        Range: [-1, 1]\n",
        "        \"\"\"\n",
        "        sanctity_score = (\n",
        "            self.sanctity_weights['human_dignity'] * policy.human_dignity +\n",
        "            self.sanctity_weights['privacy_sanctity'] * policy.privacy_sanctity +\n",
        "            self.sanctity_weights['transparency_norms'] * policy.transparency_norms +\n",
        "            self.sanctity_weights['manipulation_prevention'] * policy.manipulation_prevention\n",
        "        )\n",
        "\n",
        "        return np.clip(2 * sanctity_score - 1, -1, 1)\n",
        "\n",
        "    def evaluate_all_foundations(self, policy: PolicyFeatures) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Compute moral evaluation across all five foundations\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping foundation names to scores [-1, 1]\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'care_harm': self.evaluate_care_harm(policy),\n",
        "            'fairness_cheating': self.evaluate_fairness_cheating(policy),\n",
        "            'loyalty_betrayal': self.evaluate_loyalty_betrayal(policy),\n",
        "            'authority_subversion': self.evaluate_authority_subversion(policy),\n",
        "            'sanctity_degradation': self.evaluate_sanctity_degradation(policy)\n",
        "        }\n",
        "\n",
        "    def compute_moral_value(self,\n",
        "                           policy: PolicyFeatures,\n",
        "                           agent_foundations: MoralFoundations) -> float:\n",
        "        \"\"\"\n",
        "        Compute overall moral value of policy for agent with specific foundation weights\n",
        "\n",
        "        This is the key function for value-weighted decision-making\n",
        "\n",
        "        Args:\n",
        "            policy: Policy to evaluate\n",
        "            agent_foundations: Agent's moral foundation weights\n",
        "\n",
        "        Returns:\n",
        "            Weighted moral value [-1, 1]\n",
        "        \"\"\"\n",
        "        foundation_scores = self.evaluate_all_foundations(policy)\n",
        "\n",
        "        moral_value = (\n",
        "            agent_foundations.care_harm * foundation_scores['care_harm'] +\n",
        "            agent_foundations.fairness_cheating * foundation_scores['fairness_cheating'] +\n",
        "            agent_foundations.loyalty_betrayal * foundation_scores['loyalty_betrayal'] +\n",
        "            agent_foundations.authority_subversion * foundation_scores['authority_subversion'] +\n",
        "            agent_foundations.sanctity_degradation * foundation_scores['sanctity_degradation']\n",
        "        )\n",
        "\n",
        "        return moral_value\n",
        "\n",
        "    def check_moral_constraints(self,\n",
        "                                policy: PolicyFeatures,\n",
        "                                agent_foundations: MoralFoundations,\n",
        "                                threshold: float = -0.5) -> Tuple[bool, List[str]]:\n",
        "        \"\"\"\n",
        "        Check if policy violates any moral hard constraints\n",
        "\n",
        "        Some agents may have deontological rules: certain foundations\n",
        "        must not fall below threshold (inadmissible actions)\n",
        "\n",
        "        Args:\n",
        "            policy: Policy to check\n",
        "            agent_foundations: Agent's moral weights\n",
        "            threshold: Minimum acceptable score for any strongly-weighted foundation\n",
        "\n",
        "        Returns:\n",
        "            (is_admissible, list_of_violations)\n",
        "        \"\"\"\n",
        "        foundation_scores = self.evaluate_all_foundations(policy)\n",
        "        violations = []\n",
        "\n",
        "        # Check if any strongly-weighted foundation is severely violated\n",
        "        for foundation_name, score in foundation_scores.items():\n",
        "            weight = getattr(agent_foundations, foundation_name)\n",
        "\n",
        "            # If agent weights this foundation highly (>0.25) and score is very negative\n",
        "            if weight > 0.25 and score < threshold:\n",
        "                violations.append(f\"{foundation_name}: {score:.2f} (threshold: {threshold})\")\n",
        "\n",
        "        is_admissible = len(violations) == 0\n",
        "        return is_admissible, violations\n",
        "\n",
        "\n",
        "class MoralExplainer:\n",
        "    \"\"\"\n",
        "    Generate human-readable explanations of moral evaluations\n",
        "    Crucial for interpretability in Cambridge research validation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, evaluator: MoralEvaluator):\n",
        "        self.evaluator = evaluator\n",
        "\n",
        "    def explain_evaluation(self,\n",
        "                          policy: PolicyFeatures,\n",
        "                          agent_foundations: MoralFoundations,\n",
        "                          agent_name: str = \"Agent\") -> str:\n",
        "        \"\"\"\n",
        "        Generate natural language explanation of why agent supports/opposes policy\n",
        "        \"\"\"\n",
        "        foundation_scores = self.evaluator.evaluate_all_foundations(policy)\n",
        "        moral_value = self.evaluator.compute_moral_value(policy, agent_foundations)\n",
        "\n",
        "        # Determine overall stance\n",
        "        if moral_value > 0.3:\n",
        "            stance = \"strongly supports\"\n",
        "        elif moral_value > 0:\n",
        "            stance = \"supports\"\n",
        "        elif moral_value > -0.3:\n",
        "            stance = \"opposes\"\n",
        "        else:\n",
        "            stance = \"strongly opposes\"\n",
        "\n",
        "        # Identify dominant foundation\n",
        "        weighted_scores = {\n",
        "            name: getattr(agent_foundations, name) * score\n",
        "            for name, score in foundation_scores.items()\n",
        "        }\n",
        "        dominant_foundation = max(weighted_scores, key=weighted_scores.get)\n",
        "        dominant_value = weighted_scores[dominant_foundation]\n",
        "\n",
        "        # Generate explanation\n",
        "        explanation = f\"\"\"\n",
        "{agent_name} {stance} \"{policy.policy_name}\" (Overall Moral Value: {moral_value:.2f})\n",
        "\n",
        "PRIMARY MORAL REASONING:\n",
        "{self._explain_foundation(dominant_foundation, foundation_scores[dominant_foundation], policy)}\n",
        "\n",
        "FOUNDATION BREAKDOWN:\n",
        "\"\"\"\n",
        "\n",
        "        for foundation_name, score in foundation_scores.items():\n",
        "            weight = getattr(agent_foundations, foundation_name)\n",
        "            contribution = weight * score\n",
        "            explanation += f\"  â€¢ {foundation_name.replace('_', '/').title()}: \"\n",
        "            explanation += f\"{score:+.2f} (weight: {weight:.2f}, contribution: {contribution:+.2f})\\n\"\n",
        "\n",
        "        # Identify moral conflicts\n",
        "        conflicts = self._identify_conflicts(foundation_scores, agent_foundations)\n",
        "        if conflicts:\n",
        "            explanation += \"\\nMORAL TENSIONS:\\n\"\n",
        "            for conflict in conflicts:\n",
        "                explanation += f\"  â€¢ {conflict}\\n\"\n",
        "\n",
        "        return explanation\n",
        "\n",
        "    def _explain_foundation(self, foundation: str, score: float, policy: PolicyFeatures) -> str:\n",
        "        \"\"\"Generate foundation-specific explanation\"\"\"\n",
        "\n",
        "        explanations = {\n",
        "            'care_harm': self._explain_care_harm(score, policy),\n",
        "            'fairness_cheating': self._explain_fairness(score, policy),\n",
        "            'loyalty_betrayal': self._explain_loyalty(score, policy),\n",
        "            'authority_subversion': self._explain_authority(score, policy),\n",
        "            'sanctity_degradation': self._explain_sanctity(score, policy)\n",
        "        }\n",
        "\n",
        "        return explanations.get(foundation, \"No explanation available\")\n",
        "\n",
        "    def _explain_care_harm(self, score: float, policy: PolicyFeatures) -> str:\n",
        "        if score > 0:\n",
        "            return (f\"This policy effectively protects people from harm \"\n",
        "                   f\"(safety: {policy.safety_requirements:.2f}, \"\n",
        "                   f\"privacy: {policy.privacy_safeguards:.2f}, \"\n",
        "                   f\"vulnerable groups: {policy.vulnerable_protection:.2f})\")\n",
        "        else:\n",
        "            return (f\"This policy may cause harm through regulatory burden \"\n",
        "                   f\"or insufficient protection \"\n",
        "                   f\"(implementation cost: {policy.implementation_cost:.2f})\")\n",
        "\n",
        "    def _explain_fairness(self, score: float, policy: PolicyFeatures) -> str:\n",
        "        if score > 0:\n",
        "            return (f\"This policy promotes fairness and equity \"\n",
        "                   f\"(equity provisions: {policy.equity_provisions:.2f}, \"\n",
        "                   f\"procedural fairness: {policy.procedural_fairness:.2f})\")\n",
        "        else:\n",
        "            return (f\"This policy creates unfair burdens \"\n",
        "                   f\"(small actor burden: {policy.small_actor_burden:.2f}, \"\n",
        "                   f\"access inequality: {1-policy.access_equality:.2f})\")\n",
        "\n",
        "    def _explain_loyalty(self, score: float, policy: PolicyFeatures) -> str:\n",
        "        if score > 0:\n",
        "            return (f\"This policy serves national/group interests \"\n",
        "                   f\"(national advantage: {policy.national_advantage:.2f}, \"\n",
        "                   f\"cooperation: {policy.cross_border_cooperation:.2f})\")\n",
        "        else:\n",
        "            return (f\"This policy may harm competitiveness or group solidarity \"\n",
        "                   f\"(competitiveness impact: {policy.competitiveness_impact:.2f})\")\n",
        "\n",
        "    def _explain_authority(self, score: float, policy: PolicyFeatures) -> str:\n",
        "        if score > 0:\n",
        "            return (f\"This policy strengthens institutional governance \"\n",
        "                   f\"(institutional clarity: {policy.institutional_clarity:.2f}, \"\n",
        "                   f\"regulatory strength: {policy.regulatory_strength:.2f})\")\n",
        "        else:\n",
        "            return (f\"This policy weakens governance structures or precedent \"\n",
        "                   f\"(precedent alignment: {policy.precedent_alignment:.2f})\")\n",
        "\n",
        "    def _explain_sanctity(self, score: float, policy: PolicyFeatures) -> str:\n",
        "        if score > 0:\n",
        "            return (f\"This policy protects human dignity and autonomy \"\n",
        "                   f\"(human dignity: {policy.human_dignity:.2f}, \"\n",
        "                   f\"manipulation prevention: {policy.manipulation_prevention:.2f})\")\n",
        "        else:\n",
        "            return (f\"This policy may compromise dignity or sacred values \"\n",
        "                   f\"(privacy sanctity: {policy.privacy_sanctity:.2f})\")\n",
        "\n",
        "    def _identify_conflicts(self,\n",
        "                           foundation_scores: Dict[str, float],\n",
        "                           agent_foundations: MoralFoundations) -> List[str]:\n",
        "        \"\"\"Identify moral tradeoffs where foundations conflict\"\"\"\n",
        "        conflicts = []\n",
        "\n",
        "        weighted = {k: getattr(agent_foundations, k) * v\n",
        "                   for k, v in foundation_scores.items()}\n",
        "\n",
        "        # Find foundations with significant weight that conflict\n",
        "        for f1, score1 in weighted.items():\n",
        "            for f2, score2 in weighted.items():\n",
        "                if f1 < f2:  # Avoid duplicates\n",
        "                    # If both weighted significantly but opposite signs\n",
        "                    if abs(score1) > 0.1 and abs(score2) > 0.1:\n",
        "                        if np.sign(score1) != np.sign(score2):\n",
        "                            conflicts.append(\n",
        "                                f\"{f1.replace('_', '/').title()} ({score1:+.2f}) \"\n",
        "                                f\"conflicts with {f2.replace('_', '/').title()} ({score2:+.2f})\"\n",
        "                            )\n",
        "\n",
        "        return conflicts\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STAKEHOLDER MORAL PROFILES\n",
        "# ============================================================================\n",
        "\n",
        "STAKEHOLDER_PROFILES = {\n",
        "    \"consumer_advocacy_ngo\": MoralFoundations(\n",
        "        care_harm=0.45,\n",
        "        fairness_cheating=0.35,\n",
        "        loyalty_betrayal=0.05,\n",
        "        authority_subversion=0.10,\n",
        "        sanctity_degradation=0.05\n",
        "    ),\n",
        "\n",
        "    \"tech_industry_association\": MoralFoundations(\n",
        "        care_harm=0.20,\n",
        "        fairness_cheating=0.25,\n",
        "        loyalty_betrayal=0.15,\n",
        "        authority_subversion=0.30,\n",
        "        sanctity_degradation=0.10\n",
        "    ),\n",
        "\n",
        "    \"progressive_government\": MoralFoundations(\n",
        "        care_harm=0.35,\n",
        "        fairness_cheating=0.30,\n",
        "        loyalty_betrayal=0.10,\n",
        "        authority_subversion=0.15,\n",
        "        sanctity_degradation=0.10\n",
        "    ),\n",
        "\n",
        "    \"conservative_government\": MoralFoundations(\n",
        "        care_harm=0.20,\n",
        "        fairness_cheating=0.20,\n",
        "        loyalty_betrayal=0.25,\n",
        "        authority_subversion=0.25,\n",
        "        sanctity_degradation=0.10\n",
        "    ),\n",
        "\n",
        "    \"academic_ethics_board\": MoralFoundations(\n",
        "        care_harm=0.35,\n",
        "        fairness_cheating=0.30,\n",
        "        loyalty_betrayal=0.05,\n",
        "        authority_subversion=0.15,\n",
        "        sanctity_degradation=0.15\n",
        "    ),\n",
        "\n",
        "    \"civil_liberties_group\": MoralFoundations(\n",
        "        care_harm=0.25,\n",
        "        fairness_cheating=0.30,\n",
        "        loyalty_betrayal=0.05,\n",
        "        authority_subversion=0.15,\n",
        "        sanctity_degradation=0.25\n",
        "    ),\n",
        "\n",
        "    \"national_security_agency\": MoralFoundations(\n",
        "        care_harm=0.25,\n",
        "        fairness_cheating=0.15,\n",
        "        loyalty_betrayal=0.35,\n",
        "        authority_subversion=0.20,\n",
        "        sanctity_degradation=0.05\n",
        "    ),\n",
        "\n",
        "    \"multinational_corporation\": MoralFoundations(\n",
        "        care_harm=0.15,\n",
        "        fairness_cheating=0.25,\n",
        "        loyalty_betrayal=0.15,\n",
        "        authority_subversion=0.35,\n",
        "        sanctity_degradation=0.10\n",
        "    ),\n",
        "\n",
        "    \"small_business_coalition\": MoralFoundations(\n",
        "        care_harm=0.20,\n",
        "        fairness_cheating=0.40,\n",
        "        loyalty_betrayal=0.15,\n",
        "        authority_subversion=0.20,\n",
        "        sanctity_degradation=0.05\n",
        "    ),\n",
        "\n",
        "    \"international_standards_body\": MoralFoundations(\n",
        "        care_harm=0.30,\n",
        "        fairness_cheating=0.30,\n",
        "        loyalty_betrayal=0.10,\n",
        "        authority_subversion=0.20,\n",
        "        sanctity_degradation=0.10\n",
        "    )\n",
        "}\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# EXAMPLE USAGE AND VALIDATION\n",
        "# ============================================================================\n",
        "\n",
        "def create_example_policy() -> PolicyFeatures:\n",
        "    \"\"\"\n",
        "    Example: Mandatory AI Safety Testing Policy\n",
        "    Models the EU AI Act high-risk system requirements\n",
        "    \"\"\"\n",
        "    return PolicyFeatures(\n",
        "        policy_id=\"P001\",\n",
        "        policy_name=\"Mandatory Pre-Deployment Safety Testing for High-Risk AI\",\n",
        "        policy_type=\"regulation\",\n",
        "\n",
        "        # High safety focus\n",
        "        safety_requirements=0.85,\n",
        "        harm_prevention=0.80,\n",
        "        vulnerable_protection=0.75,\n",
        "        privacy_safeguards=0.70,\n",
        "\n",
        "        # Moderate fairness\n",
        "        equity_provisions=0.60,\n",
        "        procedural_fairness=0.75,\n",
        "        access_equality=0.65,\n",
        "        small_actor_burden=0.70,  # Burdensome for small companies\n",
        "\n",
        "        # Mixed loyalty effects\n",
        "        national_advantage=0.50,\n",
        "        competitiveness_impact=0.60,  # Could harm competitiveness\n",
        "        cross_border_cooperation=0.70,\n",
        "        ingroup_solidarity=0.55,\n",
        "\n",
        "        # Strong authority\n",
        "        institutional_clarity=0.80,\n",
        "        regulatory_strength=0.85,\n",
        "        precedent_alignment=0.75,\n",
        "        expert_deference=0.80,\n",
        "\n",
        "        # Moderate sanctity\n",
        "        human_dignity=0.70,\n",
        "        privacy_sanctity=0.70,\n",
        "        transparency_norms=0.75,\n",
        "        manipulation_prevention=0.75,\n",
        "\n",
        "        # Meta-attributes\n",
        "        implementation_cost=0.65,\n",
        "        innovation_impact=0.50,\n",
        "        enforcement_difficulty=0.55\n",
        "    )\n",
        "\n",
        "\n",
        "def run_validation_example():\n",
        "    \"\"\"\n",
        "    Demonstrate moral evaluation across different stakeholders\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"MORAL FOUNDATIONS MODULE - VALIDATION EXAMPLE\")\n",
        "    print(\"=\" * 80)\n",
        "    print()\n",
        "\n",
        "    # Create policy and evaluator\n",
        "    policy = create_example_policy()\n",
        "    evaluator = MoralEvaluator(scenario_context=\"general\")\n",
        "    explainer = MoralExplainer(evaluator)\n",
        "\n",
        "    # Evaluate from different stakeholder perspectives\n",
        "    stakeholders = [\n",
        "        (\"consumer_advocacy_ngo\", \"Consumer Rights Alliance\"),\n",
        "        (\"tech_industry_association\", \"Tech Industry Group\"),\n",
        "        (\"conservative_government\", \"National Regulatory Authority\"),\n",
        "        (\"academic_ethics_board\", \"University Ethics Board\")\n",
        "    ]\n",
        "\n",
        "    for profile_key, agent_name in stakeholders:\n",
        "        foundations = STAKEHOLDER_PROFILES[profile_key]\n",
        "\n",
        "        print(f\"\\n{'=' * 80}\")\n",
        "        print(explainer.explain_evaluation(policy, foundations, agent_name))\n",
        "\n",
        "        # Check for moral constraints\n",
        "        is_admissible, violations = evaluator.check_moral_constraints(\n",
        "            policy, foundations, threshold=-0.6\n",
        "        )\n",
        "\n",
        "        if not is_admissible:\n",
        "            print(f\"\\nâš ï¸  MORAL CONSTRAINTS VIOLATED:\")\n",
        "            for violation in violations:\n",
        "                print(f\"   {violation}\")\n",
        "        else:\n",
        "            print(f\"\\nâœ“ Policy is morally admissible for {agent_name}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"MORAL DISTANCE MATRIX\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\nMoral similarity between stakeholders (lower = more similar):\\n\")\n",
        "\n",
        "    # Compute pairwise moral distances\n",
        "    profile_list = list(stakeholders)\n",
        "    for i, (key1, name1) in enumerate(profile_list):\n",
        "        for key2, name2 in profile_list[i+1:]:\n",
        "            distance = STAKEHOLDER_PROFILES[key1].distance_to(STAKEHOLDER_PROFILES[key2])\n",
        "            print(f\"{name1} â†” {name2}: {distance:.3f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_validation_example()\n",
        "'''\n",
        "\n",
        "with open('moral_foundations.py', 'w') as f:\n",
        "    f.write(moral_foundations_content)\n",
        "\n",
        "trust_dynamics_content = r'''\"\"\"\n",
        "Trust Dynamics Module for Auracelle Bach\n",
        "=========================================\n",
        "\n",
        "Implements computational models of trust evolution, reciprocity, and reputation\n",
        "in multi-agent AI governance simulations.\n",
        "\n",
        "Based on:\n",
        "- Ostrom, E. (1990). Governing the Commons\n",
        "- Axelrod, R. (1984). The Evolution of Cooperation\n",
        "- Fehr & GÃ¤chter (2000). Cooperation and Punishment\n",
        "- Berg et al. (1995). Trust Game experiments\n",
        "- Evans AGPO Framework trust formalization\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Optional, Set\n",
        "from dataclasses import dataclass, field\n",
        "from enum import Enum\n",
        "import json\n",
        "\n",
        "\n",
        "class InteractionType(Enum):\n",
        "    \"\"\"Types of agent interactions that affect trust\"\"\"\n",
        "    COOPERATION = \"cooperation\"\n",
        "    DEFECTION = \"defection\"\n",
        "    NEGOTIATION = \"negotiation\"\n",
        "    ENFORCEMENT = \"enforcement\"\n",
        "    INFORMATION_SHARING = \"information_sharing\"\n",
        "\n",
        "\n",
        "class ReputationSignal(Enum):\n",
        "    \"\"\"Types of reputation information\"\"\"\n",
        "    DIRECT_EXPERIENCE = \"direct\"      # First-hand interaction\n",
        "    THIRD_PARTY = \"third_party\"       # Gossip/network information\n",
        "    INSTITUTIONAL = \"institutional\"    # Formal ratings/enforcement\n",
        "    PUBLIC_RECORD = \"public\"          # Observable actions\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class InteractionRecord:\n",
        "    \"\"\"\n",
        "    Record of a single interaction between agents\n",
        "    Used for trust updating and reputation calculation\n",
        "    \"\"\"\n",
        "    timestep: int\n",
        "    agent_i: str  # Acting agent\n",
        "    agent_j: str  # Target/partner agent\n",
        "    interaction_type: InteractionType\n",
        "    outcome_for_i: float  # Payoff/benefit for agent i [-1, 1]\n",
        "    outcome_for_j: float  # Payoff/benefit for agent j [-1, 1]\n",
        "    cooperation_level: float  # [0, 1] how cooperative was the action\n",
        "    policy_context: Optional[str] = None  # Which policy was being negotiated\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrustState:\n",
        "    \"\"\"\n",
        "    Agent's trust beliefs about other agents in the network\n",
        "    \"\"\"\n",
        "    agent_id: str\n",
        "\n",
        "    # Trust network: trust level in each other agent [0, 1]\n",
        "    trust_levels: Dict[str, float] = field(default_factory=dict)\n",
        "\n",
        "    # Reputation beliefs: what agent thinks others' reputation is [0, 1]\n",
        "    reputation_beliefs: Dict[str, float] = field(default_factory=dict)\n",
        "\n",
        "    # Interaction history\n",
        "    interaction_history: List[InteractionRecord] = field(default_factory=list)\n",
        "\n",
        "    # Reciprocity tracking\n",
        "    debts_owed: Dict[str, float] = field(default_factory=dict)  # Positive reciprocity\n",
        "    grievances: Dict[str, float] = field(default_factory=dict)  # Negative reciprocity\n",
        "\n",
        "    # Coalition/alliance memberships\n",
        "    coalition_members: Set[str] = field(default_factory=set)\n",
        "\n",
        "    # Trust characteristics\n",
        "    baseline_trust: float = 0.5  # Initial trust in unknown agents\n",
        "    trust_decay_rate: float = 0.02  # How fast trust erodes without interaction\n",
        "    forgiveness_rate: float = 0.05  # How fast grievances fade\n",
        "    reciprocity_strength: float = 0.7  # How much agent values reciprocity\n",
        "    institutional_trust: float = 0.6  # Trust in governance mechanisms\n",
        "\n",
        "    def get_trust(self, agent_j: str) -> float:\n",
        "        \"\"\"Get current trust level in agent j\"\"\"\n",
        "        return self.trust_levels.get(agent_j, self.baseline_trust)\n",
        "\n",
        "    def get_reputation_belief(self, agent_j: str) -> float:\n",
        "        \"\"\"Get believed reputation of agent j\"\"\"\n",
        "        return self.reputation_beliefs.get(agent_j, 0.5)\n",
        "\n",
        "    def get_net_reciprocity(self, agent_j: str) -> float:\n",
        "        \"\"\"\n",
        "        Get net reciprocity balance with agent j\n",
        "        Positive = they owe us, Negative = we owe them\n",
        "        \"\"\"\n",
        "        debt = self.debts_owed.get(agent_j, 0.0)\n",
        "        grievance = self.grievances.get(agent_j, 0.0)\n",
        "        return debt - grievance\n",
        "\n",
        "\n",
        "class TrustDynamicsEngine:\n",
        "    \"\"\"\n",
        "    Core engine for trust evolution in governance networks\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 learning_rate: float = 0.3,\n",
        "                 reputation_weight: float = 0.2,\n",
        "                 institutional_weight: float = 0.15):\n",
        "        \"\"\"\n",
        "        Initialize trust dynamics engine\n",
        "\n",
        "        Args:\n",
        "            learning_rate: How quickly trust updates from experience\n",
        "            reputation_weight: How much third-party info influences trust\n",
        "            institutional_weight: How much formal mechanisms affect trust\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.reputation_weight = reputation_weight\n",
        "        self.institutional_weight = institutional_weight\n",
        "\n",
        "        # Network-level reputation scores\n",
        "        self.global_reputation: Dict[str, float] = {}\n",
        "\n",
        "        # Institutional enforcement probability\n",
        "        self.enforcement_probability: float = 0.5\n",
        "\n",
        "    def update_trust_from_interaction(self,\n",
        "                                     agent_i_trust: TrustState,\n",
        "                                     agent_j: str,\n",
        "                                     interaction: InteractionRecord) -> float:\n",
        "        \"\"\"\n",
        "        Update agent i's trust in agent j based on interaction outcome\n",
        "\n",
        "        Implements Ostrom's trust evolution mechanism:\n",
        "        Trust increases with cooperation, decreases with defection\n",
        "        \"\"\"\n",
        "        current_trust = agent_i_trust.get_trust(agent_j)\n",
        "\n",
        "        # Component 1: Direct experience update\n",
        "        # Positive outcomes increase trust, negative decrease it\n",
        "        outcome_signal = interaction.outcome_for_i\n",
        "\n",
        "        # Trust update is asymmetric: losses hurt more than gains help\n",
        "        if outcome_signal >= 0:\n",
        "            experience_update = (\n",
        "                outcome_signal *\n",
        "                (1 - current_trust)  # Diminishing returns to trust building\n",
        "            )\n",
        "        else:\n",
        "            # Betrayal is more damaging (loss aversion)\n",
        "            experience_update = (\n",
        "                outcome_signal * 1.5 *\n",
        "                current_trust  # More to lose when trust is high\n",
        "            )\n",
        "\n",
        "        # Cooperation level modulates update\n",
        "        cooperation_factor = interaction.cooperation_level\n",
        "        weighted_experience = cooperation_factor * experience_update\n",
        "\n",
        "        # Component 2: Reputation signal\n",
        "        network_reputation = self.get_network_reputation(agent_j)\n",
        "        reputation_signal = network_reputation - current_trust\n",
        "\n",
        "        # Component 3: Institutional backing\n",
        "        # If there are enforcement mechanisms, trust is more stable\n",
        "        institutional_factor = (\n",
        "            self.enforcement_probability *\n",
        "            agent_i_trust.institutional_trust\n",
        "        )\n",
        "\n",
        "        # Combined trust update\n",
        "        trust_change = (\n",
        "            self.learning_rate * weighted_experience +\n",
        "            self.reputation_weight * reputation_signal +\n",
        "            self.institutional_weight * institutional_factor\n",
        "        )\n",
        "\n",
        "        new_trust = np.clip(current_trust + trust_change, 0, 1)\n",
        "\n",
        "        # Update trust state\n",
        "        agent_i_trust.trust_levels[agent_j] = new_trust\n",
        "\n",
        "        # Record interaction\n",
        "        agent_i_trust.interaction_history.append(interaction)\n",
        "\n",
        "        return new_trust\n",
        "\n",
        "    def update_reciprocity_accounts(self,\n",
        "                                    agent_i_trust: TrustState,\n",
        "                                    agent_j: str,\n",
        "                                    interaction: InteractionRecord):\n",
        "        \"\"\"\n",
        "        Update reciprocity debts and grievances\n",
        "        Positive reciprocity: track who helped us\n",
        "        Negative reciprocity: track who harmed us\n",
        "        \"\"\"\n",
        "        outcome = interaction.outcome_for_i\n",
        "        cooperation = interaction.cooperation_level\n",
        "\n",
        "        # Positive reciprocity: agent j helped us\n",
        "        if outcome > 0 and cooperation > 0.5:\n",
        "            current_debt = agent_i_trust.debts_owed.get(agent_j, 0.0)\n",
        "            # We now \"owe\" them for their help\n",
        "            agent_i_trust.debts_owed[agent_j] = np.clip(\n",
        "                current_debt + outcome * cooperation,\n",
        "                0, 2.0  # Cap maximum debt\n",
        "            )\n",
        "\n",
        "        # Negative reciprocity: agent j harmed us\n",
        "        if outcome < 0:\n",
        "            current_grievance = agent_i_trust.grievances.get(agent_j, 0.0)\n",
        "            # We now have a grievance to settle\n",
        "            agent_i_trust.grievances[agent_j] = np.clip(\n",
        "                current_grievance + abs(outcome),\n",
        "                0, 2.0  # Cap maximum grievance\n",
        "            )\n",
        "\n",
        "    def compute_reciprocity_preference(self,\n",
        "                                      agent_i_trust: TrustState,\n",
        "                                      action_targets: List[str]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Compute reciprocity-based preference for cooperating with each target\n",
        "\n",
        "        Returns preference scores [-1, 1] for each target agent\n",
        "        \"\"\"\n",
        "        preferences = {}\n",
        "\n",
        "        for agent_j in action_targets:\n",
        "            # Positive reciprocity: prefer to help those who helped us\n",
        "            debt = agent_i_trust.debts_owed.get(agent_j, 0.0)\n",
        "\n",
        "            # Negative reciprocity: prefer to punish those who harmed us\n",
        "            grievance = agent_i_trust.grievances.get(agent_j, 0.0)\n",
        "\n",
        "            # Net preference\n",
        "            reciprocity_preference = (\n",
        "                agent_i_trust.reciprocity_strength *\n",
        "                (debt - grievance)\n",
        "            )\n",
        "\n",
        "            preferences[agent_j] = np.clip(reciprocity_preference, -1, 1)\n",
        "\n",
        "        return preferences\n",
        "\n",
        "    def decay_trust_and_reciprocity(self, agent_trust: TrustState):\n",
        "        \"\"\"\n",
        "        Apply time decay to trust levels and reciprocity accounts\n",
        "        Trust erodes without positive interaction\n",
        "        Reciprocity accounts fade over time (forgiveness)\n",
        "        \"\"\"\n",
        "        # Trust decay\n",
        "        for agent_j in agent_trust.trust_levels:\n",
        "            current_trust = agent_trust.trust_levels[agent_j]\n",
        "\n",
        "            # Trust decays toward baseline\n",
        "            decay = agent_trust.trust_decay_rate * (current_trust - agent_trust.baseline_trust)\n",
        "            agent_trust.trust_levels[agent_j] = np.clip(current_trust - decay, 0, 1)\n",
        "\n",
        "        # Reciprocity decay (forgiveness)\n",
        "        for agent_j in agent_trust.debts_owed:\n",
        "            agent_trust.debts_owed[agent_j] *= (1 - agent_trust.forgiveness_rate)\n",
        "\n",
        "        for agent_j in agent_trust.grievances:\n",
        "            agent_trust.grievances[agent_j] *= (1 - agent_trust.forgiveness_rate)\n",
        "\n",
        "    def update_network_reputation(self,\n",
        "                                  agent_id: str,\n",
        "                                  all_interactions: List[InteractionRecord]):\n",
        "        \"\"\"\n",
        "        Update global network reputation based on all visible interactions\n",
        "        Reputation = average cooperation/fairness across all interactions\n",
        "        \"\"\"\n",
        "        relevant_interactions = [\n",
        "            interaction for interaction in all_interactions\n",
        "            if interaction.agent_i == agent_id or interaction.agent_j == agent_id\n",
        "        ]\n",
        "\n",
        "        if not relevant_interactions:\n",
        "            self.global_reputation[agent_id] = 0.5  # Neutral\n",
        "            return\n",
        "\n",
        "        # Compute average cooperation as reputation proxy\n",
        "        cooperation_scores = []\n",
        "        for interaction in relevant_interactions:\n",
        "            if interaction.agent_i == agent_id:\n",
        "                # Agent's cooperation in this interaction\n",
        "                cooperation_scores.append(interaction.cooperation_level)\n",
        "            else:\n",
        "                # If agent_j, infer cooperation from outcome\n",
        "                if interaction.outcome_for_j > 0:\n",
        "                    cooperation_scores.append(0.7)\n",
        "                elif interaction.outcome_for_j < 0:\n",
        "                    cooperation_scores.append(0.3)\n",
        "                else:\n",
        "                    cooperation_scores.append(0.5)\n",
        "\n",
        "        reputation = np.mean(cooperation_scores)\n",
        "\n",
        "        # Update with exponential smoothing\n",
        "        old_reputation = self.global_reputation.get(agent_id, 0.5)\n",
        "        self.global_reputation[agent_id] = 0.7 * old_reputation + 0.3 * reputation\n",
        "\n",
        "    def get_network_reputation(self, agent_id: str) -> float:\n",
        "        \"\"\"Get agent's network-wide reputation [0, 1]\"\"\"\n",
        "        return self.global_reputation.get(agent_id, 0.5)\n",
        "\n",
        "    def compute_trust_based_cooperation_incentive(self,\n",
        "                                                  agent_i_trust: TrustState,\n",
        "                                                  agent_j: str) -> float:\n",
        "        \"\"\"\n",
        "        Compute how much trust incentivizes cooperation with agent j\n",
        "\n",
        "        High trust â†’ willing to cooperate even without immediate payoff\n",
        "        Low trust â†’ require strong incentives to cooperate\n",
        "\n",
        "        Returns cooperation bonus [-0.5, 0.5]\n",
        "        \"\"\"\n",
        "        trust_level = agent_i_trust.get_trust(agent_j)\n",
        "\n",
        "        # Trust provides cooperation bonus\n",
        "        # Trust=1 gives max bonus, Trust=0 gives penalty\n",
        "        cooperation_bonus = (trust_level - 0.5)\n",
        "\n",
        "        # Modulated by reciprocity balance\n",
        "        reciprocity = agent_i_trust.get_net_reciprocity(agent_j)\n",
        "\n",
        "        total_incentive = cooperation_bonus + 0.3 * reciprocity\n",
        "\n",
        "        return np.clip(total_incentive, -0.5, 0.5)\n",
        "\n",
        "\n",
        "class CoalitionManager:\n",
        "    \"\"\"\n",
        "    Manages coalition formation based on trust and value alignment\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 trust_threshold: float = 0.6,\n",
        "                 value_alignment_weight: float = 0.4):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            trust_threshold: Minimum trust needed to form coalition\n",
        "            value_alignment_weight: How much moral alignment matters vs trust\n",
        "        \"\"\"\n",
        "        self.trust_threshold = trust_threshold\n",
        "        self.value_alignment_weight = value_alignment_weight\n",
        "\n",
        "        # Active coalitions\n",
        "        self.coalitions: Dict[str, Set[str]] = {}  # coalition_id -> member set\n",
        "\n",
        "    def can_form_coalition(self,\n",
        "                          agent_i_trust: TrustState,\n",
        "                          agent_j: str,\n",
        "                          moral_distance: Optional[float] = None) -> bool:\n",
        "        \"\"\"\n",
        "        Determine if two agents can form a coalition\n",
        "        Requires sufficient trust and value alignment\n",
        "        \"\"\"\n",
        "        trust = agent_i_trust.get_trust(agent_j)\n",
        "\n",
        "        # Check trust threshold\n",
        "        if trust < self.trust_threshold:\n",
        "            return False\n",
        "\n",
        "        # Check value alignment if provided\n",
        "        if moral_distance is not None:\n",
        "            # moral_distance [0, ~1.4], lower is better\n",
        "            alignment_score = 1 - (moral_distance / 1.5)\n",
        "\n",
        "            combined_score = (\n",
        "                (1 - self.value_alignment_weight) * trust +\n",
        "                self.value_alignment_weight * alignment_score\n",
        "            )\n",
        "\n",
        "            return combined_score > 0.65\n",
        "\n",
        "        return True\n",
        "\n",
        "    def form_coalition(self,\n",
        "                      coalition_id: str,\n",
        "                      members: Set[str]):\n",
        "        \"\"\"Create a new coalition\"\"\"\n",
        "        self.coalitions[coalition_id] = members\n",
        "\n",
        "    def update_coalition_trust(self,\n",
        "                              coalition_id: str,\n",
        "                              member_trust_states: Dict[str, TrustState]):\n",
        "        \"\"\"\n",
        "        Update in-coalition trust bonuses\n",
        "        Coalition members get trust boost toward each other\n",
        "        \"\"\"\n",
        "        if coalition_id not in self.coalitions:\n",
        "            return\n",
        "\n",
        "        members = self.coalitions[coalition_id]\n",
        "        coalition_trust_bonus = 0.1\n",
        "\n",
        "        for agent_i in members:\n",
        "            if agent_i not in member_trust_states:\n",
        "                continue\n",
        "\n",
        "            trust_state = member_trust_states[agent_i]\n",
        "\n",
        "            for agent_j in members:\n",
        "                if agent_i != agent_j:\n",
        "                    current_trust = trust_state.get_trust(agent_j)\n",
        "                    # Coalition membership boosts trust\n",
        "                    trust_state.trust_levels[agent_j] = np.clip(\n",
        "                        current_trust + coalition_trust_bonus,\n",
        "                        0, 1\n",
        "                    )\n",
        "                    # Update coalition membership\n",
        "                    trust_state.coalition_members.add(agent_j)\n",
        "\n",
        "\n",
        "class TrustBasedPolicyNegotiation:\n",
        "    \"\"\"\n",
        "    Models how trust affects policy negotiation dynamics\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, trust_engine: TrustDynamicsEngine):\n",
        "        self.trust_engine = trust_engine\n",
        "\n",
        "    def compute_negotiation_power(self,\n",
        "                                  agent_trust: TrustState,\n",
        "                                  other_agents: List[str]) -> float:\n",
        "        \"\"\"\n",
        "        Compute agent's negotiation power based on network trust\n",
        "        High trust = more influence in negotiations\n",
        "        \"\"\"\n",
        "        # Average trust others have in this agent (reputation)\n",
        "        reputation = self.trust_engine.get_network_reputation(agent_trust.agent_id)\n",
        "\n",
        "        # Agent's own trust in others (willingness to cooperate)\n",
        "        own_trust = np.mean([\n",
        "            agent_trust.get_trust(other)\n",
        "            for other in other_agents\n",
        "        ])\n",
        "\n",
        "        # Coalition size bonus\n",
        "        coalition_bonus = 0.1 * len(agent_trust.coalition_members)\n",
        "\n",
        "        negotiation_power = (\n",
        "            0.5 * reputation +\n",
        "            0.3 * own_trust +\n",
        "            0.2 * coalition_bonus\n",
        "        )\n",
        "\n",
        "        return np.clip(negotiation_power, 0, 1)\n",
        "\n",
        "    def compute_compromise_willingness(self,\n",
        "                                      agent_i_trust: TrustState,\n",
        "                                      agent_j: str,\n",
        "                                      policy_value_gap: float) -> float:\n",
        "        \"\"\"\n",
        "        How willing is agent i to compromise with agent j?\n",
        "\n",
        "        High trust â†’ willing to accept suboptimal deals\n",
        "        Low trust â†’ demand better terms\n",
        "\n",
        "        Args:\n",
        "            policy_value_gap: How much policy differs from agent's ideal [-1, 1]\n",
        "\n",
        "        Returns:\n",
        "            Compromise willingness [0, 1]\n",
        "        \"\"\"\n",
        "        trust = agent_i_trust.get_trust(agent_j)\n",
        "        reciprocity = agent_i_trust.get_net_reciprocity(agent_j)\n",
        "\n",
        "        # Base willingness from trust\n",
        "        base_willingness = trust\n",
        "\n",
        "        # Reciprocity adjustment\n",
        "        if reciprocity > 0:\n",
        "            # They helped us before, more willing to compromise\n",
        "            willingness = base_willingness + 0.2 * reciprocity\n",
        "        elif reciprocity < 0:\n",
        "            # We have grievance, less willing\n",
        "            willingness = base_willingness + 0.3 * reciprocity  # Negative impact\n",
        "        else:\n",
        "            willingness = base_willingness\n",
        "\n",
        "        # Modulated by policy value gap\n",
        "        # Small gaps â†’ easier to compromise even with low trust\n",
        "        gap_factor = 1 - abs(policy_value_gap)\n",
        "\n",
        "        final_willingness = willingness * (0.5 + 0.5 * gap_factor)\n",
        "\n",
        "        return np.clip(final_willingness, 0, 1)\n",
        "\n",
        "    def model_repeated_game_strategy(self,\n",
        "                                    agent_i_trust: TrustState,\n",
        "                                    agent_j: str,\n",
        "                                    history_length: int = 5) -> str:\n",
        "        \"\"\"\n",
        "        Determine cooperation strategy based on trust and history\n",
        "        Implements variants of Tit-for-Tat\n",
        "\n",
        "        Returns: \"cooperate\", \"defect\", \"conditional_cooperate\"\n",
        "        \"\"\"\n",
        "        trust = agent_i_trust.get_trust(agent_j)\n",
        "\n",
        "        # Get recent interaction history\n",
        "        recent_interactions = [\n",
        "            interaction for interaction in agent_i_trust.interaction_history[-history_length:]\n",
        "            if interaction.agent_j == agent_j\n",
        "        ]\n",
        "\n",
        "        if not recent_interactions:\n",
        "            # No history: trust-based decision\n",
        "            return \"cooperate\" if trust > 0.6 else \"conditional_cooperate\"\n",
        "\n",
        "        # Check if agent j cooperated recently\n",
        "        recent_cooperation = np.mean([\n",
        "            interaction.cooperation_level\n",
        "            for interaction in recent_interactions\n",
        "        ])\n",
        "\n",
        "        # Tit-for-Tat with forgiveness\n",
        "        if recent_cooperation > 0.7:\n",
        "            return \"cooperate\"  # They cooperated, reciprocate\n",
        "        elif recent_cooperation < 0.3:\n",
        "            # They defected\n",
        "            grievance = agent_i_trust.grievances.get(agent_j, 0.0)\n",
        "            if grievance > 1.0 and trust < 0.3:\n",
        "                return \"defect\"  # Punish severe betrayal\n",
        "            else:\n",
        "                return \"conditional_cooperate\"  # Forgive but cautious\n",
        "        else:\n",
        "            # Mixed signals\n",
        "            return \"conditional_cooperate\" if trust > 0.5 else \"defect\"\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# TRUST-BASED GOVERNANCE SCENARIOS\n",
        "# ============================================================================\n",
        "\n",
        "def create_governance_network_trust_states(agent_ids: List[str]) -> Dict[str, TrustState]:\n",
        "    \"\"\"\n",
        "    Initialize trust states for all agents in governance network\n",
        "    \"\"\"\n",
        "    trust_states = {}\n",
        "\n",
        "    for agent_id in agent_ids:\n",
        "        trust_states[agent_id] = TrustState(\n",
        "            agent_id=agent_id,\n",
        "            baseline_trust=0.5,\n",
        "            trust_decay_rate=0.02,\n",
        "            forgiveness_rate=0.05,\n",
        "            reciprocity_strength=0.7,\n",
        "            institutional_trust=0.6\n",
        "        )\n",
        "\n",
        "    return trust_states\n",
        "\n",
        "\n",
        "def simulate_trust_evolution_example():\n",
        "    \"\"\"\n",
        "    Demonstrate trust dynamics in AI governance negotiation\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"TRUST DYNAMICS MODULE - VALIDATION EXAMPLE\")\n",
        "    print(\"=\" * 80)\n",
        "    print()\n",
        "\n",
        "    # Create agents\n",
        "    agents = [\"Government_A\", \"TechCorp\", \"ConsumerNGO\", \"StandardsBody\"]\n",
        "    trust_states = create_governance_network_trust_states(agents)\n",
        "\n",
        "    # Initialize trust engine\n",
        "    engine = TrustDynamicsEngine(\n",
        "        learning_rate=0.3,\n",
        "        reputation_weight=0.2,\n",
        "        institutional_weight=0.15\n",
        "    )\n",
        "\n",
        "    # Initialize coalition manager\n",
        "    coalition_mgr = CoalitionManager(trust_threshold=0.6)\n",
        "\n",
        "    print(\"INITIAL STATE:\")\n",
        "    print(\"-\" * 80)\n",
        "    for agent_id in agents:\n",
        "        print(f\"{agent_id}: Baseline trust = {trust_states[agent_id].baseline_trust}\")\n",
        "    print()\n",
        "\n",
        "    # Simulate negotiation rounds\n",
        "    print(\"\\nNEGOTIATION ROUND 1: Data Privacy Policy\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Interaction 1: TechCorp cooperates with Government_A\n",
        "    interaction1 = InteractionRecord(\n",
        "        timestep=1,\n",
        "        agent_i=\"TechCorp\",\n",
        "        agent_j=\"Government_A\",\n",
        "        interaction_type=InteractionType.NEGOTIATION,\n",
        "        outcome_for_i=0.6,  # Moderate gain for TechCorp\n",
        "        outcome_for_j=0.7,  # Good outcome for Government\n",
        "        cooperation_level=0.8,  # High cooperation\n",
        "        policy_context=\"data_privacy\"\n",
        "    )\n",
        "\n",
        "    new_trust = engine.update_trust_from_interaction(\n",
        "        trust_states[\"TechCorp\"],\n",
        "        \"Government_A\",\n",
        "        interaction1\n",
        "    )\n",
        "    engine.update_reciprocity_accounts(\n",
        "        trust_states[\"TechCorp\"],\n",
        "        \"Government_A\",\n",
        "        interaction1\n",
        "    )\n",
        "\n",
        "    print(f\"TechCorp cooperates with Government_A (cooperation=0.8)\")\n",
        "    print(f\"  â†’ TechCorp's trust in Government_A: {trust_states['TechCorp'].baseline_trust:.2f} â†’ {new_trust:.2f}\")\n",
        "    print(f\"  â†’ Reciprocity debt owed to Government_A: {trust_states['TechCorp'].debts_owed.get('Government_A', 0):.2f}\")\n",
        "    print()\n",
        "\n",
        "    # Interaction 2: ConsumerNGO defects against TechCorp\n",
        "    interaction2 = InteractionRecord(\n",
        "        timestep=1,\n",
        "        agent_i=\"ConsumerNGO\",\n",
        "        agent_j=\"TechCorp\",\n",
        "        interaction_type=InteractionType.NEGOTIATION,\n",
        "        outcome_for_i=0.4,\n",
        "        outcome_for_j=-0.5,  # Negative outcome for TechCorp\n",
        "        cooperation_level=0.2,  # Low cooperation (defection)\n",
        "        policy_context=\"data_privacy\"\n",
        "    )\n",
        "\n",
        "    new_trust = engine.update_trust_from_interaction(\n",
        "        trust_states[\"ConsumerNGO\"],\n",
        "        \"TechCorp\",\n",
        "        interaction2\n",
        "    )\n",
        "    engine.update_reciprocity_accounts(\n",
        "        trust_states[\"ConsumerNGO\"],\n",
        "        \"TechCorp\",\n",
        "        interaction2\n",
        "    )\n",
        "\n",
        "    print(f\"ConsumerNGO defects against TechCorp (cooperation=0.2)\")\n",
        "    print(f\"  â†’ ConsumerNGO's trust in TechCorp: {trust_states['ConsumerNGO'].baseline_trust:.2f} â†’ {new_trust:.2f}\")\n",
        "    print()\n",
        "\n",
        "    # Update TechCorp's trust in ConsumerNGO (perspective flip)\n",
        "    interaction2_reverse = InteractionRecord(\n",
        "        timestep=1,\n",
        "        agent_i=\"TechCorp\",\n",
        "        agent_j=\"ConsumerNGO\",\n",
        "        interaction_type=InteractionType.NEGOTIATION,\n",
        "        outcome_for_i=-0.5,\n",
        "        outcome_for_j=0.4,\n",
        "        cooperation_level=0.2,\n",
        "        policy_context=\"data_privacy\"\n",
        "    )\n",
        "\n",
        "    new_trust_reverse = engine.update_trust_from_interaction(\n",
        "        trust_states[\"TechCorp\"],\n",
        "        \"ConsumerNGO\",\n",
        "        interaction2_reverse\n",
        "    )\n",
        "    engine.update_reciprocity_accounts(\n",
        "        trust_states[\"TechCorp\"],\n",
        "        \"ConsumerNGO\",\n",
        "        interaction2_reverse\n",
        "    )\n",
        "\n",
        "    print(f\"TechCorp experiences defection from ConsumerNGO\")\n",
        "    print(f\"  â†’ TechCorp's trust in ConsumerNGO: {trust_states['TechCorp'].baseline_trust:.2f} â†’ {new_trust_reverse:.2f}\")\n",
        "    print(f\"  â†’ Grievance against ConsumerNGO: {trust_states['TechCorp'].grievances.get('ConsumerNGO', 0):.2f}\")\n",
        "    print()\n",
        "\n",
        "    # Update network reputations\n",
        "    all_interactions = [interaction1, interaction2, interaction2_reverse]\n",
        "    for agent_id in agents:\n",
        "        engine.update_network_reputation(agent_id, all_interactions)\n",
        "\n",
        "    print(\"\\nNETWORK REPUTATION SCORES:\")\n",
        "    print(\"-\" * 80)\n",
        "    for agent_id in agents:\n",
        "        reputation = engine.get_network_reputation(agent_id)\n",
        "        print(f\"{agent_id}: {reputation:.2f}\")\n",
        "    print()\n",
        "\n",
        "    # Coalition formation\n",
        "    print(\"\\nCOALITION FORMATION:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    can_coalition = coalition_mgr.can_form_coalition(\n",
        "        trust_states[\"TechCorp\"],\n",
        "        \"Government_A\",\n",
        "        moral_distance=0.3  # Moderate value alignment\n",
        "    )\n",
        "\n",
        "    print(f\"Can TechCorp form coalition with Government_A? {can_coalition}\")\n",
        "    print(f\"  (Trust: {trust_states['TechCorp'].get_trust('Government_A'):.2f}, \"\n",
        "          f\"Threshold: {coalition_mgr.trust_threshold})\")\n",
        "\n",
        "    if can_coalition:\n",
        "        coalition_mgr.form_coalition(\"tech_gov_alliance\", {\"TechCorp\", \"Government_A\"})\n",
        "        print(\"  â†’ Coalition 'tech_gov_alliance' formed!\")\n",
        "    print()\n",
        "\n",
        "    # Negotiation dynamics\n",
        "    print(\"\\nNEGOTIATION ROUND 2: AI Safety Standards\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    negotiator = TrustBasedPolicyNegotiation(engine)\n",
        "\n",
        "    # Compute negotiation power\n",
        "    for agent_id in agents:\n",
        "        power = negotiator.compute_negotiation_power(\n",
        "            trust_states[agent_id],\n",
        "            [a for a in agents if a != agent_id]\n",
        "        )\n",
        "        print(f\"{agent_id} negotiation power: {power:.2f}\")\n",
        "    print()\n",
        "\n",
        "    # Compute compromise willingness\n",
        "    print(\"\\nCOMPROMISE WILLINGNESS:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # TechCorp willing to compromise with Government_A (high trust)\n",
        "    willingness_high_trust = negotiator.compute_compromise_willingness(\n",
        "        trust_states[\"TechCorp\"],\n",
        "        \"Government_A\",\n",
        "        policy_value_gap=0.3  # Moderate disagreement\n",
        "    )\n",
        "\n",
        "    # TechCorp unwilling to compromise with ConsumerNGO (low trust, grievance)\n",
        "    willingness_low_trust = negotiator.compute_compromise_willingness(\n",
        "        trust_states[\"TechCorp\"],\n",
        "        \"ConsumerNGO\",\n",
        "        policy_value_gap=0.3\n",
        "    )\n",
        "\n",
        "    print(f\"TechCorp â†’ Government_A: {willingness_high_trust:.2f} (high trust)\")\n",
        "    print(f\"TechCorp â†’ ConsumerNGO: {willingness_low_trust:.2f} (low trust, grievance)\")\n",
        "    print()\n",
        "\n",
        "    # Repeated game strategies\n",
        "    print(\"\\nREPEATED GAME STRATEGIES:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    strategy_gov = negotiator.model_repeated_game_strategy(\n",
        "        trust_states[\"TechCorp\"],\n",
        "        \"Government_A\"\n",
        "    )\n",
        "\n",
        "    strategy_ngo = negotiator.model_repeated_game_strategy(\n",
        "        trust_states[\"TechCorp\"],\n",
        "        \"ConsumerNGO\"\n",
        "    )\n",
        "\n",
        "    print(f\"TechCorp strategy toward Government_A: {strategy_gov}\")\n",
        "    print(f\"TechCorp strategy toward ConsumerNGO: {strategy_ngo}\")\n",
        "    print()\n",
        "\n",
        "    # Trust decay over time\n",
        "    print(\"\\nTIME DECAY (10 rounds without interaction):\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for timestep in range(10):\n",
        "        engine.decay_trust_and_reciprocity(trust_states[\"TechCorp\"])\n",
        "\n",
        "    print(f\"TechCorp's trust in Government_A after decay: \"\n",
        "          f\"{trust_states['TechCorp'].get_trust('Government_A'):.2f}\")\n",
        "    print(f\"Reciprocity debt after decay: \"\n",
        "          f\"{trust_states['TechCorp'].debts_owed.get('Government_A', 0):.2f}\")\n",
        "    print(f\"Grievance against ConsumerNGO after decay: \"\n",
        "          f\"{trust_states['TechCorp'].grievances.get('ConsumerNGO', 0):.2f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    simulate_trust_evolution_example()\n",
        "'''\n",
        "\n",
        "with open('trust_dynamics.py', 'w') as f:\n",
        "    f.write(trust_dynamics_content)\n",
        "\n",
        "print(\"âœ… Cognitive architecture modules created\")\n",
        "print(\"   ğŸ§  moral_foundations.py (665 lines)\")\n",
        "print(\"   ğŸ¤ trust_dynamics.py (695 lines)\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CREATE MAIN APP.PY\n",
        "# =============================================================================\n",
        "\n",
        "app_content = \"\"\"import streamlit as st\n",
        "\n",
        "st.set_page_config(page_title=\"Auracelle Bach | Login\", layout=\"wide\")\n",
        "\n",
        "st.markdown('''\n",
        "<style>\n",
        ".stApp {\n",
        "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "}\n",
        "</style>\n",
        "''', unsafe_allow_html=True)\n",
        "\n",
        "st.title(\"ğŸ¼ Auracelle Bach: E-AGPO-HT Complete Mathematical Intelligence\")\n",
        "st.subheader(\"9 Mathematical Enhancements for AI Governance\")\n",
        "\n",
        "if \"authenticated\" not in st.session_state:\n",
        "    st.session_state[\"authenticated\"] = False\n",
        "\n",
        "if not st.session_state[\"authenticated\"]:\n",
        "    with st.form(\"login_form\"):\n",
        "        username = st.text_input(\"Username\")\n",
        "        password = st.text_input(\"Password\", type=\"password\")\n",
        "\n",
        "        st.markdown(\"#### ğŸ¯ Purpose\")\n",
        "        st.info(\"Bach: Complete Mathematical Intelligence Suite for AI Governance - All 9 E-AGPO-HT Enhancements\")\n",
        "\n",
        "        st.markdown(\"**ğŸ”¢ Active Enhancements:**\")\n",
        "        st.markdown('''\n",
        "        1ï¸âƒ£ Bayesian Uncertainty Quantification\n",
        "        2ï¸âƒ£ Convergence Prediction Modeling\n",
        "        3ï¸âƒ£ Hierarchical Capability Gap Analysis\n",
        "        4ï¸âƒ£ Multi-Objective Pareto Optimization\n",
        "        5ï¸âƒ£ Network Diffusion & Cascade Effects\n",
        "        6ï¸âƒ£ Historical Pattern Matching\n",
        "        7ï¸âƒ£ Maturity Trajectory Planning\n",
        "        8ï¸âƒ£ Kalman Filter Capability Tracking\n",
        "        9ï¸âƒ£ RL-Optimized Negotiation Strategies\n",
        "        ''')\n",
        "\n",
        "        submit = st.form_submit_button(\"ğŸš€ Launch Bach\")\n",
        "\n",
        "    if submit:\n",
        "        if password == \"charlie2025\":\n",
        "            st.session_state[\"authenticated\"] = True\n",
        "            st.session_state[\"username\"] = username\n",
        "            st.success(\"âœ… Authentication successful!\")\n",
        "            st.rerun()\n",
        "        else:\n",
        "            st.error(\"âŒ Incorrect password. Access denied.\")\n",
        "            st.stop()\n",
        "else:\n",
        "    st.switch_page(\"pages/simulation.py\")\n",
        "\"\"\"\n",
        "\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(app_content)\n",
        "\n",
        "print(\"âœ… Main app.py created\")\n",
        "\n",
        "# =============================================================================\n",
        "# CREATE COMPLETE SIMULATION PAGE (ALL 9 ENHANCEMENTS)\n",
        "# =============================================================================\n",
        "\n",
        "simulation_content = '''import streamlit as st\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from pyvis.network import Network\n",
        "import streamlit.components.v1 as components\n",
        "import numpy as np\n",
        "from bach_api_utils import get_bach_api_client\n",
        "\n",
        "st.set_page_config(layout=\"wide\", page_title=\"Auracelle Bach - Complete Suite\")\n",
        "\n",
        "if not st.session_state.get(\"authenticated\", False):\n",
        "    st.warning(\"âš ï¸ Please log in first.\")\n",
        "    st.switch_page(\"app.py\")\n",
        "\n",
        "bach_api = get_bach_api_client()\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".reportview-container {background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);}\n",
        ".metric-card {background: white; padding: 15px; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);}\n",
        ".stTabs [data-baseweb=\"tab-list\"] {gap: 8px;}\n",
        ".stTabs [data-baseweb=\"tab\"] {background-color: rgba(255,255,255,0.1); border-radius: 4px;}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.title(\"ğŸ¼ Auracelle Bach: Complete Mathematical Intelligence Suite\")\n",
        "\n",
        "# =============================================================================\n",
        "# POLICY FRAMEWORKS SIDEBAR\n",
        "# =============================================================================\n",
        "\n",
        "with st.sidebar:\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### ğŸ“š International Policy Frameworks\")\n",
        "    st.markdown(\"*Integrated into simulation logic*\")\n",
        "\n",
        "    with st.expander(\"ğŸ”’ Binding Frameworks (7)\", expanded=False):\n",
        "        st.markdown(\"\"\"\n",
        "        **1. EU AI Act**\n",
        "        Comprehensive AI regulation with risk-based approach\n",
        "\n",
        "        **2. GDPR**\n",
        "        Data protection & privacy rights\n",
        "\n",
        "        **3. NIS2 Directive**\n",
        "        Network & information security\n",
        "\n",
        "        **4. US Executive Order 14110**\n",
        "        Safe, secure & trustworthy AI development\n",
        "\n",
        "        **5. Council of Europe Convention**\n",
        "        First international AI treaty (Sept 2024)\n",
        "\n",
        "        **6. Digital Services Act (DSA)**\n",
        "        Platform accountability & content moderation\n",
        "\n",
        "        **7. UK AI Regulation**\n",
        "        Sectoral regulation approach\n",
        "        \"\"\")\n",
        "\n",
        "    with st.expander(\"ğŸ¤ Voluntary Frameworks (5)\", expanded=False):\n",
        "        st.markdown(\"\"\"\n",
        "        **1. UNESCO Recommendation on AI Ethics**\n",
        "        Global ethical AI principles (193 countries)\n",
        "\n",
        "        **2. OECD AI Principles**\n",
        "        Foundation for responsible AI policy\n",
        "\n",
        "        **3. NATO Principles on Responsible Use**\n",
        "        Defense & security AI ethics\n",
        "\n",
        "        **4. ISO/IEC 42001**\n",
        "        AI management system standard\n",
        "\n",
        "        **5. UN AI Principles**\n",
        "        Universal AI governance framework\n",
        "        \"\"\")\n",
        "\n",
        "    # Summary box\n",
        "    st.markdown(\"\"\"\n",
        "    <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                padding: 15px; border-radius: 8px; margin-top: 15px;'>\n",
        "        <p style='color: white; margin: 0; font-size: 13px; text-align: center;'>\n",
        "            <strong>12 Frameworks</strong><br>\n",
        "            <span style='font-size: 11px;'>7 Binding â€¢ 5 Voluntary</span>\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "st.markdown(\"**9 Mathematical Enhancements from E-AGPO-HT Formalization**\")\n",
        "\n",
        "st.info(\"\"\"\n",
        "ğŸ“Š **Data Sources**: This simulation integrates data from three authoritative APIs:\n",
        "- **OECD AI Principles & Policy Observatory** - AI policies, principles, and incidents\n",
        "- **Privacy International** - Surveillance scores and data protection laws\n",
        "- **ParlaMint Parliamentary Debates** - Legislative discourse analysis\n",
        "\n",
        "âš ï¸ Note: If live APIs are unavailable, the system automatically uses validated static fallback data.\n",
        "\"\"\")\n",
        "\n",
        "if \"round\" not in st.session_state:\n",
        "    st.session_state[\"round\"] = 1\n",
        "\n",
        "# Sidebar Configuration\n",
        "st.sidebar.header(\"ğŸ¯ Scenario Configuration\")\n",
        "scenario_type = st.sidebar.selectbox(\"Select Scenario Type\", [\n",
        "    \"Bilateral Policy Negotiation\",\n",
        "    \"Multilateral AI Governance Round (3+ Actors)\",\n",
        "    \"Cross-Border Digital Shock Response\",\n",
        "    \"Regulatory Divergence & Convergence Simulation\",\n",
        "    \"Human-AI Joint Decision Making (Hybrid Governance Scenario)\",\n",
        "    \"Cross-Border Data Governance Corridor Analysis\"\n",
        "])\n",
        "\n",
        "country_to_iso = {\n",
        "    \"USA\": \"USA\", \"China\": \"CHN\", \"EU\": \"GBR\", \"India\": \"IND\",\n",
        "    \"Japan\": \"JPN\", \"Russia\": \"CHN\", \"Brazil\": \"BRA\", \"UAE\": \"ARE\"\n",
        "}\n",
        "\n",
        "# Expanded actor list (countries + regional blocs)\n",
        "regional_actors = [\n",
        "    \"MENA\",\n",
        "    \"APAC / Asia-Pacific\",\n",
        "    \"African Union (AU)\",\n",
        "    \"BRICS\",\n",
        "    \"GCC\",\n",
        "    \"ASEAN+\",\n",
        "    \"Five Eyes (FVEY)\"\n",
        "]\n",
        "all_actors = list(country_to_iso.keys()) + regional_actors\n",
        "\n",
        "selected_policy = None\n",
        "selected_country_a = None\n",
        "selected_country_b = None\n",
        "\n",
        "if \"policies\" not in st.session_state:\n",
        "    st.session_state[\"policies\"] = [\"AI Ethics\", \"AI Safety\", \"Data Privacy\", \"Export Controls\", \"R&D Investment\"]\n",
        "\n",
        "policies = st.session_state[\"policies\"]\n",
        "\n",
        "if scenario_type == \"Bilateral Policy Negotiation\":\n",
        "    st.sidebar.subheader(\"ğŸŒ Bilateral Actors\")\n",
        "    selected_country_a = st.sidebar.selectbox(\"Select Actor A\", all_actors, index=0)\n",
        "    selected_country_b = st.sidebar.selectbox(\"Select Actor B\", all_actors, index=1)\n",
        "\n",
        "    st.sidebar.subheader(\"ğŸ“‹ Policy Focus\")\n",
        "    selected_policy = st.sidebar.selectbox(\"Select Policy Area\", policies)\n",
        "\n",
        "elif scenario_type == \"Multilateral AI Governance Round (3+ Actors)\":\n",
        "    st.sidebar.subheader(\"ğŸŒ Multilateral Actors (3+)\")\n",
        "    selected_actors = st.sidebar.multiselect(\n",
        "        \"Select Actors (minimum 3)\",\n",
        "        options=all_actors,\n",
        "        default=[all_actors[0], all_actors[1], all_actors[2]] if len(all_actors) >= 3 else all_actors\n",
        "    )\n",
        "    if len(selected_actors) < 3:\n",
        "        st.sidebar.warning(\"Select at least 3 actors to run a multilateral round.\")\n",
        "    # Store all selected actors for multilateral analysis\n",
        "    if len(selected_actors) >= 2:\n",
        "        selected_country_a = selected_actors[0]\n",
        "        selected_country_b = selected_actors[1]\n",
        "    # Make selected_actors available globally for tabs\n",
        "    # Always update when actors change (not just when scenario type changes)\n",
        "    if 'selected_actors' not in st.session_state or st.session_state.get('selected_actors') != selected_actors or st.session_state.get('scenario_type') != scenario_type:\n",
        "        st.session_state['selected_actors'] = selected_actors\n",
        "        st.session_state['scenario_type'] = scenario_type\n",
        "        # Force refresh to update all modules\n",
        "        if 'actors_changed' not in st.session_state:\n",
        "            st.session_state['actors_changed'] = True\n",
        "    st.sidebar.caption(\"Complexity factors: coalition shifts â€¢ institutional asymmetry â€¢ cognitive overload\")\n",
        "    # Add confirmation button for actor selection\n",
        "    if st.sidebar.button(\"âœ… Apply Actor Selection\", help=\"Click to confirm your actor selection\"):\n",
        "        st.session_state['selected_actors'] = selected_actors\n",
        "        st.session_state['actors_changed'] = True\n",
        "        st.success(f\"âœ… Updated to {len(selected_actors)} actors: {', '.join(selected_actors)}\")\n",
        "        st.rerun()\n",
        "\n",
        "\n",
        "    st.sidebar.subheader(\"ğŸ“‹ Policy Focus\")\n",
        "    selected_policy = st.sidebar.selectbox(\"Select Policy Area\", policies)\n",
        "\n",
        "elif scenario_type == \"Cross-Border Digital Shock Response\":\n",
        "    st.sidebar.subheader(\"âš¡ Shock Type\")\n",
        "    shock_type = st.sidebar.selectbox(\n",
        "        \"Select Shock\",\n",
        "        [\"Cyber breach\", \"Disinformation wave\", \"Major AI system failure\", \"Data localization emergency\", \"Critical infrastructure attack\"]\n",
        "    )\n",
        "    st.sidebar.subheader(\"ğŸŒ Impacted Actors\")\n",
        "    selected_country_a = st.sidebar.selectbox(\"Primary Impacted Actor\", all_actors, index=0)\n",
        "    selected_country_b = st.sidebar.selectbox(\"Secondary Actor / Key Ally\", all_actors, index=1)\n",
        "    st.sidebar.caption(\"Shock modelling: rapid escalation â€¢ constrained information â€¢ time-to-comply pressure\")\n",
        "    st.sidebar.subheader(\"ğŸ“‹ Policy Focus\")\n",
        "    selected_policy = st.sidebar.selectbox(\"Select Policy Area\", policies)\n",
        "\n",
        "elif scenario_type == \"Regulatory Divergence & Convergence Simulation\":\n",
        "    st.sidebar.subheader(\"ğŸ§­ Regulatory Relationship\")\n",
        "    selected_country_a = st.sidebar.selectbox(\"Actor A\", all_actors, index=0)\n",
        "    selected_country_b = st.sidebar.selectbox(\"Actor B\", all_actors, index=1)\n",
        "    st.sidebar.slider(\"Initial Alignment (0=Fragmented, 100=Aligned)\", 0, 100, 50, key=\"reg_alignment\")\n",
        "    st.sidebar.checkbox(\"External Pressure Event (forces convergence)\", value=False, key=\"reg_pressure\")\n",
        "    st.sidebar.caption(\"States: align â€¢ drift â€¢ fragment â€¢ oscillate â€¢ converge-under-pressure\")\n",
        "    st.sidebar.subheader(\"ğŸ“‹ Policy Focus\")\n",
        "    selected_policy = st.sidebar.selectbox(\"Select Policy Area\", policies)\n",
        "\n",
        "elif scenario_type == \"Human-AI Joint Decision Making (Hybrid Governance Scenario)\":\n",
        "    st.sidebar.subheader(\"ğŸ¤ Hybrid Governance\")\n",
        "    selected_country_a = st.sidebar.selectbox(\"Human Institution / Actor\", all_actors, index=0)\n",
        "    selected_country_b = \"AI System\"\n",
        "    st.sidebar.selectbox(\"AI Role\", [\"Adviser\", \"Co-decider\", \"Autonomous Executor\", \"Auditor/Assurance Agent\"], key=\"hybrid_ai_role\")\n",
        "    st.sidebar.slider(\"Trust Calibration (0=Under-reliance, 100=Over-reliance)\", 0, 100, 50, key=\"hybrid_trust\")\n",
        "    st.sidebar.caption(\"Models: HITL failures â€¢ explanation burden â€¢ over/under reliance â€¢ trust trajectories\")\n",
        "    st.sidebar.subheader(\"ğŸ“‹ Policy Focus\")\n",
        "    selected_policy = st.sidebar.selectbox(\"Select Policy Area\", policies)\n",
        "\n",
        "elif scenario_type == \"Cross-Border Data Governance Corridor Analysis\":\n",
        "    st.sidebar.subheader(\"ğŸ›°ï¸ Data Governance Corridor\")\n",
        "    corridor_nodes = [\"MENA\", \"EU\", \"USA\", \"APAC / Asia-Pacific\", \"African Union (AU)\", \"GCC\", \"ASEAN+\", \"BRICS\"]\n",
        "    src_region = st.sidebar.selectbox(\"Source Region\", corridor_nodes, index=0)\n",
        "    dst_region = st.sidebar.selectbox(\"Destination Region\", corridor_nodes, index=1 if len(corridor_nodes) > 1 else 0)\n",
        "    selected_country_a = src_region\n",
        "    selected_country_b = dst_region\n",
        "\n",
        "    st.sidebar.subheader(\"ğŸ” Risk Lens\")\n",
        "    risk_lens = st.sidebar.radio(\n",
        "        \"Select Corridor Risk Lens\",\n",
        "        [\"Cross-Border Compliance Risk (CBCR)\", \"Cross-Border Digital Policy Risk (CBDPR)\"],\n",
        "        index=0\n",
        "    )\n",
        "    st.sidebar.caption(\"CBCR: compliance mismatch â€¢ enforcement uncertainty â€¢ audit gaps â€¢ trust asymmetry\")\n",
        "    st.sidebar.caption(\"CBDPR: norms volatility â€¢ governance friction â€¢ market vs state models â€¢ traceability divergence\")\n",
        "\n",
        "    st.sidebar.subheader(\"ğŸ“‹ Policy Focus\")\n",
        "    selected_policy = st.sidebar.selectbox(\"Select Policy Area\", policies)\n",
        "\n",
        "st.sidebar.header(\"âš™ï¸ Simulation Controls\")\n",
        "if st.sidebar.button(\"â–¶ï¸ Start/Next Round\"):\n",
        "    st.session_state[\"round\"] += 1\n",
        "if st.sidebar.button(\"ğŸ”„ Reset\"):\n",
        "    for key in list(st.session_state.keys()):\n",
        "        if key not in [\"authenticated\", \"username\"]:\n",
        "            del st.session_state[key]\n",
        "    st.rerun()\n",
        "\n",
        "st.sidebar.info(f\"**Round:** {st.session_state['round']}\")\n",
        "st.sidebar.markdown(\"---\")\n",
        "st.sidebar.markdown(\"### ğŸ“Š Active Enhancements\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "1ï¸âƒ£ Bayesian Uncertainty\n",
        "2ï¸âƒ£ Convergence Prediction\n",
        "3ï¸âƒ£ Capability Gap Analysis\n",
        "4ï¸âƒ£ Pareto Optimization\n",
        "5ï¸âƒ£ Network Diffusion\n",
        "6ï¸âƒ£ Historical Matching\n",
        "7ï¸âƒ£ Maturity Planning\n",
        "8ï¸âƒ£ Kalman Filtering\n",
        "9ï¸âƒ£ RL Strategy Optimization\n",
        "\"\"\")\n",
        "\n",
        "# Main Tabs - All 9 Enhancements\n",
        "tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9 = st.tabs([\n",
        "    \"ğŸ¼ Bayesian\", \"ğŸ”® Convergence\", \"ğŸ¯ Gap Analysis\", \"ğŸ“ˆ Pareto\",\n",
        "    \"ğŸŒ Diffusion\", \"ğŸ“š Historical\", \"ğŸ“Š Maturity\", \"ğŸ¯ Kalman\", \"ğŸ¤– RL Strategy\"\n",
        "])\n",
        "\n",
        "iso_a = country_to_iso.get(selected_country_a, \"USA\")\n",
        "iso_b = country_to_iso.get(selected_country_b, \"CHN\")\n",
        "\n",
        "# TAB 1: Bayesian Uncertainty Quantification\n",
        "with tab1:\n",
        "    st.header(\"1ï¸âƒ£ Bayesian Ethical Alignment with Uncertainty Quantification\")\n",
        "    st.markdown(\"*Quantifies uncertainty in ethical alignment scores using Bayesian posterior distributions*\")\n",
        "\n",
        "    # Get actors based on scenario type\n",
        "    if scenario_type == \"Multilateral AI Governance Round (3+ Actors)\":\n",
        "        display_actors = st.session_state.get('selected_actors', [selected_country_a, selected_country_b])\n",
        "    else:\n",
        "        display_actors = [selected_country_a, selected_country_b] if selected_country_b else [selected_country_a]\n",
        "\n",
        "    # Handle AI System case\n",
        "    display_actors = [a for a in display_actors if a != \"AI System\"]\n",
        "\n",
        "    if not display_actors:\n",
        "        st.warning(\"âš ï¸ Please select at least one actor\")\n",
        "    else:\n",
        "        # Create dynamic columns based on number of actors\n",
        "        num_cols = min(len(display_actors), 4)  # Max 4 columns for readability\n",
        "        cols = st.columns(num_cols)\n",
        "\n",
        "        bayesian_results = {}\n",
        "\n",
        "        for idx, actor in enumerate(display_actors):\n",
        "            col_idx = idx % num_cols\n",
        "            iso_code = country_to_iso.get(actor, actor)\n",
        "\n",
        "            with cols[col_idx]:\n",
        "                st.subheader(f\"ğŸŒ {actor}\")\n",
        "                try:\n",
        "                    bayesian = bach_api.calculate_ethical_alignment_bayesian(iso_code, selected_policy)\n",
        "                    bayesian_results[actor] = bayesian\n",
        "\n",
        "                    st.metric(\n",
        "                        \"Ethical Alignment Score\",\n",
        "                        f\"{bayesian['score']:.3f}\",\n",
        "                        delta=f\"Â±{bayesian['std_dev']:.3f}\"\n",
        "                    )\n",
        "                    st.progress(bayesian['reliability'], text=f\"Data Reliability: {bayesian['reliability']:.1%}\")\n",
        "\n",
        "                    with st.expander(\"ğŸ“Š Details\"):\n",
        "                        st.write(f\"**95% CI:** [{bayesian['ci_lower']:.3f}, {bayesian['ci_upper']:.3f}]\")\n",
        "                        st.write(f\"**Std Dev:** {bayesian['std_dev']:.3f}\")\n",
        "                        st.write(f\"**Reliability:** {bayesian['reliability']:.3f}\")\n",
        "                except Exception as e:\n",
        "                    st.error(f\"âŒ Error fetching data: {str(e)}\")\n",
        "\n",
        "        # Visualization for all actors\n",
        "        if bayesian_results:\n",
        "            st.subheader(\"ğŸ“Š Comparative Analysis\")\n",
        "\n",
        "            fig = go.Figure()\n",
        "            for actor, result in bayesian_results.items():\n",
        "                fig.add_trace(go.Bar(\n",
        "                    name=actor,\n",
        "                    x=['Ethical Alignment'],\n",
        "                    y=[result['score']],\n",
        "                    error_y=dict(type='data', array=[1.96*result['std_dev']]),\n",
        "                    text=f\"{result['score']:.3f}\",\n",
        "                    textposition='auto'\n",
        "                ))\n",
        "\n",
        "            fig.update_layout(\n",
        "                title=f\"Ethical Alignment Comparison with 95% CI - {selected_policy}\",\n",
        "                barmode='group',\n",
        "                yaxis_title=\"Score\",\n",
        "                showlegend=True\n",
        "            )\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            # Summary table\n",
        "            st.subheader(\"ğŸ“‹ Summary Table\")\n",
        "            summary_data = []\n",
        "            for actor, result in bayesian_results.items():\n",
        "                summary_data.append({\n",
        "                    \"Actor\": actor,\n",
        "                    \"Score\": f\"{result['score']:.3f}\",\n",
        "                    \"CI Lower\": f\"{result['ci_lower']:.3f}\",\n",
        "                    \"CI Upper\": f\"{result['ci_upper']:.3f}\",\n",
        "                    \"Std Dev\": f\"{result['std_dev']:.3f}\",\n",
        "                    \"Reliability\": f\"{result['reliability']:.1%}\"\n",
        "                })\n",
        "            st.dataframe(summary_data, use_container_width=True)\n",
        "\n",
        "# TAB 2: Convergence Prediction\n",
        "with tab2:\n",
        "    st.header(\"2ï¸âƒ£ Negotiation Convergence Prediction Model\")\n",
        "    st.markdown(\"*Predicts expected rounds and probability of successful convergence*\")\n",
        "\n",
        "    # Get actors\n",
        "    if scenario_type == \"Multilateral AI Governance Round (3+ Actors)\":\n",
        "        display_actors = st.session_state.get('selected_actors', [selected_country_a, selected_country_b])\n",
        "    else:\n",
        "        display_actors = [selected_country_a, selected_country_b] if selected_country_b else [selected_country_a]\n",
        "\n",
        "    display_actors = [a for a in display_actors if a != \"AI System\"]\n",
        "\n",
        "    if len(display_actors) < 2:\n",
        "        st.warning(\"âš ï¸ Convergence prediction requires at least 2 actors\")\n",
        "    else:\n",
        "        # For multilateral, show pairwise convergence\n",
        "        if len(display_actors) > 2:\n",
        "            st.info(f\"ğŸ“Š Analyzing {len(display_actors)} actors - showing key bilateral convergence paths\")\n",
        "\n",
        "            # Select comparison pairs\n",
        "            col1, col2 = st.columns(2)\n",
        "            with col1:\n",
        "                actor1 = st.selectbox(\"Select First Actor\", display_actors, key=\"conv_actor1\")\n",
        "            with col2:\n",
        "                remaining = [a for a in display_actors if a != actor1]\n",
        "                actor2 = st.selectbox(\"Select Second Actor\", remaining, key=\"conv_actor2\")\n",
        "\n",
        "            iso1 = country_to_iso.get(actor1, actor1)\n",
        "            iso2 = country_to_iso.get(actor2, actor2)\n",
        "        else:\n",
        "            actor1, actor2 = display_actors[0], display_actors[1]\n",
        "            iso1 = country_to_iso.get(actor1, actor1)\n",
        "            iso2 = country_to_iso.get(actor2, actor2)\n",
        "\n",
        "        try:\n",
        "            convergence = bach_api.predict_convergence_timeline(iso1, iso2, selected_policy)\n",
        "\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\"Expected Rounds to Convergence\", convergence[\"expected_rounds\"])\n",
        "            with col2:\n",
        "                st.metric(\"Success Probability\", f\"{convergence['probability_success']:.1%}\")\n",
        "            with col3:\n",
        "                st.metric(\"Initial Ethical Gap\", f\"{convergence['initial_gap']:.3f}\")\n",
        "\n",
        "            if convergence[\"trajectory\"]:\n",
        "                traj_df = pd.DataFrame(convergence[\"trajectory\"])\n",
        "                fig = go.Figure()\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=traj_df[\"round\"],\n",
        "                    y=traj_df[\"position_a\"],\n",
        "                    mode='lines+markers',\n",
        "                    name=f\"{actor1} Position\",\n",
        "                    line=dict(color='blue', width=3)\n",
        "                ))\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=traj_df[\"round\"],\n",
        "                    y=traj_df[\"position_b\"],\n",
        "                    mode='lines+markers',\n",
        "                    name=f\"{actor2} Position\",\n",
        "                    line=dict(color='red', width=3)\n",
        "                ))\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=traj_df[\"round\"],\n",
        "                    y=traj_df[\"gap\"],\n",
        "                    mode='lines+markers',\n",
        "                    name=\"Remaining Gap\",\n",
        "                    line=dict(color='green', width=2, dash='dash')\n",
        "                ))\n",
        "                fig.update_layout(\n",
        "                    title=f\"Convergence Trajectory: {actor1} â†” {actor2}\",\n",
        "                    xaxis_title=\"Negotiation Round\",\n",
        "                    yaxis_title=\"Position/Gap\",\n",
        "                    hovermode='x unified'\n",
        "                )\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "                st.dataframe(traj_df, use_container_width=True)\n",
        "\n",
        "            # For multilateral, show convergence matrix\n",
        "            if len(display_actors) > 2:\n",
        "                st.subheader(\"ğŸ”„ Multilateral Convergence Matrix\")\n",
        "                st.info(\"Pairwise convergence difficulty between all actors\")\n",
        "\n",
        "                matrix_data = []\n",
        "                for a1 in display_actors:\n",
        "                    row = {\"Actor\": a1}\n",
        "                    for a2 in display_actors:\n",
        "                        if a1 == a2:\n",
        "                            row[a2] = \"-\"\n",
        "                        else:\n",
        "                            try:\n",
        "                                iso_a1 = country_to_iso.get(a1, a1)\n",
        "                                iso_a2 = country_to_iso.get(a2, a2)\n",
        "                                conv = bach_api.predict_convergence_timeline(iso_a1, iso_a2, selected_policy)\n",
        "                                row[a2] = f\"{conv['expected_rounds']} rounds ({conv['probability_success']:.0%})\"\n",
        "                            except:\n",
        "                                row[a2] = \"N/A\"\n",
        "                    matrix_data.append(row)\n",
        "\n",
        "                st.dataframe(matrix_data, use_container_width=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"âŒ Error predicting convergence: {str(e)}\")\n",
        "\n",
        "# TAB 3: Hierarchical Capability Gap Analysis\n",
        "with tab3:\n",
        "    st.header(\"3ï¸âƒ£ Hierarchical Capability Gap Diagnosis\")\n",
        "    st.markdown(\"*Identifies specific capability bottlenecks blocking governance maturity*\")\n",
        "\n",
        "    target = st.slider(\"Target g-GWC (Global Governance Capability)\", 0.5, 1.0, 0.8, 0.05)\n",
        "\n",
        "    gap = bach_api.diagnose_capability_gap(iso_a, target)\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.metric(\"Current g-GWC\", f\"{gap['current_gwc']:.3f}\")\n",
        "    with col2:\n",
        "        st.metric(\"Capability Gap\", f\"{gap['gap']:.3f}\", delta=f\"-{gap['gap']:.1%}\")\n",
        "\n",
        "    st.info(f\"**Status:** {gap['status']}\")\n",
        "\n",
        "    if gap['priorities']:\n",
        "        st.subheader(\"ğŸ¯ Investment Priorities\")\n",
        "\n",
        "        for p in gap['priorities']:\n",
        "            with st.expander(f\"Priority #{p['investment_priority']}: {p['capability']} (Gap Contribution: {p['gap_contribution']:.1f}%)\"):\n",
        "                st.write(f\"**Current Score:** {p['current_score']:.3f}\")\n",
        "                st.write(\"**Limiting Factors:**\")\n",
        "                for factor in p['limiting_factors']:\n",
        "                    st.write(f\"  - {factor['factor']}: {factor['score']:.3f}\")\n",
        "\n",
        "        # Visualization\n",
        "        priority_data = pd.DataFrame(gap['priorities'])\n",
        "        fig = px.bar(\n",
        "            priority_data,\n",
        "            x='capability',\n",
        "            y='gap_contribution',\n",
        "            title=\"Capability Gap Contributions\",\n",
        "            labels={'gap_contribution': 'Gap Contribution (%)', 'capability': 'Capability Domain'}\n",
        "        )\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "# TAB 4: Multi-Objective Pareto Optimization\n",
        "with tab4:\n",
        "    st.header(\"4ï¸âƒ£ Multi-Objective Pareto Optimization\")\n",
        "    st.markdown(\"*Identifies optimal policy scenarios across multiple competing objectives*\")\n",
        "\n",
        "    policy_options = [\"AI Ethics\", \"AI Safety\", \"Data Privacy\", \"Export Controls\", \"R&D Investment\"]\n",
        "\n",
        "    with st.spinner(\"Computing Pareto frontier...\"):\n",
        "        pareto = bach_api.compute_pareto_scenarios(iso_a, iso_b, policy_options)\n",
        "\n",
        "    all_df = pd.DataFrame(pareto[\"all_scenarios\"])\n",
        "    pareto_df = pd.DataFrame(pareto[\"pareto_optimal\"])\n",
        "\n",
        "    # 3D Scatter Plot\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Non-Pareto scenarios\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=all_df[\"ethical_alignment\"],\n",
        "        y=all_df[\"privacy_protection\"],\n",
        "        z=all_df[\"speed_to_agreement\"],\n",
        "        mode='markers',\n",
        "        marker=dict(size=5, color='lightgray', opacity=0.5),\n",
        "        text=all_df[\"policy\"],\n",
        "        name=\"All Scenarios\"\n",
        "    ))\n",
        "\n",
        "    # Pareto-optimal scenarios\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=pareto_df[\"ethical_alignment\"],\n",
        "        y=pareto_df[\"privacy_protection\"],\n",
        "        z=pareto_df[\"speed_to_agreement\"],\n",
        "        mode='markers',\n",
        "        marker=dict(size=10, color=pareto_df[\"composite_score\"], colorscale='Viridis', showscale=True),\n",
        "        text=pareto_df[\"policy\"],\n",
        "        name=\"Pareto Optimal\"\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"3D Pareto Frontier\",\n",
        "        scene=dict(\n",
        "            xaxis_title=\"Ethical Alignment\",\n",
        "            yaxis_title=\"Privacy Protection\",\n",
        "            zaxis_title=\"Speed to Agreement\"\n",
        "        )\n",
        "    )\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    # Recommendation\n",
        "    rec = pareto[\"recommendation\"]\n",
        "    st.success(f\"ğŸ¯ **Recommended Policy:** {rec['policy']}\")\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "    with col1:\n",
        "        st.metric(\"Ethical Alignment\", f\"{rec['ethical_alignment']:.3f}\")\n",
        "    with col2:\n",
        "        st.metric(\"Privacy Protection\", f\"{rec['privacy_protection']:.3f}\")\n",
        "    with col3:\n",
        "        st.metric(\"Speed to Agreement\", f\"{rec['speed_to_agreement']:.3f}\")\n",
        "    with col4:\n",
        "        st.metric(\"Innovation Potential\", f\"{rec['innovation_potential']:.3f}\")\n",
        "\n",
        "    st.dataframe(pareto_df, use_container_width=True)\n",
        "\n",
        "# TAB 5: Network Diffusion Simulation\n",
        "with tab5:\n",
        "    st.header(\"5ï¸âƒ£ Policy Diffusion & Network Cascade Effects\")\n",
        "    st.markdown(\"*Simulates how policies spread through international influence networks*\")\n",
        "\n",
        "    all_countries = [\"USA\", \"GBR\", \"CHN\", \"JPN\", \"IND\", \"BRA\", \"ARE\"]\n",
        "    initial_adopters = st.multiselect(\n",
        "        \"Select Initial Policy Adopters\",\n",
        "        all_countries,\n",
        "        default=[iso_a]\n",
        "    )\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        rounds = st.slider(\"Simulation Rounds\", 5, 20, 10)\n",
        "    with col2:\n",
        "        influence = st.slider(\"Influence Strength\", 0.1, 0.5, 0.3, 0.05)\n",
        "\n",
        "    if st.button(\"ğŸš€ Run Diffusion Simulation\"):\n",
        "        with st.spinner(\"Simulating policy diffusion...\"):\n",
        "            diffusion = bach_api.simulate_policy_diffusion(initial_adopters, selected_policy, rounds, influence)\n",
        "\n",
        "        st.metric(\"Network Cascade Probability\", f\"{diffusion['cascade_probability']:.1%}\")\n",
        "\n",
        "        # Trajectory visualization\n",
        "        traj_data = []\n",
        "        for round_idx, state in enumerate(diffusion['trajectory']):\n",
        "            for country, adoption in state.items():\n",
        "                traj_data.append({\n",
        "                    'Round': round_idx,\n",
        "                    'Country': country,\n",
        "                    'Adoption': adoption\n",
        "                })\n",
        "\n",
        "        traj_df = pd.DataFrame(traj_data)\n",
        "\n",
        "        fig = px.line(\n",
        "            traj_df,\n",
        "            x='Round',\n",
        "            y='Adoption',\n",
        "            color='Country',\n",
        "            title=\"Policy Adoption Diffusion Over Time\"\n",
        "        )\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        # Final adoption state\n",
        "        st.subheader(\"ğŸ“Š Final Adoption State\")\n",
        "        final_df = pd.DataFrame([\n",
        "            {\"Country\": k, \"Adoption Rate\": f\"{v:.1%}\", \"Status\": \"Adopted\" if v > 0.5 else \"Pending\"}\n",
        "            for k, v in diffusion['final_adoption'].items()\n",
        "        ]).sort_values('Adoption Rate', ascending=False)\n",
        "\n",
        "        st.dataframe(final_df, use_container_width=True)\n",
        "\n",
        "        # Tipping points\n",
        "        if diffusion['tipping_rounds']:\n",
        "            st.subheader(\"âš¡ Tipping Points\")\n",
        "            tip_df = pd.DataFrame([\n",
        "                {\"Country\": k, \"Tipping Round\": v}\n",
        "                for k, v in diffusion['tipping_rounds'].items()\n",
        "            ]).sort_values('Tipping Round')\n",
        "            st.dataframe(tip_df)\n",
        "\n",
        "# TAB 6: Historical Pattern Matching\n",
        "with tab6:\n",
        "    st.header(\"6ï¸âƒ£ Historical Scenario Pattern Matching\")\n",
        "    st.markdown(\"*Learns from past negotiations to predict outcomes*\")\n",
        "\n",
        "    st.subheader(\"ğŸ” Current Negotiation Context\")\n",
        "\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        power = st.slider(\"Power Asymmetry\", 0.0, 1.0, 0.6, 0.05)\n",
        "    with col2:\n",
        "        salience = st.slider(\"Issue Salience\", 0.0, 1.0, 0.8, 0.05)\n",
        "    with col3:\n",
        "        pressure = st.slider(\"Time Pressure\", 0.0, 1.0, 0.7, 0.05)\n",
        "\n",
        "    if st.button(\"ğŸ” Find Historical Matches\"):\n",
        "        matches = bach_api.match_historical_scenarios(\n",
        "            [selected_country_a, selected_country_b],\n",
        "            power,\n",
        "            salience,\n",
        "            pressure\n",
        "        )\n",
        "\n",
        "        st.subheader(\"ğŸ“š Top Historical Precedents\")\n",
        "\n",
        "        for i, match in enumerate(matches, 1):\n",
        "            with st.expander(f\"#{i}: {match['scenario']} (Relevance: {match['relevance']:.1%})\"):\n",
        "                col1, col2 = st.columns(2)\n",
        "\n",
        "                with col1:\n",
        "                    st.write(f\"**Similarity Score:** {match['similarity']:.1%}\")\n",
        "                    st.write(f\"**Actors Involved:** {', '.join(match['actors'])}\")\n",
        "                    st.write(f\"**Outcome:** {match['outcome'].replace('_', ' ').title()}\")\n",
        "\n",
        "                with col2:\n",
        "                    st.write(f\"**Historical Success Rate:** {match['success_rate']:.1%}\")\n",
        "                    st.info(f\"**Key Lesson:** {match['key_lesson']}\")\n",
        "\n",
        "        # Visualization\n",
        "        match_df = pd.DataFrame(matches)\n",
        "        fig = px.bar(\n",
        "            match_df,\n",
        "            x='scenario',\n",
        "            y='relevance',\n",
        "            color='success_rate',\n",
        "            title=\"Historical Scenario Relevance\",\n",
        "            labels={'relevance': 'Relevance Score', 'scenario': 'Historical Scenario'}\n",
        "        )\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "# TAB 7: Maturity Trajectory Planning\n",
        "with tab7:\n",
        "    st.header(\"7ï¸âƒ£ Capability Maturity Trajectory Planning\")\n",
        "    st.markdown(\"*Projects governance maturity growth with resource investment models*\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        target_maturity = st.slider(\"Target Maturity Level\", 1, 4, 3)\n",
        "    with col2:\n",
        "        investment = st.slider(\"Monthly Investment ($M)\", 0.5, 5.0, 1.0, 0.5)\n",
        "\n",
        "    months = st.slider(\"Planning Horizon (Months)\", 12, 48, 24)\n",
        "\n",
        "    if st.button(\"ğŸ“Š Calculate Trajectory\"):\n",
        "        with st.spinner(\"Computing maturity trajectory...\"):\n",
        "            trajectory = bach_api.calculate_maturity_trajectory(\n",
        "                iso_a,\n",
        "                target_maturity,\n",
        "                investment,\n",
        "                months\n",
        "            )\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.metric(\"Current Maturity\", trajectory['current_maturity'])\n",
        "        with col2:\n",
        "            st.metric(\"Months to Target\", trajectory['months_to_target'])\n",
        "        with col3:\n",
        "            st.metric(\"Total Investment\", f\"${trajectory['total_investment_required']:.1f}M\")\n",
        "\n",
        "        st.info(f\"ğŸ¯ **Critical Milestone:** Month {trajectory['critical_milestone_month']}\")\n",
        "\n",
        "        # Trajectory visualization\n",
        "        traj_df = pd.DataFrame(trajectory['trajectory'])\n",
        "\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=traj_df['month'],\n",
        "            y=traj_df['maturity'],\n",
        "            mode='lines+markers',\n",
        "            name='Maturity Level',\n",
        "            line=dict(color='blue', width=3)\n",
        "        ))\n",
        "        fig.add_hline(\n",
        "            y=target_maturity,\n",
        "            line_dash=\"dash\",\n",
        "            line_color=\"red\",\n",
        "            annotation_text=\"Target\"\n",
        "        )\n",
        "        fig.update_layout(\n",
        "            title=f\"Maturity Growth Trajectory for {selected_country_a}\",\n",
        "            xaxis_title=\"Month\",\n",
        "            yaxis_title=\"Maturity Level\"\n",
        "        )\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        st.dataframe(traj_df, use_container_width=True)\n",
        "\n",
        "# TAB 8: Kalman Filter Tracking\n",
        "with tab8:\n",
        "    st.header(\"8ï¸âƒ£ Kalman Filter Capability Tracking\")\n",
        "    st.markdown(\"*Real-time state estimation with uncertainty management*\")\n",
        "\n",
        "    if st.button(\"ğŸ¯ Initialize Kalman Filter\"):\n",
        "        bach_api.initialize_kalman_filter(iso_a)\n",
        "        st.success(f\"âœ… Kalman filter initialized for {selected_country_a}\")\n",
        "\n",
        "    if iso_a in bach_api.kalman_states:\n",
        "        st.subheader(\"ğŸ“¡ Current Filter State\")\n",
        "        state = bach_api.kalman_states[iso_a]\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.metric(\"Current Estimate\", f\"{state['x_hat']:.3f}\")\n",
        "        with col2:\n",
        "            st.metric(\"Uncertainty (P)\", f\"{state['P']:.4f}\")\n",
        "\n",
        "        st.subheader(\"ğŸ”„ Update Filter\")\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            new_measurement = st.slider(\"New Capability Measurement\", 0.0, 1.0, 0.7, 0.01)\n",
        "        with col2:\n",
        "            intervention = st.slider(\"Intervention Effect\", 0.0, 0.5, 0.1, 0.01)\n",
        "\n",
        "        if st.button(\"ğŸ“Š Update Kalman Filter\"):\n",
        "            result = bach_api.kalman_update(iso_a, new_measurement, intervention)\n",
        "\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\"Smoothed Estimate\", f\"{result['smoothed_estimate']:.3f}\")\n",
        "            with col2:\n",
        "                st.metric(\"Uncertainty\", f\"{result['uncertainty']:.4f}\")\n",
        "            with col3:\n",
        "                st.metric(\"Confidence\", f\"{result['confidence']:.1f}%\")\n",
        "\n",
        "        # History visualization\n",
        "        if len(state['history']) > 1:\n",
        "            history_df = pd.DataFrame(state['history'], columns=['Step', 'Estimate', 'Uncertainty'])\n",
        "\n",
        "            fig = go.Figure()\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=history_df['Step'],\n",
        "                y=history_df['Estimate'],\n",
        "                mode='lines+markers',\n",
        "                name='Capability Estimate',\n",
        "                error_y=dict(\n",
        "                    type='data',\n",
        "                    array=history_df['Uncertainty'],\n",
        "                    visible=True\n",
        "                )\n",
        "            ))\n",
        "            fig.update_layout(\n",
        "                title=\"Kalman Filter Tracking History\",\n",
        "                xaxis_title=\"Update Step\",\n",
        "                yaxis_title=\"Capability Estimate\"\n",
        "            )\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "    else:\n",
        "        st.info(\"ğŸ‘† Click 'Initialize Kalman Filter' to begin tracking\")\n",
        "\n",
        "# TAB 9: RL Strategy Optimization\n",
        "with tab9:\n",
        "    st.header(\"9ï¸âƒ£ Reinforcement Learning Strategy Optimization\")\n",
        "    st.markdown(\"*Q-learning based negotiation strategy discovery*\")\n",
        "\n",
        "    num_sims = st.slider(\"Number of Simulations\", 50, 500, 100, 50)\n",
        "\n",
        "    if st.button(\"ğŸ¤– Discover Optimal Strategy\"):\n",
        "        with st.spinner(\"Running RL simulations...\"):\n",
        "            strategy = bach_api.optimize_negotiation_strategy(\n",
        "                iso_a,\n",
        "                iso_b,\n",
        "                selected_policy,\n",
        "                num_sims\n",
        "            )\n",
        "\n",
        "        st.success(f\"ğŸ¯ **Recommended First Move:** {strategy['recommended_first_move']}\")\n",
        "        st.info(f\"ğŸ’¡ **Strategy Rationale:** {strategy['explanation']}\")\n",
        "\n",
        "        st.metric(\n",
        "            \"Expected Agreement Probability\",\n",
        "            f\"{strategy['expected_agreement_probability']:.1%}\"\n",
        "        )\n",
        "\n",
        "        st.subheader(\"ğŸ“Š Action Value Estimates (Q-Values)\")\n",
        "\n",
        "        q_df = pd.DataFrame([\n",
        "            {\"Action\": k, \"Q-Value\": v, \"Rank\": i+1}\n",
        "            for i, (k, v) in enumerate(sorted(strategy['q_values'].items(), key=lambda x: x[1], reverse=True))\n",
        "        ])\n",
        "\n",
        "        fig = px.bar(\n",
        "            q_df,\n",
        "            x='Action',\n",
        "            y='Q-Value',\n",
        "            color='Q-Value',\n",
        "            title=\"Negotiation Action Q-Values\",\n",
        "            color_continuous_scale='RdYlGn'\n",
        "        )\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        st.dataframe(q_df, use_container_width=True)\n",
        "\n",
        "        st.subheader(\"ğŸ² Optimal Action Sequence\")\n",
        "        for i, action in enumerate(strategy['optimal_action_sequence'], 1):\n",
        "            st.write(f\"{i}. **{action.replace('_', ' ').title()}**\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "<div style='text-align: center; padding: 20px;'>\n",
        "    <h3>ğŸ¼ Auracelle Bach | Complete E-AGPO-HT Mathematical Suite</h3>\n",
        "    <p><strong>9 Mathematical Enhancements Active</strong></p>\n",
        "    print(\"   ğŸ§  Cognitive Architecture: Moral Foundations + Trust Dynamics\")\n",
        "    <p style='font-size: 12px;'>Bayesian â€¢ Convergence â€¢ Gap Analysis â€¢ Pareto â€¢ Diffusion â€¢ Historical â€¢ Maturity â€¢ Kalman â€¢ RL</p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "'''\n",
        "\n",
        "with open('pages/simulation.py', 'w') as f:\n",
        "    f.write(simulation_content)\n",
        "\n",
        "print(\"âœ… Complete simulation page created with all 9 enhancements + 12 policy frameworks\")\n",
        "\n",
        "# =============================================================================\n",
        "# CREATE COGNITIVE ARCHITECTURE DEMO PAGE\n",
        "# =============================================================================\n",
        "\n",
        "cognitive_demo_content = r'''import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from moral_foundations import (\n",
        "    MoralFoundations, PolicyFeatures, MoralEvaluator,\n",
        "    MoralExplainer, STAKEHOLDER_PROFILES\n",
        ")\n",
        "from trust_dynamics import (\n",
        "    TrustState, TrustDynamicsEngine, CoalitionManager,\n",
        "    TrustBasedPolicyNegotiation, InteractionRecord, InteractionType\n",
        ")\n",
        "\n",
        "st.set_page_config(page_title=\"Cognitive Architecture Demo\", page_icon=\"ğŸ§ \", layout=\"wide\")\n",
        "\n",
        "# Password protection\n",
        "if 'authenticated' not in st.session_state:\n",
        "    st.session_state.authenticated = False\n",
        "\n",
        "if not st.session_state.authenticated:\n",
        "    password = st.text_input(\"Enter password:\", type=\"password\")\n",
        "    if st.button(\"Login\"):\n",
        "        if password == \"charlie2025\":\n",
        "            st.session_state.authenticated = True\n",
        "            st.rerun()\n",
        "        else:\n",
        "            st.error(\"Incorrect password\")\n",
        "    st.stop()\n",
        "\n",
        "# Header\n",
        "st.title(\"ğŸ§  Cognitive Architecture Demonstration\")\n",
        "st.markdown(\"\"\"\n",
        "This module demonstrates **human-inspired reasoning** in AI governance simulations through:\n",
        "- ğŸ¯ **Moral Foundations**: Computational ethics based on Haidt's theory\n",
        "- ğŸ¤ **Trust Dynamics**: Cooperation mechanisms from Ostrom/Axelrod research\n",
        "- ğŸ”„ **Value-Weighted Decisions**: Combining strategy, ethics, and social relationships\n",
        "\"\"\")\n",
        "\n",
        "# Tabs for different demonstrations\n",
        "tab1, tab2, tab3, tab4 = st.tabs([\n",
        "    \"ğŸ“Š Moral Foundations\",\n",
        "    \"ğŸ¤ Trust Dynamics\",\n",
        "    \"ğŸ¯ Integrated Agents\",\n",
        "    \"ğŸ“ˆ Simulation Results\"\n",
        "])\n",
        "\n",
        "# =============================================================================\n",
        "# TAB 1: MORAL FOUNDATIONS DEMO\n",
        "# =============================================================================\n",
        "\n",
        "with tab1:\n",
        "    st.header(\"Moral Foundations Analysis\")\n",
        "\n",
        "    col1, col2 = st.columns([1, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.subheader(\"Define Policy\")\n",
        "\n",
        "        policy_name = st.text_input(\"Policy Name\", \"GDPR-Style Privacy Regulation\")\n",
        "\n",
        "        st.markdown(\"### Policy Attributes (0-1 scale)\")\n",
        "\n",
        "        # Care/Harm dimensions\n",
        "        with st.expander(\"ğŸ¥ Care/Harm Dimensions\", expanded=True):\n",
        "            safety_req = st.slider(\"Safety Requirements\", 0.0, 1.0, 0.85, 0.05)\n",
        "            privacy_safe = st.slider(\"Privacy Safeguards\", 0.0, 1.0, 0.90, 0.05)\n",
        "            vulnerable_prot = st.slider(\"Vulnerable Protection\", 0.0, 1.0, 0.80, 0.05)\n",
        "\n",
        "        # Fairness dimensions\n",
        "        with st.expander(\"âš–ï¸ Fairness Dimensions\"):\n",
        "            equity_prov = st.slider(\"Equity Provisions\", 0.0, 1.0, 0.75, 0.05)\n",
        "            proc_fair = st.slider(\"Procedural Fairness\", 0.0, 1.0, 0.80, 0.05)\n",
        "            small_burden = st.slider(\"Small Actor Burden\", 0.0, 1.0, 0.65, 0.05)\n",
        "\n",
        "        # Authority dimensions\n",
        "        with st.expander(\"ğŸ›ï¸ Authority Dimensions\"):\n",
        "            inst_clarity = st.slider(\"Institutional Clarity\", 0.0, 1.0, 0.85, 0.05)\n",
        "            reg_strength = st.slider(\"Regulatory Strength\", 0.0, 1.0, 0.90, 0.05)\n",
        "\n",
        "        # Sanctity dimensions\n",
        "        with st.expander(\"âœ¨ Sanctity Dimensions\"):\n",
        "            human_dig = st.slider(\"Human Dignity\", 0.0, 1.0, 0.90, 0.05)\n",
        "            priv_sanct = st.slider(\"Privacy Sanctity\", 0.0, 1.0, 0.95, 0.05)\n",
        "\n",
        "        policy = PolicyFeatures(\n",
        "            policy_id=\"DEMO\",\n",
        "            policy_name=policy_name,\n",
        "            policy_type=\"regulation\",\n",
        "            safety_requirements=safety_req,\n",
        "            privacy_safeguards=privacy_safe,\n",
        "            vulnerable_protection=vulnerable_prot,\n",
        "            equity_provisions=equity_prov,\n",
        "            procedural_fairness=proc_fair,\n",
        "            small_actor_burden=small_burden,\n",
        "            institutional_clarity=inst_clarity,\n",
        "            regulatory_strength=reg_strength,\n",
        "            human_dignity=human_dig,\n",
        "            privacy_sanctity=priv_sanct\n",
        "        )\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Stakeholder Evaluations\")\n",
        "\n",
        "        evaluator = MoralEvaluator(scenario_context=\"data_privacy\")\n",
        "        explainer = MoralExplainer(evaluator)\n",
        "\n",
        "        # Select stakeholders to compare\n",
        "        selected_stakeholders = st.multiselect(\n",
        "            \"Compare Stakeholders\",\n",
        "            options=list(STAKEHOLDER_PROFILES.keys()),\n",
        "            default=[\"consumer_advocacy_ngo\", \"tech_industry_association\",\n",
        "                    \"progressive_government\", \"academic_ethics_board\"]\n",
        "        )\n",
        "\n",
        "        if selected_stakeholders:\n",
        "            # Compute moral values\n",
        "            results = []\n",
        "            for stakeholder_key in selected_stakeholders:\n",
        "                foundations = STAKEHOLDER_PROFILES[stakeholder_key]\n",
        "                moral_value = evaluator.compute_moral_value(policy, foundations)\n",
        "                results.append({\n",
        "                    'Stakeholder': stakeholder_key.replace('_', ' ').title(),\n",
        "                    'Moral Value': moral_value,\n",
        "                    'Stance': 'Support' if moral_value > 0 else 'Oppose'\n",
        "                })\n",
        "\n",
        "            results_df = pd.DataFrame(results)\n",
        "\n",
        "            # Visualization\n",
        "            fig = px.bar(\n",
        "                results_df,\n",
        "                x='Stakeholder',\n",
        "                y='Moral Value',\n",
        "                color='Moral Value',\n",
        "                color_continuous_scale='RdYlGn',\n",
        "                range_color=[-1, 1],\n",
        "                title=\"Moral Evaluation by Stakeholder\"\n",
        "            )\n",
        "            fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            # Detailed explanations\n",
        "            st.markdown(\"### Detailed Reasoning\")\n",
        "\n",
        "            selected_for_detail = st.selectbox(\n",
        "                \"View detailed explanation for:\",\n",
        "                options=selected_stakeholders,\n",
        "                format_func=lambda x: x.replace('_', ' ').title()\n",
        "            )\n",
        "\n",
        "            if selected_for_detail:\n",
        "                foundations = STAKEHOLDER_PROFILES[selected_for_detail]\n",
        "                explanation = explainer.explain_evaluation(\n",
        "                    policy,\n",
        "                    foundations,\n",
        "                    agent_name=selected_for_detail.replace('_', ' ').title()\n",
        "                )\n",
        "                st.code(explanation, language=\"text\")\n",
        "\n",
        "# =============================================================================\n",
        "# TAB 2: TRUST DYNAMICS DEMO\n",
        "# =============================================================================\n",
        "\n",
        "with tab2:\n",
        "    st.header(\"Trust Evolution Simulation\")\n",
        "\n",
        "    col1, col2 = st.columns([1, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.subheader(\"Configure Interaction\")\n",
        "\n",
        "        agent_a = st.selectbox(\"Agent A\", [\"Government\", \"TechCorp\", \"ConsumerNGO\", \"StandardsBody\"])\n",
        "        agent_b = st.selectbox(\"Agent B\", [\"Government\", \"TechCorp\", \"ConsumerNGO\", \"StandardsBody\"], index=1)\n",
        "\n",
        "        interaction_type = st.select_slider(\n",
        "            \"Interaction Type\",\n",
        "            options=[\"Strong Defection\", \"Mild Defection\", \"Neutral\", \"Mild Cooperation\", \"Strong Cooperation\"],\n",
        "            value=\"Mild Cooperation\"\n",
        "        )\n",
        "\n",
        "        # Map interaction type to numerical values\n",
        "        type_map = {\n",
        "            \"Strong Defection\": (0.2, -0.7),\n",
        "            \"Mild Defection\": (0.4, -0.3),\n",
        "            \"Neutral\": (0.5, 0.0),\n",
        "            \"Mild Cooperation\": (0.7, 0.4),\n",
        "            \"Strong Cooperation\": (0.9, 0.7)\n",
        "        }\n",
        "\n",
        "        cooperation_level, outcome = type_map[interaction_type]\n",
        "\n",
        "        num_rounds = st.slider(\"Number of Rounds\", 1, 20, 10)\n",
        "\n",
        "        if st.button(\"Run Trust Simulation\"):\n",
        "            # Initialize trust states\n",
        "            trust_states = {\n",
        "                agent_a: TrustState(agent_id=agent_a, baseline_trust=0.5),\n",
        "                agent_b: TrustState(agent_id=agent_b, baseline_trust=0.5)\n",
        "            }\n",
        "\n",
        "            engine = TrustDynamicsEngine()\n",
        "\n",
        "            # Track trust evolution\n",
        "            trust_history = []\n",
        "\n",
        "            for round_num in range(num_rounds):\n",
        "                # Create interaction\n",
        "                interaction = InteractionRecord(\n",
        "                    timestep=round_num,\n",
        "                    agent_i=agent_a,\n",
        "                    agent_j=agent_b,\n",
        "                    interaction_type=InteractionType.NEGOTIATION,\n",
        "                    outcome_for_i=outcome + np.random.normal(0, 0.1),\n",
        "                    outcome_for_j=outcome + np.random.normal(0, 0.1),\n",
        "                    cooperation_level=cooperation_level + np.random.normal(0, 0.05)\n",
        "                )\n",
        "\n",
        "                # Update trust\n",
        "                new_trust_ab = engine.update_trust_from_interaction(\n",
        "                    trust_states[agent_a], agent_b, interaction\n",
        "                )\n",
        "\n",
        "                new_trust_ba = engine.update_trust_from_interaction(\n",
        "                    trust_states[agent_b], agent_a, interaction\n",
        "                )\n",
        "\n",
        "                # Apply decay\n",
        "                engine.decay_trust_and_reciprocity(trust_states[agent_a])\n",
        "                engine.decay_trust_and_reciprocity(trust_states[agent_b])\n",
        "\n",
        "                trust_history.append({\n",
        "                    'Round': round_num + 1,\n",
        "                    f'{agent_a} â†’ {agent_b}': new_trust_ab,\n",
        "                    f'{agent_b} â†’ {agent_a}': new_trust_ba\n",
        "                })\n",
        "\n",
        "            # Store in session state\n",
        "            st.session_state.trust_history = trust_history\n",
        "            st.session_state.trust_states = trust_states\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Trust Evolution Over Time\")\n",
        "\n",
        "        if 'trust_history' in st.session_state:\n",
        "            trust_df = pd.DataFrame(st.session_state.trust_history)\n",
        "\n",
        "            fig = go.Figure()\n",
        "\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=trust_df['Round'],\n",
        "                y=trust_df[f'{agent_a} â†’ {agent_b}'],\n",
        "                mode='lines+markers',\n",
        "                name=f'{agent_a} â†’ {agent_b}'\n",
        "            ))\n",
        "\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=trust_df['Round'],\n",
        "                y=trust_df[f'{agent_b} â†’ {agent_a}'],\n",
        "                mode='lines+markers',\n",
        "                name=f'{agent_b} â†’ {agent_a}'\n",
        "            ))\n",
        "\n",
        "            fig.update_layout(\n",
        "                title=\"Trust Level Evolution\",\n",
        "                xaxis_title=\"Round\",\n",
        "                yaxis_title=\"Trust Level\",\n",
        "                yaxis_range=[0, 1],\n",
        "                hovermode='x unified'\n",
        "            )\n",
        "\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            # Final stats\n",
        "            st.markdown(\"### Final Trust State\")\n",
        "\n",
        "            final_trust_ab = trust_df[f'{agent_a} â†’ {agent_b}'].iloc[-1]\n",
        "            final_trust_ba = trust_df[f'{agent_b} â†’ {agent_a}'].iloc[-1]\n",
        "\n",
        "            col_a, col_b = st.columns(2)\n",
        "\n",
        "            with col_a:\n",
        "                st.metric(\n",
        "                    f\"{agent_a} trusts {agent_b}\",\n",
        "                    f\"{final_trust_ab:.2f}\",\n",
        "                    delta=f\"{final_trust_ab - 0.5:+.2f} from baseline\"\n",
        "                )\n",
        "\n",
        "            with col_b:\n",
        "                st.metric(\n",
        "                    f\"{agent_b} trusts {agent_a}\",\n",
        "                    f\"{final_trust_ba:.2f}\",\n",
        "                    delta=f\"{final_trust_ba - 0.5:+.2f} from baseline\"\n",
        "                )\n",
        "\n",
        "# =============================================================================\n",
        "# TAB 3: INTEGRATED AGENTS\n",
        "# =============================================================================\n",
        "\n",
        "with tab3:\n",
        "    st.header(\"Integrated Cognitive Agents\")\n",
        "    st.markdown(\"\"\"\n",
        "    This demonstrates how cognitive architecture combines:\n",
        "    1. **Strategic Value** (game-theoretic payoffs)\n",
        "    2. **Moral Value** (ethical alignment)\n",
        "    3. **Social Value** (trust and reciprocity)\n",
        "    \"\"\")\n",
        "\n",
        "    # Agent configuration\n",
        "    st.subheader(\"Agent Configuration\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        agent_profile = st.selectbox(\n",
        "            \"Select Stakeholder Profile\",\n",
        "            options=list(STAKEHOLDER_PROFILES.keys()),\n",
        "            format_func=lambda x: x.replace('_', ' ').title()\n",
        "        )\n",
        "\n",
        "        # Show moral foundations profile\n",
        "        st.markdown(\"#### Moral Foundations Profile\")\n",
        "\n",
        "        foundations = STAKEHOLDER_PROFILES[agent_profile]\n",
        "        found_dict = foundations.to_dict()\n",
        "\n",
        "        fig = go.Figure()\n",
        "\n",
        "        fig.add_trace(go.Scatterpolar(\n",
        "            r=list(found_dict.values()),\n",
        "            theta=[k.replace('_', '/').title() for k in found_dict.keys()],\n",
        "            fill='toself',\n",
        "            name=agent_profile.replace('_', ' ').title()\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            polar=dict(radialaxis=dict(visible=True, range=[0, 0.5])),\n",
        "            showlegend=False,\n",
        "            height=400\n",
        "        )\n",
        "\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    with col2:\n",
        "        st.markdown(\"#### Decision Weight Configuration\")\n",
        "\n",
        "        instrumental_w = st.slider(\"Instrumental Weight\", 0.0, 1.0, 0.6, 0.05)\n",
        "        moral_w = st.slider(\"Moral Weight\", 0.0, 1.0, 0.3, 0.05)\n",
        "        social_w = st.slider(\"Social Weight\", 0.0, 1.0, 0.1, 0.05)\n",
        "\n",
        "        # Normalize\n",
        "        total = instrumental_w + moral_w + social_w\n",
        "        if total > 0:\n",
        "            instrumental_w /= total\n",
        "            moral_w /= total\n",
        "            social_w /= total\n",
        "\n",
        "        st.markdown(f\"\"\"\n",
        "        **Normalized Weights:**\n",
        "        - Instrumental: {instrumental_w:.2f}\n",
        "        - Moral: {moral_w:.2f}\n",
        "        - Social: {social_w:.2f}\n",
        "        \"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "# TAB 4: SIMULATION RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "with tab4:\n",
        "    st.header(\"Simulation Results\")\n",
        "\n",
        "    st.info(\"ğŸš§ Run a full multi-agent simulation from the main Simulation page to see results here.\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    ### What Gets Tracked:\n",
        "    - **Policy Consensus**: How much agents agree on policies over time\n",
        "    - **Trust Network Evolution**: Changes in trust relationships\n",
        "    - **Coalition Formation**: When agents form alliances\n",
        "    - **Moral Polarization**: Diversity of values in the network\n",
        "    - **Decision Explanations**: Natural language justifications for choices\n",
        "    \"\"\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "<div style='text-align: center; padding: 20px;'>\n",
        "    <h3>ğŸ§  Auracelle Bach | Cognitive Architecture Module</h3>\n",
        "    <p><strong>Human-Inspired Governance Simulation</strong></p>\n",
        "    <p style='font-size: 12px;'>Moral Foundations â€¢ Trust Dynamics â€¢ Value-Weighted Decisions</p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "'''\n",
        "\n",
        "with open('pages/cognitive_demo.py', 'w') as f:\n",
        "    f.write(cognitive_demo_content)\n",
        "\n",
        "print(\"âœ… Cognitive architecture demo page created\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "# NOTE: Policy frameworks are displayed in sidebar of simulation page\n",
        "# See institutional_behavior.py for full framework list\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# INSTITUTIONAL BEHAVIOR MODULES PAGE\n",
        "# =============================================================================\n",
        "\n",
        "institutional_page_content = '''\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "\n",
        "st.set_page_config(page_title=\"Institutional Behavior\", page_icon=\"ğŸ›ï¸\", layout=\"wide\")\n",
        "\n",
        "# =============================================================================\n",
        "# PASSWORD PROTECTION\n",
        "# =============================================================================\n",
        "\n",
        "if 'authenticated' not in st.session_state:\n",
        "    st.session_state.authenticated = False\n",
        "\n",
        "if not st.session_state.authenticated:\n",
        "    st.title(\"ğŸ” Auracelle Bach - Institutional Behavior Modules\")\n",
        "    password = st.text_input(\"Enter password:\", type=\"password\")\n",
        "    if st.button(\"Login\"):\n",
        "        if password == \"charlie2025\":\n",
        "            st.session_state.authenticated = True\n",
        "            st.rerun()\n",
        "        else:\n",
        "            st.error(\"Incorrect password\")\n",
        "    st.stop()\n",
        "\n",
        "# =============================================================================\n",
        "# PAGE HEADER\n",
        "# =============================================================================\n",
        "\n",
        "st.title(\"ğŸ›ï¸ Institutional Behavior Modules\")\n",
        "st.markdown(\"\"\"\n",
        "<div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            padding: 20px; border-radius: 10px; margin-bottom: 20px;'>\n",
        "    <h3 style='color: white; margin: 0;'>Human-Inspired Organizational Cognition</h3>\n",
        "    <p style='color: white; margin: 5px 0 0 0; font-size: 14px;'>\n",
        "        Modeling real institutional decision-making patterns\n",
        "    </p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "### ğŸ¯ Module Overview\n",
        "\n",
        "This page demonstrates three key institutional behavior modules that capture how real\n",
        "organizations make decisions under constraints, biases, and resistance to change.\n",
        "\n",
        "**Modules:**\n",
        "1. **ğŸ§  Bounded Rationality Engine** - Herbert Simon's satisficing theory\n",
        "2. **ğŸ­ Cognitive Bias System** - 6 organizational biases\n",
        "3. **âš™ï¸ Organizational Inertia Modeling** - Change resistance patterns\n",
        "\"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE 1: BOUNDED RATIONALITY ENGINE\n",
        "# =============================================================================\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.header(\"1. ğŸ§  Bounded Rationality Engine\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "**Theoretical Foundation:** Herbert Simon's satisficing theory\n",
        "\n",
        "Organizations don't optimizeâ€”they **satisfice** (satisfy + suffice). They search for\n",
        "\"good enough\" solutions within cognitive and resource constraints.\n",
        "\"\"\")\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.markdown(\"#### Parameters\")\n",
        "\n",
        "    aspiration_level = st.slider(\n",
        "        \"Aspiration Level (minimum acceptable)\",\n",
        "        0.0, 1.0, 0.7, 0.05,\n",
        "        help=\"Minimum performance threshold for acceptance\"\n",
        "    )\n",
        "\n",
        "    search_depth = st.slider(\n",
        "        \"Search Depth (alternatives considered)\",\n",
        "        1, 20, 5, 1,\n",
        "        help=\"Number of alternatives to evaluate before stopping\"\n",
        "    )\n",
        "\n",
        "    cognitive_load = st.slider(\n",
        "        \"Cognitive Load (processing constraints)\",\n",
        "        0.0, 1.0, 0.5, 0.05,\n",
        "        help=\"Higher values = more limited processing capacity\"\n",
        "    )\n",
        "\n",
        "with col2:\n",
        "    st.markdown(\"#### Decision Simulation\")\n",
        "\n",
        "    # Simulate bounded rationality decision-making\n",
        "    np.random.seed(42)\n",
        "\n",
        "    alternatives = []\n",
        "    for i in range(search_depth):\n",
        "        # Quality decreases with cognitive load\n",
        "        base_quality = np.random.beta(2, 2)\n",
        "        adjusted_quality = base_quality * (1 - cognitive_load * 0.5)\n",
        "\n",
        "        alternatives.append({\n",
        "            'Alternative': f'Option {i+1}',\n",
        "            'Quality': adjusted_quality,\n",
        "            'Meets Aspiration': adjusted_quality >= aspiration_level\n",
        "        })\n",
        "\n",
        "    df_alternatives = pd.DataFrame(alternatives)\n",
        "\n",
        "    # Find first satisficing option\n",
        "    satisficing_idx = df_alternatives[df_alternatives['Meets Aspiration']].index\n",
        "\n",
        "    if len(satisficing_idx) > 0:\n",
        "        selected = satisficing_idx[0]\n",
        "        optimal = df_alternatives['Quality'].idxmax()\n",
        "\n",
        "        st.success(f\"âœ… Selected: {df_alternatives.iloc[selected]['Alternative']} \" +\n",
        "                  f\"(Quality: {df_alternatives.iloc[selected]['Quality']:.2f})\")\n",
        "\n",
        "        if selected != optimal:\n",
        "            st.warning(f\"âš ï¸ Not optimal! Best option was {df_alternatives.iloc[optimal]['Alternative']} \" +\n",
        "                      f\"(Quality: {df_alternatives.iloc[optimal]['Quality']:.2f})\")\n",
        "        else:\n",
        "            st.info(\"ğŸ¯ Satisficing solution is also optimal!\")\n",
        "    else:\n",
        "        st.error(\"âŒ No alternatives meet aspiration level - search continues or threshold lowers\")\n",
        "\n",
        "# Visualization\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=df_alternatives['Alternative'],\n",
        "    y=df_alternatives['Quality'],\n",
        "    marker_color=['green' if m else 'red' for m in df_alternatives['Meets Aspiration']],\n",
        "    text=[f\"{q:.2f}\" for q in df_alternatives['Quality']],\n",
        "    textposition='auto',\n",
        "))\n",
        "\n",
        "fig.add_hline(y=aspiration_level, line_dash=\"dash\", line_color=\"blue\",\n",
        "              annotation_text=\"Aspiration Level\", annotation_position=\"right\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Bounded Rationality: Search Process\",\n",
        "    xaxis_title=\"Alternatives (evaluated in order)\",\n",
        "    yaxis_title=\"Quality Score\",\n",
        "    yaxis_range=[0, 1],\n",
        "    height=400\n",
        ")\n",
        "\n",
        "st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "**Key Insights:**\n",
        "- Organizations stop searching when they find \"good enough\" (green bars)\n",
        "- Cognitive load reduces perceived quality of alternatives\n",
        "- Satisficing â‰  optimizing (may miss better options evaluated later)\n",
        "\"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE 2: COGNITIVE BIAS SYSTEM\n",
        "# =============================================================================\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.header(\"2. ğŸ­ Cognitive Bias System\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "**Six Organizational Biases:**\n",
        "\n",
        "Organizations systematically deviate from rational decision-making due to cognitive biases.\n",
        "\"\"\")\n",
        "\n",
        "# Bias definitions\n",
        "biases = {\n",
        "    \"Status Quo Bias\": {\n",
        "        \"description\": \"Preference for current state; resistance to change\",\n",
        "        \"impact\": \"Underweights benefits of new policies\",\n",
        "        \"example\": \"Keeping legacy AI governance despite better alternatives\"\n",
        "    },\n",
        "    \"Confirmation Bias\": {\n",
        "        \"description\": \"Seeking information that confirms existing beliefs\",\n",
        "        \"impact\": \"Ignores contradictory evidence\",\n",
        "        \"example\": \"Only reviewing studies supporting current approach\"\n",
        "    },\n",
        "    \"Availability Bias\": {\n",
        "        \"description\": \"Overweighting easily recalled information\",\n",
        "        \"impact\": \"Recent/dramatic events dominate decisions\",\n",
        "        \"example\": \"Overreacting to recent AI incident\"\n",
        "    },\n",
        "    \"Anchoring Bias\": {\n",
        "        \"description\": \"Over-relying on first piece of information\",\n",
        "        \"impact\": \"Initial proposals constrain negotiation range\",\n",
        "        \"example\": \"First country's proposal sets agenda\"\n",
        "    },\n",
        "    \"Loss Aversion\": {\n",
        "        \"description\": \"Losses loom larger than equivalent gains\",\n",
        "        \"impact\": \"Risk-averse decision-making\",\n",
        "        \"example\": \"Rejecting beneficial but uncertain AI policy\"\n",
        "    },\n",
        "    \"Groupthink\": {\n",
        "        \"description\": \"Conformity pressure suppresses dissent\",\n",
        "        \"impact\": \"Poor decisions due to consensus pressure\",\n",
        "        \"example\": \"Committee adopts flawed policy to maintain harmony\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Interactive bias selector\n",
        "selected_bias = st.selectbox(\"Select Bias to Explore:\", list(biases.keys()))\n",
        "\n",
        "col1, col2 = st.columns([1, 1])\n",
        "\n",
        "with col1:\n",
        "    st.markdown(f\"#### {selected_bias}\")\n",
        "    st.markdown(f\"**Definition:** {biases[selected_bias]['description']}\")\n",
        "    st.markdown(f\"**Impact:** {biases[selected_bias]['impact']}\")\n",
        "    st.markdown(f\"**Example:** {biases[selected_bias]['example']}\")\n",
        "\n",
        "with col2:\n",
        "    st.markdown(\"#### Bias Strength Simulation\")\n",
        "\n",
        "    bias_strength = st.slider(\n",
        "        \"Bias Intensity\",\n",
        "        0.0, 1.0, 0.5, 0.05,\n",
        "        help=\"How strongly this bias affects decisions\"\n",
        "    )\n",
        "\n",
        "    # Simulate bias impact on decision quality\n",
        "    rational_score = 0.8  # Unbiased decision quality\n",
        "    biased_score = rational_score * (1 - bias_strength * 0.4)\n",
        "\n",
        "    st.metric(\"Rational Decision Quality\", f\"{rational_score:.2f}\")\n",
        "    st.metric(\"Biased Decision Quality\", f\"{biased_score:.2f}\",\n",
        "              delta=f\"{biased_score - rational_score:.2f}\")\n",
        "\n",
        "    # Show bias adjustment\n",
        "    st.markdown(f\"\"\"\n",
        "    **Adjustment:** Decision quality reduced by {(rational_score - biased_score)*100:.1f}%\n",
        "    \"\"\")\n",
        "\n",
        "# Multi-bias interaction\n",
        "st.markdown(\"#### Multi-Bias Interaction\")\n",
        "\n",
        "col1, col2, col3 = st.columns(3)\n",
        "\n",
        "with col1:\n",
        "    status_quo = st.slider(\"Status Quo\", 0.0, 1.0, 0.3, 0.1, key='sq')\n",
        "    confirmation = st.slider(\"Confirmation\", 0.0, 1.0, 0.3, 0.1, key='cf')\n",
        "\n",
        "with col2:\n",
        "    availability = st.slider(\"Availability\", 0.0, 1.0, 0.3, 0.1, key='av')\n",
        "    anchoring = st.slider(\"Anchoring\", 0.0, 1.0, 0.3, 0.1, key='an')\n",
        "\n",
        "with col3:\n",
        "    loss_aversion = st.slider(\"Loss Aversion\", 0.0, 1.0, 0.3, 0.1, key='la')\n",
        "    groupthink = st.slider(\"Groupthink\", 0.0, 1.0, 0.3, 0.1, key='gt')\n",
        "\n",
        "# Calculate combined bias effect\n",
        "bias_values = [status_quo, confirmation, availability, anchoring, loss_aversion, groupthink]\n",
        "combined_bias = 1 - np.prod([1 - b*0.15 for b in bias_values])\n",
        "\n",
        "# Visualization\n",
        "bias_df = pd.DataFrame({\n",
        "    'Bias': ['Status Quo', 'Confirmation', 'Availability', 'Anchoring', 'Loss Aversion', 'Groupthink'],\n",
        "    'Strength': bias_values\n",
        "})\n",
        "\n",
        "fig = px.bar(bias_df, x='Bias', y='Strength',\n",
        "             title=f\"Bias Profile (Combined Effect: {combined_bias:.2%} reduction)\",\n",
        "             color='Strength',\n",
        "             color_continuous_scale='Reds')\n",
        "fig.update_layout(height=400)\n",
        "st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "st.markdown(f\"\"\"\n",
        "**Combined Impact:** With these bias levels, organizational decision quality is reduced by\n",
        "approximately **{combined_bias*100:.1f}%** from the rational baseline.\n",
        "\"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE 3: ORGANIZATIONAL INERTIA MODELING\n",
        "# =============================================================================\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.header(\"3. âš™ï¸ Organizational Inertia Modeling\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "**Theoretical Foundation:** Change resistance patterns\n",
        "\n",
        "Organizations resist change due to:\n",
        "- Structural inertia (established procedures, roles, systems)\n",
        "- Cultural inertia (norms, values, identity)\n",
        "- Political inertia (power structures, coalitions)\n",
        "\"\"\")\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.markdown(\"#### Inertia Parameters\")\n",
        "\n",
        "    org_age = st.slider(\"Organization Age (years)\", 1, 50, 15, 1,\n",
        "                       help=\"Older organizations have stronger inertia\")\n",
        "\n",
        "    change_magnitude = st.slider(\"Change Magnitude\", 0.0, 1.0, 0.5, 0.05,\n",
        "                                 help=\"How radical is the proposed change\")\n",
        "\n",
        "    external_pressure = st.slider(\"External Pressure\", 0.0, 1.0, 0.3, 0.05,\n",
        "                                  help=\"Environmental forces demanding change\")\n",
        "\n",
        "    leadership_commitment = st.slider(\"Leadership Commitment\", 0.0, 1.0, 0.6, 0.05,\n",
        "                                     help=\"How committed leadership is to change\")\n",
        "\n",
        "with col2:\n",
        "    st.markdown(\"#### Inertia Calculation\")\n",
        "\n",
        "    # Calculate inertia components\n",
        "    structural_inertia = min(1.0, org_age / 30)  # Increases with age\n",
        "    cultural_inertia = 0.7  # Relatively constant\n",
        "    political_inertia = 0.6 * (1 - leadership_commitment)  # Decreases with leadership\n",
        "\n",
        "    # Total inertia\n",
        "    base_inertia = (structural_inertia + cultural_inertia + political_inertia) / 3\n",
        "\n",
        "    # Change resistance increases with magnitude\n",
        "    change_resistance = base_inertia * (1 + change_magnitude)\n",
        "\n",
        "    # Success probability\n",
        "    change_success_prob = external_pressure * leadership_commitment / (1 + change_resistance)\n",
        "\n",
        "    st.metric(\"Structural Inertia\", f\"{structural_inertia:.2f}\")\n",
        "    st.metric(\"Cultural Inertia\", f\"{cultural_inertia:.2f}\")\n",
        "    st.metric(\"Political Inertia\", f\"{political_inertia:.2f}\")\n",
        "    st.markdown(\"---\")\n",
        "    st.metric(\"Total Change Resistance\", f\"{change_resistance:.2f}\")\n",
        "    st.metric(\"Change Success Probability\", f\"{change_success_prob:.2%}\")\n",
        "\n",
        "# Visualization: Inertia over time\n",
        "st.markdown(\"#### Change Adoption Timeline\")\n",
        "\n",
        "time_periods = np.arange(0, 24, 1)  # 24 months\n",
        "adoption_curve = []\n",
        "\n",
        "for t in time_periods:\n",
        "    # S-curve adoption with inertia delay\n",
        "    time_adjusted = t - (change_resistance * 6)  # Inertia delays adoption\n",
        "    if time_adjusted < 0:\n",
        "        adoption = 0\n",
        "    else:\n",
        "        adoption = change_success_prob / (1 + np.exp(-0.4 * (time_adjusted - 8)))\n",
        "    adoption_curve.append(adoption)\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=time_periods,\n",
        "    y=adoption_curve,\n",
        "    mode='lines',\n",
        "    name='Adoption Rate',\n",
        "    line=dict(color='blue', width=3)\n",
        "))\n",
        "\n",
        "# Add resistance threshold\n",
        "fig.add_hline(y=0.5, line_dash=\"dash\", line_color=\"red\",\n",
        "              annotation_text=\"50% Adoption\", annotation_position=\"right\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Organizational Change Adoption Over Time\",\n",
        "    xaxis_title=\"Months\",\n",
        "    yaxis_title=\"Adoption Rate\",\n",
        "    yaxis_range=[0, 1],\n",
        "    height=400\n",
        ")\n",
        "\n",
        "st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "**Key Insights:**\n",
        "- High inertia delays change adoption (flat initial curve)\n",
        "- External pressure and leadership commitment can overcome inertia\n",
        "- S-curve pattern: slow start â†’ rapid adoption â†’ plateau\n",
        "\"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "# INTEGRATED DEMONSTRATION\n",
        "# =============================================================================\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.header(\"ğŸ¯ Integrated Demonstration\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "### Real-World Scenario: EU AI Act Implementation\n",
        "\n",
        "Watch how all three modules interact when an organization faces implementing the EU AI Act.\n",
        "\"\"\")\n",
        "\n",
        "col1, col2, col3 = st.columns(3)\n",
        "\n",
        "with col1:\n",
        "    st.markdown(\"**ğŸ§  Bounded Rationality**\")\n",
        "    st.markdown(\"Organization searches for compliance approach\")\n",
        "    st.markdown(\"- Aspiration: 'Good enough' compliance\")\n",
        "    st.markdown(\"- Stops at first acceptable option\")\n",
        "    st.markdown(\"- Misses optimal solution\")\n",
        "\n",
        "with col2:\n",
        "    st.markdown(\"**ğŸ­ Cognitive Biases**\")\n",
        "    st.markdown(\"Multiple biases distort decision\")\n",
        "    st.markdown(\"- Status quo: Prefer minimal change\")\n",
        "    st.markdown(\"- Anchoring: First proposal dominates\")\n",
        "    st.markdown(\"- Loss aversion: Focus on costs\")\n",
        "\n",
        "with col3:\n",
        "    st.markdown(\"**âš™ï¸ Organizational Inertia**\")\n",
        "    st.markdown(\"Resistance slows implementation\")\n",
        "    st.markdown(\"- Structural: Existing processes\")\n",
        "    st.markdown(\"- Cultural: 'We've always done it this way'\")\n",
        "    st.markdown(\"- Political: Department conflicts\")\n",
        "\n",
        "# Simulation results\n",
        "st.markdown(\"#### Simulation Results\")\n",
        "\n",
        "# Simulate combined effect\n",
        "rational_timeline = 6  # months\n",
        "rational_quality = 0.9\n",
        "\n",
        "# Bounded rationality effect\n",
        "satisficing_quality = 0.7  # Good enough, not optimal\n",
        "\n",
        "# Bias effect\n",
        "biased_quality = satisficing_quality * (1 - combined_bias)\n",
        "\n",
        "# Inertia effect\n",
        "actual_timeline = rational_timeline * (1 + change_resistance)\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.metric(\"Rational Approach\",\n",
        "             f\"Quality: {rational_quality:.2f} | Time: {rational_timeline} months\")\n",
        "    st.metric(\"Actual Approach\",\n",
        "             f\"Quality: {biased_quality:.2f} | Time: {actual_timeline:.1f} months\",\n",
        "             delta=f\"-{(rational_quality - biased_quality)*100:.0f}% quality\")\n",
        "\n",
        "with col2:\n",
        "    # Show breakdown\n",
        "    st.markdown(\"**Quality Degradation:**\")\n",
        "    st.markdown(f\"1. Satisficing: {rational_quality:.2f} â†’ {satisficing_quality:.2f}\")\n",
        "    st.markdown(f\"2. Biases: {satisficing_quality:.2f} â†’ {biased_quality:.2f}\")\n",
        "    st.markdown(f\"3. Inertia: Delays by {(actual_timeline - rational_timeline):.1f} months\")\n",
        "\n",
        "# =============================================================================\n",
        "# FOOTER\n",
        "# =============================================================================\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "<div style='text-align: center; padding: 20px;'>\n",
        "    <h3>ğŸ›ï¸ Auracelle Bach | Institutional Behavior Modules</h3>\n",
        "    <p><strong>Human-Inspired Organizational Cognition</strong></p>\n",
        "    <p style='font-size: 12px;'>Bounded Rationality â€¢ Cognitive Biases â€¢ Organizational Inertia</p>\n",
        "    <p style='font-size: 10px; color: #666;'>\n",
        "        Based on: Simon (1956) â€¢ Kahneman & Tversky (1979) â€¢ Hannan & Freeman (1984)\n",
        "    </p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "'''\n",
        "\n",
        "with open('pages/institutional_behavior.py', 'w') as f:\n",
        "    f.write(institutional_page_content)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 3D AI GOVERNANCE COORDINATION VISUALIZATION PAGE\n",
        "# =============================================================================\n",
        "\n",
        "viz_3d_content = '''\n",
        "import streamlit as st\n",
        "import streamlit.components.v1 as components\n",
        "\n",
        "st.set_page_config(page_title=\"3D Governance Visualization\", page_icon=\"ğŸŒ\", layout=\"wide\")\n",
        "\n",
        "# =============================================================================\n",
        "# PASSWORD PROTECTION\n",
        "# =============================================================================\n",
        "\n",
        "if 'authenticated' not in st.session_state:\n",
        "    st.session_state.authenticated = False\n",
        "\n",
        "if not st.session_state.authenticated:\n",
        "    st.title(\"ğŸ” Auracelle Bach - 3D Coordination Visualization\")\n",
        "    password = st.text_input(\"Enter password:\", type=\"password\")\n",
        "    if st.button(\"Login\"):\n",
        "        if password == \"charlie2025\":\n",
        "            st.session_state.authenticated = True\n",
        "            st.rerun()\n",
        "        else:\n",
        "            st.error(\"Incorrect password\")\n",
        "    st.stop()\n",
        "\n",
        "# =============================================================================\n",
        "# PAGE HEADER\n",
        "# =============================================================================\n",
        "\n",
        "st.title(\"ğŸŒ 3D AI Governance Coordination\")\n",
        "st.markdown(\"\"\"\n",
        "<div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            padding: 20px; border-radius: 10px; margin-bottom: 20px;'>\n",
        "    <h3 style='color: white; margin: 0;'>Like AlphaFold for Policy Alignment</h3>\n",
        "    <p style='color: white; margin: 5px 0 0 0; font-size: 14px;'>\n",
        "        Interactive Multi-Stakeholder Policy Alignment in 3D Space\n",
        "    </p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "### ğŸ¯ Visualization Overview\n",
        "\n",
        "This 3D visualization shows AI governance coordination challenges the same way AlphaFold shows protein structures:\n",
        "\n",
        "**The 3D Space:**\n",
        "- **X-axis**: Safety/Ethics regulations (0 = permissive, 1 = strict)\n",
        "- **Y-axis**: Innovation/Development policies (0 = restrictive, 1 = supportive)\n",
        "- **Z-axis**: Data governance standards (0 = minimal, 1 = comprehensive)\n",
        "\n",
        "**Each node represents:**\n",
        "- Countries (US, EU, China, UK, Japan, etc.)\n",
        "- International organizations (UNESCO, OECD, NATO, UN, WEF)\n",
        "\n",
        "**Closer nodes = More aligned policies**\n",
        "\n",
        "**Color coding:**\n",
        "- ğŸ”µ Blue = High alignment stakeholders\n",
        "- ğŸŸ  Orange = Medium alignment\n",
        "- ğŸ”´ Red = Low alignment (different approach)\n",
        "- ğŸŸ¢ Green = Policy leaders (international orgs)\n",
        "\"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "# EMBED THE 3D VISUALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "html_code = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <style>\n",
        "        * { margin: 0; padding: 0; box-sizing: border-box; }\n",
        "        body {\n",
        "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\n",
        "            background: #0a0e27;\n",
        "            color: #e0e7ff;\n",
        "        }\n",
        "        .container {\n",
        "            display: grid;\n",
        "            grid-template-columns: 280px 1fr;\n",
        "            gap: 1rem;\n",
        "            padding: 1rem;\n",
        "            height: 100vh;\n",
        "        }\n",
        "        .controls {\n",
        "            background: rgba(26, 31, 58, 0.8);\n",
        "            border: 1px solid rgba(102, 126, 234, 0.2);\n",
        "            border-radius: 12px;\n",
        "            padding: 1rem;\n",
        "            overflow-y: auto;\n",
        "        }\n",
        "        .control-section { margin-bottom: 1.5rem; }\n",
        "        .control-section h3 {\n",
        "            font-size: 0.75rem;\n",
        "            text-transform: uppercase;\n",
        "            letter-spacing: 1px;\n",
        "            color: #667eea;\n",
        "            margin-bottom: 0.75rem;\n",
        "        }\n",
        "        .control-group { margin-bottom: 1rem; }\n",
        "        .control-group label {\n",
        "            display: block;\n",
        "            font-size: 0.75rem;\n",
        "            color: #94a3b8;\n",
        "            margin-bottom: 0.4rem;\n",
        "        }\n",
        "        .slider {\n",
        "            width: 100%;\n",
        "            height: 4px;\n",
        "            background: rgba(102, 126, 234, 0.2);\n",
        "            border-radius: 2px;\n",
        "            -webkit-appearance: none;\n",
        "        }\n",
        "        .slider::-webkit-slider-thumb {\n",
        "            -webkit-appearance: none;\n",
        "            width: 14px;\n",
        "            height: 14px;\n",
        "            background: linear-gradient(135deg, #667eea, #f093fb);\n",
        "            border-radius: 50%;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "        .slider::-moz-range-thumb {\n",
        "            width: 14px;\n",
        "            height: 14px;\n",
        "            background: linear-gradient(135deg, #667eea, #f093fb);\n",
        "            border-radius: 50%;\n",
        "            cursor: pointer;\n",
        "            border: none;\n",
        "        }\n",
        "        .value {\n",
        "            display: inline-block;\n",
        "            margin-left: 0.5rem;\n",
        "            padding: 2px 6px;\n",
        "            background: rgba(102, 126, 234, 0.15);\n",
        "            border-radius: 3px;\n",
        "            font-size: 0.7rem;\n",
        "            color: #f093fb;\n",
        "        }\n",
        "        .button {\n",
        "            width: 100%;\n",
        "            padding: 0.6rem;\n",
        "            background: linear-gradient(135deg, #667eea, #764ba2);\n",
        "            border: none;\n",
        "            border-radius: 6px;\n",
        "            color: white;\n",
        "            font-weight: 600;\n",
        "            cursor: pointer;\n",
        "            font-size: 0.8rem;\n",
        "            margin-top: 0.5rem;\n",
        "        }\n",
        "        .button:hover { opacity: 0.9; }\n",
        "        .button.secondary {\n",
        "            background: rgba(102, 126, 234, 0.15);\n",
        "            border: 1px solid rgba(102, 126, 234, 0.3);\n",
        "        }\n",
        "        .scenario-btn {\n",
        "            padding: 0.5rem;\n",
        "            background: rgba(102, 126, 234, 0.1);\n",
        "            border: 1px solid rgba(102, 126, 234, 0.2);\n",
        "            border-radius: 5px;\n",
        "            color: #e0e7ff;\n",
        "            font-size: 0.7rem;\n",
        "            cursor: pointer;\n",
        "            margin-bottom: 0.4rem;\n",
        "            text-align: center;\n",
        "        }\n",
        "        .scenario-btn:hover { background: rgba(102, 126, 234, 0.2); }\n",
        "        .scenario-btn.active {\n",
        "            background: linear-gradient(135deg, #667eea, #764ba2);\n",
        "            border-color: transparent;\n",
        "        }\n",
        "        #canvas { width: 100%; height: 100%; border-radius: 8px; }\n",
        "        .stats {\n",
        "            position: absolute;\n",
        "            top: 1rem;\n",
        "            right: 1rem;\n",
        "            background: rgba(10, 14, 39, 0.9);\n",
        "            border: 1px solid rgba(102, 126, 234, 0.2);\n",
        "            border-radius: 8px;\n",
        "            padding: 0.75rem;\n",
        "            min-width: 160px;\n",
        "        }\n",
        "        .stat { margin-bottom: 0.5rem; font-size: 0.7rem; }\n",
        "        .stat-label { color: #94a3b8; display: block; margin-bottom: 0.2rem; }\n",
        "        .stat-value {\n",
        "            color: #e0e7ff;\n",
        "            font-size: 1rem;\n",
        "            font-weight: 700;\n",
        "        }\n",
        "        .viz-container { position: relative; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <div class=\"controls\">\n",
        "            <div class=\"control-section\">\n",
        "                <h3>Scenarios</h3>\n",
        "                <button class=\"scenario-btn active\" onclick=\"loadScenario('fragmented')\">Fragmented Policies</button>\n",
        "                <button class=\"scenario-btn\" onclick=\"loadScenario('convergence')\">Path to Convergence</button>\n",
        "                <button class=\"scenario-btn\" onclick=\"loadScenario('resistance')\">High Resistance</button>\n",
        "                <button class=\"scenario-btn\" onclick=\"loadScenario('optimal')\">Optimal Alignment</button>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"control-section\">\n",
        "                <h3>Parameters</h3>\n",
        "                <div class=\"control-group\">\n",
        "                    <label>Coordination Pressure <span class=\"value\" id=\"pv\">50%</span></label>\n",
        "                    <input type=\"range\" class=\"slider\" id=\"pressure\" min=\"0\" max=\"100\" value=\"50\" oninput=\"update()\">\n",
        "                </div>\n",
        "                <div class=\"control-group\">\n",
        "                    <label>Institutional Inertia <span class=\"value\" id=\"iv\">0.5</span></label>\n",
        "                    <input type=\"range\" class=\"slider\" id=\"inertia\" min=\"0\" max=\"100\" value=\"50\" oninput=\"update()\">\n",
        "                </div>\n",
        "                <div class=\"control-group\">\n",
        "                    <label>Trust Network <span class=\"value\" id=\"tv\">60%</span></label>\n",
        "                    <input type=\"range\" class=\"slider\" id=\"trust\" min=\"0\" max=\"100\" value=\"60\" oninput=\"update()\">\n",
        "                </div>\n",
        "                <div class=\"control-group\">\n",
        "                    <label>Time Evolution <span class=\"value\" id=\"tmv\">0 mo</span></label>\n",
        "                    <input type=\"range\" class=\"slider\" id=\"time\" min=\"0\" max=\"24\" value=\"0\" oninput=\"update()\">\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"control-section\">\n",
        "                <h3>Animation</h3>\n",
        "                <button class=\"button\" onclick=\"toggleAnim()\"><span id=\"at\">â–¶ Start</span></button>\n",
        "                <button class=\"button secondary\" onclick=\"reset()\">â†º Reset</button>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"viz-container\">\n",
        "            <canvas id=\"canvas\"></canvas>\n",
        "            <div class=\"stats\">\n",
        "                <div class=\"stat\">\n",
        "                    <span class=\"stat-label\">Global Alignment</span>\n",
        "                    <span class=\"stat-value\" id=\"as\">42%</span>\n",
        "                </div>\n",
        "                <div class=\"stat\">\n",
        "                    <span class=\"stat-label\">Stakeholders</span>\n",
        "                    <span class=\"stat-value\">15</span>\n",
        "                </div>\n",
        "                <div class=\"stat\">\n",
        "                    <span class=\"stat-label\">Clusters</span>\n",
        "                    <span class=\"stat-value\" id=\"cs\">5</span>\n",
        "                </div>\n",
        "                <div class=\"stat\">\n",
        "                    <span class=\"stat-label\">Convergence</span>\n",
        "                    <span class=\"stat-value\" id=\"ct\">18 mo</span>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js\"></script>\n",
        "    <script>\n",
        "        let scene, camera, renderer, nodes = [], edges = [], isAnim = false;\n",
        "        const stakeholders = [\n",
        "            {id:'US',p:[0.6,0.4,0.8],c:0x667eea},{id:'EU',p:[0.8,0.7,0.6],c:0x764ba2},\n",
        "            {id:'CN',p:[0.3,0.8,0.5],c:0xef4444},{id:'UK',p:[0.7,0.5,0.7],c:0x667eea},\n",
        "            {id:'JP',p:[0.6,0.6,0.7],c:0xf59e0b},{id:'IN',p:[0.4,0.5,0.6],c:0xf59e0b},\n",
        "            {id:'CA',p:[0.7,0.6,0.8],c:0x667eea},{id:'AU',p:[0.6,0.5,0.7],c:0x667eea},\n",
        "            {id:'KR',p:[0.5,0.6,0.7],c:0xf59e0b},{id:'BR',p:[0.4,0.4,0.5],c:0xef4444},\n",
        "            {id:'UNESCO',p:[0.7,0.8,0.7],c:0x10b981},{id:'OECD',p:[0.8,0.7,0.8],c:0x10b981},\n",
        "            {id:'NATO',p:[0.7,0.6,0.8],c:0x10b981},{id:'WEF',p:[0.6,0.7,0.6],c:0x10b981},\n",
        "            {id:'UN',p:[0.7,0.7,0.7],c:0x10b981}\n",
        "        ];\n",
        "\n",
        "        function init() {\n",
        "            const c = document.getElementById('canvas');\n",
        "            const w = c.clientWidth, h = c.clientHeight;\n",
        "            scene = new THREE.Scene();\n",
        "            camera = new THREE.PerspectiveCamera(60, w/h, 0.1, 1000);\n",
        "            camera.position.set(0,0,20);\n",
        "            renderer = new THREE.WebGLRenderer({canvas:c, antialias:true, alpha:true});\n",
        "            renderer.setSize(w,h);\n",
        "            renderer.setClearColor(0x0a0e27,1);\n",
        "\n",
        "            const al = new THREE.AmbientLight(0xffffff,0.4);\n",
        "            scene.add(al);\n",
        "            const pl1 = new THREE.PointLight(0x667eea,1,100);\n",
        "            pl1.position.set(10,10,10);\n",
        "            scene.add(pl1);\n",
        "\n",
        "            stakeholders.forEach((s,i) => {\n",
        "                const g = new THREE.SphereGeometry(0.3,32,32);\n",
        "                const m = new THREE.MeshPhongMaterial({color:s.c,emissive:s.c,emissiveIntensity:0.3});\n",
        "                const mesh = new THREE.Mesh(g,m);\n",
        "                mesh.position.set((s.p[0]-0.5)*15,(s.p[1]-0.5)*15,(s.p[2]-0.5)*15);\n",
        "                scene.add(mesh);\n",
        "\n",
        "                const sp = makeLabel(s.id);\n",
        "                sp.position.copy(mesh.position);\n",
        "                sp.position.y += 0.6;\n",
        "                scene.add(sp);\n",
        "\n",
        "                nodes.push({mesh,sp,init:mesh.position.clone(),tgt:mesh.position.clone()});\n",
        "            });\n",
        "\n",
        "            updateEdges();\n",
        "            animate();\n",
        "        }\n",
        "\n",
        "        function makeLabel(t) {\n",
        "            const cv = document.createElement('canvas');\n",
        "            const ctx = cv.getContext('2d');\n",
        "            cv.width = 256; cv.height = 128;\n",
        "            ctx.fillStyle = '#fff';\n",
        "            ctx.font = 'Bold 48px Arial';\n",
        "            ctx.textAlign = 'center';\n",
        "            ctx.fillText(t,128,80);\n",
        "            const tx = new THREE.Texture(cv);\n",
        "            tx.needsUpdate = true;\n",
        "            const mt = new THREE.SpriteMaterial({map:tx});\n",
        "            const sp = new THREE.Sprite(mt);\n",
        "            sp.scale.set(2,1,1);\n",
        "            return sp;\n",
        "        }\n",
        "\n",
        "        function updateEdges() {\n",
        "            edges.forEach(e => scene.remove(e.line));\n",
        "            edges = [];\n",
        "            const tr = parseInt(document.getElementById('trust').value)/100;\n",
        "            const th = 0.3 - (tr*0.2);\n",
        "            for(let i=0;i<nodes.length;i++) {\n",
        "                for(let j=i+1;j<nodes.length;j++) {\n",
        "                    const d = nodes[i].mesh.position.distanceTo(nodes[j].mesh.position);\n",
        "                    if(d < 15*th) {\n",
        "                        const mt = new THREE.LineBasicMaterial({color:0x667eea,opacity:Math.max(0.1,1-d/5),transparent:true});\n",
        "                        const gm = new THREE.BufferGeometry().setFromPoints([nodes[i].mesh.position,nodes[j].mesh.position]);\n",
        "                        const ln = new THREE.Line(gm,mt);\n",
        "                        scene.add(ln);\n",
        "                        edges.push({line:ln});\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        function update() {\n",
        "            const p = parseInt(document.getElementById('pressure').value)/100;\n",
        "            const in_ = parseInt(document.getElementById('inertia').value)/100;\n",
        "            const tr = parseInt(document.getElementById('trust').value)/100;\n",
        "            const tm = parseInt(document.getElementById('time').value);\n",
        "\n",
        "            document.getElementById('pv').textContent = Math.round(p*100)+'%';\n",
        "            document.getElementById('iv').textContent = in_.toFixed(2);\n",
        "            document.getElementById('tv').textContent = Math.round(tr*100)+'%';\n",
        "            document.getElementById('tmv').textContent = tm+' mo';\n",
        "\n",
        "            const spd = p*(1-in_)*tr;\n",
        "            const prg = Math.min(1,(tm/24)*spd*2);\n",
        "\n",
        "            const ctr = new THREE.Vector3(0,0,0);\n",
        "            nodes.forEach(n => ctr.add(n.init));\n",
        "            ctr.divideScalar(nodes.length);\n",
        "\n",
        "            nodes.forEach(n => {\n",
        "                const dir = ctr.clone().sub(n.init);\n",
        "                n.tgt.copy(n.init).add(dir.multiplyScalar(prg));\n",
        "                n.mesh.position.lerp(n.tgt,0.1);\n",
        "                n.sp.position.copy(n.mesh.position);\n",
        "                n.sp.position.y += 0.6;\n",
        "            });\n",
        "\n",
        "            updateEdges();\n",
        "\n",
        "            const al = Math.round(prg*100);\n",
        "            document.getElementById('as').textContent = al+'%';\n",
        "            document.getElementById('cs').textContent = Math.max(1,Math.round(5*(1-prg)));\n",
        "            document.getElementById('ct').textContent = Math.round(24*(1/Math.max(0.01,spd)))+' mo';\n",
        "        }\n",
        "\n",
        "        function animate() {\n",
        "            requestAnimationFrame(animate);\n",
        "            const t = Date.now()*0.0001;\n",
        "            camera.position.x = Math.sin(t)*20;\n",
        "            camera.position.z = Math.cos(t)*20;\n",
        "            camera.lookAt(scene.position);\n",
        "            renderer.render(scene,camera);\n",
        "        }\n",
        "\n",
        "        function toggleAnim() {\n",
        "            isAnim = !isAnim;\n",
        "            document.getElementById('at').textContent = isAnim ? 'â¸ Pause' : 'â–¶ Start';\n",
        "            if(isAnim) runAnim();\n",
        "        }\n",
        "\n",
        "        function runAnim() {\n",
        "            if(!isAnim) return;\n",
        "            const ts = document.getElementById('time');\n",
        "            let v = parseInt(ts.value);\n",
        "            if(v<24) {\n",
        "                v += 0.5;\n",
        "                ts.value = v;\n",
        "                update();\n",
        "                setTimeout(runAnim,100);\n",
        "            } else {\n",
        "                isAnim = false;\n",
        "                document.getElementById('at').textContent = 'â†º Restart';\n",
        "            }\n",
        "        }\n",
        "\n",
        "        function reset() {\n",
        "            isAnim = false;\n",
        "            document.getElementById('at').textContent = 'â–¶ Start';\n",
        "            document.getElementById('time').value = 0;\n",
        "            document.getElementById('pressure').value = 50;\n",
        "            document.getElementById('inertia').value = 50;\n",
        "            document.getElementById('trust').value = 60;\n",
        "            nodes.forEach(n => {\n",
        "                n.mesh.position.copy(n.init);\n",
        "                n.sp.position.copy(n.mesh.position);\n",
        "                n.sp.position.y += 0.6;\n",
        "            });\n",
        "            update();\n",
        "        }\n",
        "\n",
        "        function loadScenario(s) {\n",
        "            document.querySelectorAll('.scenario-btn').forEach(b => b.classList.remove('active'));\n",
        "            event.target.classList.add('active');\n",
        "            reset();\n",
        "            const vals = {\n",
        "                fragmented:[30,70,40],\n",
        "                convergence:[70,40,75],\n",
        "                resistance:[50,85,30],\n",
        "                optimal:[90,20,90]\n",
        "            }[s];\n",
        "            document.getElementById('pressure').value = vals[0];\n",
        "            document.getElementById('inertia').value = vals[1];\n",
        "            document.getElementById('trust').value = vals[2];\n",
        "            update();\n",
        "        }\n",
        "\n",
        "        window.addEventListener('load',init);\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Embed the HTML\n",
        "components.html(html_code, height=800, scrolling=False)\n",
        "\n",
        "# User scrolls down to see strategic recommendations below\n",
        "\n",
        "# STRATEGY RECOMMENDATIONS PANEL\n",
        "# =============================================================================\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"### ğŸ¯ Strategic Recommendations\")\n",
        "\n",
        "st.info(\"\"\"\n",
        "**Auracelle Bach Intelligence Engine**: Based on current parameters and scenario,\n",
        "here's the optimal pathway to achieve coordination.\n",
        "\"\"\")\n",
        "\n",
        "# Create tabs for different recommendation types\n",
        "rec_tab1, rec_tab2, rec_tab3 = st.tabs([\"ğŸŒ Country Actions\", \"ğŸ“Š Policy Adjustments\", \"â±ï¸ Timeline & Milestones\"])\n",
        "\n",
        "with rec_tab1:\n",
        "    st.markdown(\"#### Required Actions by Stakeholder\")\n",
        "    st.markdown(\"\"\"\n",
        "    These recommendations show **what each country/organization needs to do** to achieve\n",
        "    the selected scenario outcome.\n",
        "    \"\"\")\n",
        "\n",
        "    # Sample strategy recommendations (in real deployment, these would be dynamically generated)\n",
        "    recommendations = {\n",
        "        'fragmented': {\n",
        "            'US': {\n",
        "                'action': 'Maintain current voluntary framework approach',\n",
        "                'change': 'No significant changes required',\n",
        "                'priority': 'Low',\n",
        "                'timeline': 'Ongoing'\n",
        "            },\n",
        "            'EU': {\n",
        "                'action': 'Continue AI Act implementation',\n",
        "                'change': 'Already leading - maintain course',\n",
        "                'priority': 'Medium',\n",
        "                'timeline': 'On track for 2026'\n",
        "            },\n",
        "            'China': {\n",
        "                'action': 'Maintain state-centric governance model',\n",
        "                'change': 'Current approach diverges from Western norms',\n",
        "                'priority': 'Low',\n",
        "                'timeline': 'No convergence expected'\n",
        "            },\n",
        "            'key_insight': 'âš ï¸ This scenario maintains current fragmentation - No convergence strategy'\n",
        "        },\n",
        "        'convergence': {\n",
        "            'US': {\n",
        "                'action': 'Strengthen voluntary frameworks with enforcement mechanisms',\n",
        "                'change': '+35% regulatory strength while maintaining innovation focus',\n",
        "                'priority': 'High',\n",
        "                'timeline': '6-12 months'\n",
        "            },\n",
        "            'EU': {\n",
        "                'action': 'Moderate AI Act timelines to allow industry adaptation',\n",
        "                'change': 'Extend compliance deadlines by 6 months for high-risk systems',\n",
        "                'priority': 'High',\n",
        "                'timeline': '3-6 months'\n",
        "            },\n",
        "            'China': {\n",
        "                'action': 'Increase transparency in algorithm governance',\n",
        "                'change': '+40% transparency requirements, align with OECD principles',\n",
        "                'priority': 'Critical',\n",
        "                'timeline': '12-18 months'\n",
        "            },\n",
        "            'UK': {\n",
        "                'action': 'Harmonize sectoral approach with EU risk framework',\n",
        "                'change': 'Adopt compatible risk classification system',\n",
        "                'priority': 'High',\n",
        "                'timeline': '6-9 months'\n",
        "            },\n",
        "            'Japan': {\n",
        "                'action': 'Strengthen data governance to match GDPR standards',\n",
        "                'change': '+25% data protection requirements',\n",
        "                'priority': 'Medium',\n",
        "                'timeline': '9-12 months'\n",
        "            },\n",
        "            'India': {\n",
        "                'action': 'Formalize AI governance framework',\n",
        "                'change': 'Establish comprehensive AI policy (currently ad-hoc)',\n",
        "                'priority': 'High',\n",
        "                'timeline': '6-12 months'\n",
        "            },\n",
        "            'UNESCO': {\n",
        "                'action': 'Provide technical assistance to implementing countries',\n",
        "                'change': 'Increase capacity building programs by 50%',\n",
        "                'priority': 'Medium',\n",
        "                'timeline': '3-6 months'\n",
        "            },\n",
        "            'OECD': {\n",
        "                'action': 'Facilitate harmonization workshops among member states',\n",
        "                'change': 'Quarterly coordination meetings',\n",
        "                'priority': 'High',\n",
        "                'timeline': 'Immediate - 24 months'\n",
        "            },\n",
        "            'key_insight': 'âœ… Achievable with coordinated effort - 70% alignment in 18 months'\n",
        "        },\n",
        "        'resistance': {\n",
        "            'key_insight': 'âŒ High organizational inertia blocks progress - interventions needed to overcome resistance',\n",
        "            'US': {\n",
        "                'action': 'Address Congressional gridlock on AI legislation',\n",
        "                'change': 'Build bipartisan consensus (currently blocked)',\n",
        "                'priority': 'Critical',\n",
        "                'timeline': '12-24 months'\n",
        "            },\n",
        "            'EU': {\n",
        "                'action': 'Overcome member state implementation resistance',\n",
        "                'change': 'Increase political will, reduce bureaucratic delays',\n",
        "                'priority': 'Critical',\n",
        "                'timeline': '12-18 months'\n",
        "            },\n",
        "            'China': {\n",
        "                'action': 'Cultural resistance to Western governance norms',\n",
        "                'change': 'Find common ground on technical standards',\n",
        "                'priority': 'Critical',\n",
        "                'timeline': '18-36 months'\n",
        "            },\n",
        "            'intervention': 'ğŸš¨ Requires high-level political intervention to break deadlock'\n",
        "        },\n",
        "        'optimal': {\n",
        "            'key_insight': 'ğŸ¯ Best-case scenario - rapid convergence with strong coordination',\n",
        "            'US': {\n",
        "                'action': 'Pass comprehensive federal AI legislation',\n",
        "                'change': 'Adopt risk-based framework aligned with EU approach',\n",
        "                'priority': 'Critical',\n",
        "                'timeline': '3-6 months'\n",
        "            },\n",
        "            'EU': {\n",
        "                'action': 'Accelerate AI Act implementation with industry support',\n",
        "                'change': 'Fast-track approval processes, maintain high standards',\n",
        "                'priority': 'High',\n",
        "                'timeline': '3-6 months'\n",
        "            },\n",
        "            'China': {\n",
        "                'action': 'Major policy shift toward transparency and international alignment',\n",
        "                'change': '+60% alignment with OECD principles',\n",
        "                'priority': 'Critical',\n",
        "                'timeline': '6-12 months'\n",
        "            },\n",
        "            'UK': {\n",
        "                'action': 'Full harmonization with EU AI Act',\n",
        "                'change': 'Abandon sectoral approach, adopt EU framework',\n",
        "                'priority': 'High',\n",
        "                'timeline': '3-6 months'\n",
        "            },\n",
        "            'All': {\n",
        "                'action': 'Establish permanent international AI governance body',\n",
        "                'change': 'Create binding coordination mechanism',\n",
        "                'priority': 'Critical',\n",
        "                'timeline': '6-9 months'\n",
        "            },\n",
        "            'likelihood': 'âš¡ Requires unprecedented political will - 15% probability without major catalyst'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Determine current scenario (default to convergence)\n",
        "    current_scenario = 'convergence'  # This would be dynamically set based on UI selection\n",
        "\n",
        "    scenario_recs = recommendations.get(current_scenario, recommendations['convergence'])\n",
        "\n",
        "    # Display key insight\n",
        "    if 'key_insight' in scenario_recs:\n",
        "        st.warning(scenario_recs['key_insight'])\n",
        "\n",
        "    if 'intervention' in scenario_recs:\n",
        "        st.error(scenario_recs['intervention'])\n",
        "\n",
        "    if 'likelihood' in scenario_recs:\n",
        "        st.info(scenario_recs['likelihood'])\n",
        "\n",
        "    # Display recommendations by country\n",
        "    for country, rec in scenario_recs.items():\n",
        "        if country not in ['key_insight', 'intervention', 'likelihood']:\n",
        "            with st.expander(f\"{'ğŸŒ' if country in ['UNESCO', 'OECD', 'NATO', 'WEF', 'UN'] else 'ğŸ—ºï¸'} {country}\", expanded=False):\n",
        "                if 'action' in rec:\n",
        "                    st.markdown(f\"**Required Action:**\")\n",
        "                    st.markdown(f\"{rec['action']}\")\n",
        "\n",
        "                if 'change' in rec:\n",
        "                    st.markdown(f\"**Specific Change:**\")\n",
        "                    st.markdown(f\"{rec['change']}\")\n",
        "\n",
        "                if 'priority' in rec:\n",
        "                    priority_color = {'Critical': 'ğŸ”´', 'High': 'ğŸŸ ', 'Medium': 'ğŸŸ¡', 'Low': 'ğŸŸ¢'}\n",
        "                    st.markdown(f\"**Priority:** {priority_color.get(rec['priority'], 'âšª')} {rec['priority']}\")\n",
        "\n",
        "                if 'timeline' in rec:\n",
        "                    st.markdown(f\"**Timeline:** {rec['timeline']}\")\n",
        "\n",
        "with rec_tab2:\n",
        "    st.markdown(\"#### Quantified Policy Adjustments\")\n",
        "    st.markdown(\"\"\"\n",
        "    Based on E-AGPO-HT mathematical modeling, here are the **precise policy parameter changes**\n",
        "    needed for convergence.\n",
        "    \"\"\")\n",
        "\n",
        "    # Policy dimension adjustments\n",
        "    adjustments_df = {\n",
        "        'Safety/Ethics Regulations': {\n",
        "            'US': '+35%',\n",
        "            'EU': 'Baseline (maintain)',\n",
        "            'China': '+40%',\n",
        "            'UK': '+15%',\n",
        "            'Japan': '+20%'\n",
        "        },\n",
        "        'Innovation Support': {\n",
        "            'US': 'Baseline (maintain)',\n",
        "            'EU': '+10% (moderate enforcement)',\n",
        "            'China': '+15%',\n",
        "            'UK': '+5%',\n",
        "            'Japan': '+10%'\n",
        "        },\n",
        "        'Data Governance': {\n",
        "            'US': '+30%',\n",
        "            'EU': 'Baseline (GDPR)',\n",
        "            'China': '+50%',\n",
        "            'UK': '+20%',\n",
        "            'Japan': '+25%'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    import pandas as pd\n",
        "    df_adj = pd.DataFrame(adjustments_df).T\n",
        "\n",
        "    st.dataframe(df_adj, use_container_width=True)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    **Interpretation:**\n",
        "    - **Positive values** (+X%) = Need to strengthen/increase regulation\n",
        "    - **Baseline** = Current level is appropriate, maintain\n",
        "    - **Higher percentages** = Larger policy shifts required\n",
        "\n",
        "    **Example:** China needs +40% increase in Safety/Ethics regulations to align with EU/US standards.\n",
        "    \"\"\")\n",
        "\n",
        "    st.markdown(\"#### Distance to Consensus\")\n",
        "    st.markdown(\"\"\"\n",
        "    Shows how far each stakeholder is from the global consensus point (center of 3D space).\n",
        "    \"\"\")\n",
        "\n",
        "    distance_data = {\n",
        "        'Stakeholder': ['China', 'Brazil', 'India', 'South Korea', 'Japan', 'US', 'Canada', 'Australia', 'UK', 'EU'],\n",
        "        'Current Distance': [8.2, 7.5, 6.8, 5.2, 4.9, 3.5, 2.8, 2.6, 2.1, 1.5],\n",
        "        'Target Distance': [2.5, 3.0, 3.2, 2.0, 2.2, 2.0, 1.5, 1.5, 1.0, 1.0],\n",
        "        'Movement Required': [5.7, 4.5, 3.6, 3.2, 2.7, 1.5, 1.3, 1.1, 1.1, 0.5]\n",
        "    }\n",
        "\n",
        "    df_dist = pd.DataFrame(distance_data)\n",
        "    st.dataframe(df_dist, use_container_width=True)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    **Key Finding:** China and Brazil require the largest policy shifts to achieve convergence.\n",
        "    \"\"\")\n",
        "\n",
        "with rec_tab3:\n",
        "    st.markdown(\"#### Convergence Timeline & Milestones\")\n",
        "    st.markdown(\"\"\"\n",
        "    **Projected 18-Month Pathway to 70% Global Alignment**\n",
        "    \"\"\")\n",
        "\n",
        "    milestones = [\n",
        "        {\n",
        "            'Month': 'Month 0-3',\n",
        "            'Phase': 'Foundation',\n",
        "            'Milestone': 'Initial Coordination Framework',\n",
        "            'Actions': [\n",
        "                'OECD convenes harmonization working group',\n",
        "                'US introduces federal AI legislation',\n",
        "                'EU extends AI Act compliance timelines by 6 months',\n",
        "                'UNESCO launches capacity building program'\n",
        "            ],\n",
        "            'Expected Alignment': '45%'\n",
        "        },\n",
        "        {\n",
        "            'Month': 'Month 3-6',\n",
        "            'Phase': 'Early Adoption',\n",
        "            'Milestone': 'Core Countries Align',\n",
        "            'Actions': [\n",
        "                'UK harmonizes with EU framework',\n",
        "                'Japan strengthens data governance',\n",
        "                'Canada formalizes alignment commitment',\n",
        "                'US-EU transatlantic agreement signed'\n",
        "            ],\n",
        "            'Expected Alignment': '55%'\n",
        "        },\n",
        "        {\n",
        "            'Month': 'Month 6-12',\n",
        "            'Phase': 'Expansion',\n",
        "            'Milestone': 'Regional Blocs Form',\n",
        "            'Actions': [\n",
        "                'China increases transparency requirements',\n",
        "                'India adopts comprehensive AI policy',\n",
        "                'South Korea aligns with regional standards',\n",
        "                'Brazil joins Latin American coordination initiative'\n",
        "            ],\n",
        "            'Expected Alignment': '62%'\n",
        "        },\n",
        "        {\n",
        "            'Month': 'Month 12-18',\n",
        "            'Phase': 'Convergence',\n",
        "            'Milestone': '70% Global Alignment Achieved',\n",
        "            'Actions': [\n",
        "                'International AI governance body established',\n",
        "                'Binding coordination mechanism adopted',\n",
        "                'Cross-border enforcement framework operational',\n",
        "                'Regular monitoring and adjustment process begins'\n",
        "            ],\n",
        "            'Expected Alignment': '70%'\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    for m in milestones:\n",
        "        with st.expander(f\"**{m['Month']}**: {m['Milestone']} ({m['Expected Alignment']} alignment)\", expanded=True):\n",
        "            st.markdown(f\"**Phase:** {m['Phase']}\")\n",
        "            st.markdown(f\"**Key Actions:**\")\n",
        "            for action in m['Actions']:\n",
        "                st.markdown(f\"- {action}\")\n",
        "\n",
        "            # Progress bar\n",
        "            alignment_val = int(m['Expected Alignment'].strip('%'))\n",
        "            st.progress(alignment_val / 100)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"#### Critical Success Factors\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.markdown(\"\"\"\n",
        "        **Enablers:**\n",
        "        - âœ… Strong OECD coordination\n",
        "        - âœ… EU-US transatlantic cooperation\n",
        "        - âœ… UNESCO capacity building\n",
        "        - âœ… Regular stakeholder dialogue\n",
        "        \"\"\")\n",
        "\n",
        "    with col2:\n",
        "        st.markdown(\"\"\"\n",
        "        **Risks:**\n",
        "        - âš ï¸ US Congressional gridlock\n",
        "        - âš ï¸ China resistance to transparency\n",
        "        - âš ï¸ Industry lobbying against regulation\n",
        "        - âš ï¸ Geopolitical tensions derailing cooperation\n",
        "        \"\"\")\n",
        "\n",
        "    st.info(\"\"\"\n",
        "    **Probability Assessment:** With current coordination pressure and trust levels,\n",
        "    this pathway has a **65% probability of success**. Increasing trust network strength\n",
        "    to 80%+ would raise probability to 85%.\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# EXPLANATION SECTION\n",
        "# =============================================================================\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"### ğŸ“– How to Interpret This Visualization\")\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.markdown(\"\"\"\n",
        "    #### The AlphaFold Parallel\n",
        "\n",
        "    **AlphaFold:**\n",
        "    - Shows 3D protein structure\n",
        "    - Predicts folding in hours vs. years\n",
        "    - Confidence scores for accuracy\n",
        "    - Reveals structural alignment\n",
        "\n",
        "    **Auracelle Bach:**\n",
        "    - Shows 3D policy alignment\n",
        "    - Predicts convergence in seconds vs. years\n",
        "    - Alignment scores for coordination\n",
        "    - Reveals governance coordination patterns\n",
        "    \"\"\")\n",
        "\n",
        "with col2:\n",
        "    st.markdown(\"\"\"\n",
        "    #### What You're Seeing\n",
        "\n",
        "    **Node Positions:**\n",
        "    - Initial: Current policy stance\n",
        "    - Movement: Convergence toward consensus\n",
        "    - Clusters: Groups of aligned policies\n",
        "\n",
        "    **Connections (Lines):**\n",
        "    - Appear between aligned stakeholders\n",
        "    - Thickness = strength of alignment\n",
        "    - More lines = better coordination\n",
        "\n",
        "    **Colors:**\n",
        "    - Blue: Western democracies (aligned)\n",
        "    - Orange: Middle alignment\n",
        "    - Red: Different approach\n",
        "    - Green: International organizations\n",
        "    \"\"\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "### ğŸ¯ Real-World Applications\n",
        "\n",
        "1. **Predict Negotiation Outcomes**: See which countries will align before meetings\n",
        "2. **Identify Bottlenecks**: Find stakeholders blocking coordination\n",
        "3. **Test Policy Changes**: Adjust parameters to see impact on convergence\n",
        "4. **Timeline Forecasting**: Estimate realistic convergence timeframes\n",
        "\n",
        "This visualization makes abstract governance coordination **tangible and measurable** -\n",
        "just like AlphaFold made protein structures concrete!\n",
        "\"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "# FOOTER\n",
        "# =============================================================================\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "<div style='text-align: center; padding: 20px;'>\n",
        "    <h3>ğŸŒ Auracelle Bach | 3D Coordination Visualization</h3>\n",
        "    <p><strong>Like AlphaFold for Policy Alignment</strong></p>\n",
        "    <p style='font-size: 12px;'>Interactive Multi-Stakeholder Simulation</p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "'''\n",
        "\n",
        "with open('pages/viz_3d.py', 'w') as f:\n",
        "    f.write(viz_3d_content)\n",
        "\n",
        "print(\"âœ… 3D visualization page created\")\n",
        "\n",
        "print(\"âœ… Institutional behavior modules page created\")\n",
        "# LAUNCH STREAMLIT + NGROK\n",
        "# =============================================================================\n",
        "\n",
        "print(\"ğŸš€ Starting Streamlit...\")\n",
        "\n",
        "subprocess.run(['pkill', '-f', 'streamlit'], stderr=subprocess.DEVNULL)\n",
        "time.sleep(2)\n",
        "\n",
        "streamlit_process = subprocess.Popen(\n",
        "    ['streamlit', 'run', 'app.py', '--server.port=8501', '--server.headless=true'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "try:\n",
        "    public_url = ngrok.connect(8501, bind_tls=True, hostname=\"graceaevans-auracelle-ailabs.ngrok.app\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"âœ… Auracelle Bach - E-AGPO-HT (COMPLETE 9-ENHANCEMENT SUITE) is LIVE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nğŸŒ Access: https://graceaevans-auracelle-ailabs.ngrok.app\")\n",
        "    print(\"ğŸ” Password: charlie2025\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"\\nğŸ§  Cognitive Architecture:\")\n",
        "    print(\"   â€¢ Moral Foundations (Haidt's 5-foundation theory)\")\n",
        "    print(\"   â€¢ Trust Dynamics (Ostrom/Axelrod cooperation)\")\n",
        "    print(\"   â€¢ Value-Weighted Decision-Making\")\n",
        "    print(\"\\nğŸ†• 9 Mathematical Enhancements:\")\n",
        "    print(\"   1ï¸âƒ£  Bayesian uncertainty quantification\")\n",
        "    print(\"   2ï¸âƒ£  Convergence prediction modeling\")\n",
        "    print(\"   3ï¸âƒ£  Hierarchical capability gap analysis\")\n",
        "    print(\"   4ï¸âƒ£  Multi-objective Pareto optimization\")\n",
        "    print(\"   5ï¸âƒ£  Network diffusion & cascade effects\")\n",
        "    print(\"   6ï¸âƒ£  Historical pattern matching\")\n",
        "    print(\"   7ï¸âƒ£  Maturity trajectory planning\")\n",
        "    print(\"   8ï¸âƒ£  Kalman filter capability tracking\")\n",
        "    print(\"   9ï¸âƒ£  RL-optimized negotiation strategies\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"\\nğŸ“Š Phase 2 APIs Integrated:\")\n",
        "    print(\"   â€¢ OECD AI Principles Database\")\n",
        "    print(\"   â€¢ Privacy International Country Scores\")\n",
        "    print(\"   â€¢ ParlaMint Argumentation Patterns\")\n",
        "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style='padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                border-radius: 10px; text-align: center; margin: 20px 0;'>\n",
        "        <h2 style='color: white; margin-bottom: 15px;'>ğŸ¼ Auracelle Bach</h2>\n",
        "        <h3 style='color: white; margin-bottom: 10px;'>Complete Mathematical Intelligence + Cognitive Architecture</h3>\n",
        "        <a href='https://graceaevans-auracelle-ailabs.ngrok.app' target='_blank'\n",
        "           style='display: inline-block; padding: 15px 30px; background: white;\n",
        "                  color: #667eea; text-decoration: none; border-radius: 5px;\n",
        "                  font-weight: bold; font-size: 18px;'>\n",
        "            ğŸŒ Launch Bach\n",
        "        </a>\n",
        "        <p style='color: white; margin-top: 15px;'>\n",
        "            Password: <strong>charlie2025</strong>\n",
        "        </p>\n",
        "        <div style='background: rgba(255,255,255,0.2); padding: 15px;\n",
        "                    border-radius: 5px; margin-top: 20px;'>\n",
        "            <p style='color: white; font-weight: bold;'>âœ… All 9 Mathematical Enhancements Active</p>\n",
        "            <p style='color: white; font-weight: bold; margin-top: 10px;'>ğŸ§  Cognitive Architecture Active</p>\n",
        "            <p style='color: white; font-size: 14px;'>Moral Foundations â€¢ Trust Dynamics â€¢ Value-Weighted Decisions</p>\n",
        "            <p style='color: white; font-size: 14px;'>\n",
        "                Bayesian â€¢ Convergence â€¢ Gap Analysis â€¢ Pareto<br>\n",
        "                Network Diffusion â€¢ Historical â€¢ Maturity â€¢ Kalman â€¢ RL\n",
        "            </p>\n",
        "            <p style='color: white; font-size: 12px; margin-top: 10px;'>\n",
        "                Phase 2 APIs: OECD â€¢ Privacy International â€¢ ParlaMint\n",
        "            </p>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâš ï¸ Error: {e}\")\n",
        "    print(\"\\nğŸ”§ Troubleshooting:\")\n",
        "    print(\"1. Verify domain: graceaevans-auracelle-ailabs.ngrok.app\")\n",
        "    print(\"2. Check port 8501 availability\")\n",
        "    print(\"3. Confirm ngrok auth token\")\n",
        "    try:\n",
        "        print(\"\\nâš¡ Attempting fallback connection...\")\n",
        "        fallback = ngrok.connect(8501)\n",
        "        print(f\"âœ… Fallback URL: {fallback}\")\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='padding: 20px; background: #ff9800; border-radius: 10px; text-align: center;'>\n",
        "            <h3 style='color: white;'>âš¡ Fallback Mode Active</h3>\n",
        "            <a href='{fallback}' target='_blank' style='color: white; font-weight: bold;'>\n",
        "                Access Bach Here\n",
        "            </a>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "    except:\n",
        "        print(\"âŒ Fallback connection failed\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}